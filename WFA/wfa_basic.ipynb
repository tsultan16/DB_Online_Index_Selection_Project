{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Online Index Selection using the Work Function Algorithm (WFA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "import os\n",
    "import subprocess\n",
    "import uuid\n",
    "\n",
    "import pyodbc\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import re\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import itertools\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import IPython\n",
    "notebook_path = IPython.get_ipython().starting_dir\n",
    "target_subdirectory_path = os.path.abspath(os.path.join(os.path.dirname(notebook_path), 'database'))\n",
    "sys.path.append(target_subdirectory_path)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we will define some helper functions for generating list of all possible configurations subject to constraints (i.e. max memory usage, max number of columns per index), along with cost estimation (such as transition costs and query execution cost in a hypothetical configuration). We will also precompute estimates of all index creation costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index:\n",
    "    def __init__(self, table_name, index_id, index_columns, size, include_columns=(), value=None):\n",
    "        self.table_name = table_name\n",
    "        self.index_id = index_id\n",
    "        self.index_columns = index_columns\n",
    "        self.size = size\n",
    "        self.include_columns = include_columns\n",
    "        self.value = value\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Index({self.table_name}, {self.index_id}, {self.index_columns}, {self.include_columns}, {self.size}, {self.value})\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Function for generating all possible configurations (i.e. subsets of indixes) and also precomputing index creation cost estimates\n",
    "\"\"\"\n",
    "def generate_all_configurations(connection, MAX_SIZE=1024, MAX_KEY_COLS=3, MAX_INCLUDE_COLS=3, verbose=False):\n",
    "    # first, generate all possible indices\n",
    "    tables = get_all_tables(connection)\n",
    "    all_indices = {} \n",
    "    # tqdm bar around table loop\n",
    "    for table_name, table in tqdm(tables.items(), desc=\"Generating all indices for table:\"):\n",
    "        #print(f\"Table --> {table}\")\n",
    "        columns = table.get_columns()\n",
    "        #print(f\"Columns --> {columns}\")    \n",
    "        if verbose:\n",
    "            print(f\"Table --> {table_name} with columns --> {columns}\")\n",
    "        # get all possible permutations of columns, up to MAX_KEY_COLS columns\n",
    "        for num_columns in range(1, min(MAX_KEY_COLS, len(columns)+1)):\n",
    "            col_permutations = list(itertools.permutations(columns, num_columns))\n",
    "            # also generate permutations of columns with include columns\n",
    "            for cp in col_permutations:\n",
    "                # get columns not in cp\n",
    "                include_columns = list(set(columns) - set(cp))\n",
    "                # get all permutations of include columns up to MAX_INCLUDE_COLS columns\n",
    "                include_col_permutations = list(itertools.permutations(include_columns, MAX_INCLUDE_COLS))\n",
    "                for icp in include_col_permutations:\n",
    "                    index_id = get_index_id(cp, table_name, include_columns)\n",
    "                    if index_id not in all_indices:\n",
    "                        index_size = get_estimated_index_size(connection, table_name, list(cp) + include_columns)\n",
    "                        # create index object\n",
    "                        all_indices[index_id] = Index(table_name, index_id, cp, index_size, tuple(icp))\n",
    "\n",
    "    print(f\"Total number of indices generated: {len(all_indices)}, total estimated size: {sum([i.size for i in all_indices.values()])} Mb\")\n",
    "\n",
    "    # now estimate the creation cost of each index (we this by creating the index and then dropping it, which is potentially \n",
    "    # very expensive, but I don't know a more efficient way)\n",
    "    index_creation_cost = {}\n",
    "    for index_id, index in tqdm(all_indices.items(), desc=\"Estimating index creation cost:\"):\n",
    "        index_creation_cost[index_id] = create_nonclustered_index_object(connection, index)\n",
    "        drop_noncluster_index_object(connection, index)\n",
    "\n",
    "\n",
    "    # now generate all possible configurations within the MAX_SIZE limit\n",
    "    all_configurations = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clone_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
