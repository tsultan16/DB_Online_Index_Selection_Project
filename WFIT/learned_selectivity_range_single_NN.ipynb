{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the PDF of a single table attribute using a Feedforward Neural Network. (Will also try linear regression in a separate notebook)\n",
    "\n",
    "The input for the model is a range predicate and the output should be a prediction for the selectivity.\n",
    "\n",
    "i.e. Given the range $a \\leq x \\leq b$, the model predicts the following:\n",
    "\n",
    "$selectivity(a \\leq x \\leq b) = P(a \\leq x \\leq b)$\n",
    "\n",
    "where $P(x)$ is the learned probability density function.\n",
    "\n",
    "Intseda of directly learning P(x), we will learn a model that predicts $P(a \\leq x \\leq b)$, i.e. it predicts range selectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto reload all modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from simple_cost_model import *\n",
    "from tpch_qgen_class_v2 import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up query generator\n",
    "qg = TPCH_QGEN(DBNAME='tpch10_skew')\n",
    "\n",
    "# Get the statistics for all tables in the tpch database\n",
    "tables, pk_columns = get_tpch_schema()\n",
    "table_names = list(tables.keys())\n",
    "stats = {}\n",
    "estimated_rows = {}\n",
    "for table_name in table_names:\n",
    "    stats[table_name], estimated_rows[table_name] = get_table_stats(table_name, dbname=\"tpch10\")\n",
    "\n",
    "table_attributes = {}\n",
    "for table_name in table_names:\n",
    "    table_attributes[table_name] = list(stats[table_name].keys())\n",
    "\n",
    "# create a dictionary and specify whether each attribute in each table is numeric or char\n",
    "data_type_dict = {}\n",
    "for table_name in tables.keys():\n",
    "    for column_name, column_type in tables[table_name]:\n",
    "        if (\"INT\" in column_type) or (\"DECIMAL\" in column_type) or (\"BIT\" in column_type):\n",
    "            data_type_dict[column_name] = \"numeric\"\n",
    "        else:\n",
    "            data_type_dict[column_name] = \"char\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load actual stats from pickle file\n",
    "with open('tpch10_skew_stats.pkl', 'rb') as f:\n",
    "    actual_stats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement a function for computing the exact selectitiy of any range predicate using the actual statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for computing selectivity of one-sided range predicates using actual stats\n",
    "def exact_selectivity_range(actual_table_stats, column_name, boundary_left, boundary_right):\n",
    "    # make sure attribute data type is numeric\n",
    "    if data_type_dict[column_name] != \"numeric\":\n",
    "        raise ValueError(\"Attribute data type must be numeric\")\n",
    "    \n",
    "    stats = actual_table_stats[column_name]\n",
    "    total_rows = stats['total_count']\n",
    "    #num_distinct = stats['distinct_count']\n",
    "    min_value = stats['min']\n",
    "    max_value = stats['max']\n",
    "    histogram = stats['histogram']\n",
    "\n",
    "    # check if histogram is available\n",
    "    if histogram:\n",
    "        # find all values that fall within the range\n",
    "        selectivity = 0\n",
    "        for value, count in histogram.items():\n",
    "            if boundary_left <= value <= boundary_right:\n",
    "                selectivity += count\n",
    "     \n",
    "        selectivity = selectivity / total_rows\n",
    "    else:\n",
    "        # if histogram is not available, use min and max values, assume uniform distribution\n",
    "        selectivity = (min(max(boundary_left, min_value), max_value) - boundary_left) / (boundary_right - boundary_left)\n",
    "\n",
    "    return selectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick an attribute from one of the tables for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual_stats for attribute c_nationkey: {'min': 0, 'max': 24, 'total_count': 1500000, 'distinct_count': 25, 'histogram': {0: 47704, 1: 86742, 2: 53076, 3: 84877, 4: 70086, 5: 53448, 6: 44748, 7: 44405, 8: 61934, 9: 50617, 10: 57095, 11: 42172, 12: 51829, 13: 103247, 14: 36509, 15: 153124, 16: 46098, 17: 58485, 18: 61718, 19: 44427, 20: 56483, 21: 44522, 22: 51881, 23: 58816, 24: 35957}}\n",
      "exact selectivity for range [10, 20]: 0.4741246666666667\n"
     ]
    }
   ],
   "source": [
    "table_name = \"customer\"\n",
    "column_name = \"c_nationkey\"\n",
    "actual_table_stats = actual_stats[table_name]\n",
    "print(f\"actual_stats for attribute {column_name}: {actual_table_stats[column_name]}\")\n",
    "\n",
    "# test out the function\n",
    "boundary_left = 10\n",
    "boundary_right = 20\n",
    "exact_selectivity = exact_selectivity_range(actual_table_stats, column_name, boundary_left, boundary_right)\n",
    "\n",
    "print(f\"exact selectivity for range [{boundary_left}, {boundary_right}]: {exact_selectivity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets train a feedforward neural network to predict the selectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network model for predicitng range selectivity\n",
    "class SelectivityModel(nn.Module):\n",
    "    def __init__(self, hidden_size=64):\n",
    "        super(SelectivityModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, hidden_size)  # Input is [a, b]\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size//2)\n",
    "        self.fc4 = nn.Linear(hidden_size//2, 1)  # Output is selectivity\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))  # Output as probability\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_range_predicate_samples(actual_stats, table_name, column_name, num_samples=100, fraction_eq=0.1):\n",
    "    data = []\n",
    "    stats = actual_stats[table_name][column_name]\n",
    "    min_value = stats['min']\n",
    "    max_value = stats['max']\n",
    "    \n",
    "    epsilon = 1e-6 * (max_value - min_value)\n",
    "\n",
    "    # make sure that column stats has histogram, otherwise we cannot generate equality predicate samples\n",
    "    if not actual_table_stats[column_name]['histogram']:\n",
    "        fraction_eq = 0\n",
    "    num_eq_samples = int(num_samples * fraction_eq)\n",
    "    num_range_samples = num_samples - num_eq_samples\n",
    "    \n",
    "    # generate range predicate samples\n",
    "    for i in range(num_range_samples):\n",
    "        # generate a random start of the range\n",
    "        a = np.random.uniform(min_value, 0.9*max_value)\n",
    "        # generate a random end of the range, larger than a\n",
    "        b = np.random.uniform(a, max_value)\n",
    "        selectivity = exact_selectivity_range(actual_table_stats, column_name, a, b)\n",
    "        data.append(([a, b], selectivity))\n",
    "\n",
    "    # generate equality predicate samples\n",
    "    for i in range(num_eq_samples):\n",
    "        # draw a value from the histogram uniformly at random\n",
    "        histogram = actual_table_stats[column_name]['histogram']\n",
    "        values = list(histogram.keys())\n",
    "        a = np.random.choice(values) \n",
    "        b = a + epsilon\n",
    "        a = a - epsilon   \n",
    "        selectivity = exact_selectivity_range(actual_table_stats, column_name, a, b)\n",
    "        data.append(([a, b], selectivity))     \n",
    "\n",
    "    # shuffle the data\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_NN(model, criterion, optimizer, data_loader, X_test, y_test, num_epochs, val_every=100):\n",
    "    # training loop\n",
    "    with tqdm(total=num_epochs, desc='Training Progress') as pbar:\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            for inputs, targets in data_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            # compute MAE on the training set\n",
    "            mae_train = torch.mean(torch.abs(outputs - targets))\n",
    "\n",
    "            # Update the progress bar and print loss every 100 epochs\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                pbar.set_postfix({'Loss': f'{total_loss:.4f}', 'MAE': f'{mae_train.item():.4f}'})\n",
    "            pbar.update(1)\n",
    "\n",
    "            if (epoch + 1) % val_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_outputs = model(X_test)\n",
    "                    val_loss = criterion(val_outputs, y_test)\n",
    "                    # also compute the mean absolute error\n",
    "                    mae_val = torch.mean(torch.abs(val_outputs - y_test))\n",
    "                    # update pbar with validation loss and MAE\n",
    "                    pbar.set_postfix({'Loss': f'{total_loss:.4f}', 'MAE':f'{mae_train.item():.4f}', 'Val Loss': f'{val_loss.item():.4f}', 'Val MAE': f'{mae_val.item():.4f}'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"customer\"\n",
    "column_name = \"c_nationkey\"\n",
    "actual_attribute_stats = actual_stats[table_name][column_name]\n",
    "min_value = actual_attribute_stats['min']\n",
    "max_value = actual_attribute_stats['max']\n",
    "\n",
    "# generate a bunch of random range predicates and their selectivities\n",
    "num_samples = 100\n",
    "data = generate_range_predicate_samples(actual_stats, table_name, column_name, num_samples=num_samples, fraction_eq=0.2)\n",
    "\n",
    "# split into training and testing data\n",
    "train_size = int(0.8 * num_samples)\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "\n",
    "X_train = torch.tensor([d[0] for d in train_data], dtype=torch.float32)\n",
    "y_train = torch.tensor([d[1] for d in train_data], dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_test = torch.tensor([d[0] for d in test_data], dtype=torch.float32)\n",
    "y_test = torch.tensor([d[1] for d in test_data], dtype=torch.float32).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "num_epochs = 1000\n",
    "hidden_size = 32\n",
    "batch_size = 32\n",
    "l2_lambda = 0.001 # l2 regularization parameter\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SelectivityModel(hidden_size=hidden_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=l2_lambda)\n",
    "\n",
    "\n",
    "# Create a dataset and data loader\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "train_data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 1000/1000 [00:01<00:00, 507.65it/s, Loss=0.0031, MAE=0.0243, Val Loss=0.0025, Val MAE=0.0403]\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "train_NN(model, criterion, optimizer, train_data_loader, X_test, y_test, num_epochs, val_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.002503875643014908\n",
      "Range: [9.1023, 21.5426], Actual Selectivity: 0.5038, Predicted Selectivity: 0.5482\n",
      "Range: [10.3351, 13.9641], Actual Selectivity: 0.1315, Predicted Selectivity: 0.1650\n",
      "Range: [19.9939, 23.0051], Actual Selectivity: 0.1411, Predicted Selectivity: 0.1183\n",
      "Range: [8.8859, 16.2834], Actual Selectivity: 0.3605, Predicted Selectivity: 0.3481\n",
      "Range: [10.0000, 10.0000], Actual Selectivity: 0.0381, Predicted Selectivity: 0.0533\n",
      "Range: [4.1559, 21.9569], Actual Selectivity: 0.6739, Predicted Selectivity: 0.7534\n",
      "Range: [6.6836, 20.8266], Actual Selectivity: 0.5788, Predicted Selectivity: 0.6102\n",
      "Range: [0.7961, 14.8834], Actual Selectivity: 0.5605, Predicted Selectivity: 0.6312\n",
      "Range: [12.0000, 12.0000], Actual Selectivity: 0.0346, Predicted Selectivity: 0.0515\n",
      "Range: [4.7215, 16.2654], Actual Selectivity: 0.4968, Predicted Selectivity: 0.5041\n",
      "Range: [19.3261, 23.9775], Actual Selectivity: 0.1411, Predicted Selectivity: 0.1927\n",
      "Range: [4.5185, 21.8065], Actual Selectivity: 0.6739, Predicted Selectivity: 0.7351\n",
      "Range: [20.6742, 22.3646], Actual Selectivity: 0.0643, Predicted Selectivity: 0.0773\n",
      "Range: [16.0000, 16.0000], Actual Selectivity: 0.0307, Predicted Selectivity: 0.0481\n",
      "Range: [15.2768, 19.0836], Actual Selectivity: 0.1405, Predicted Selectivity: 0.1614\n",
      "Range: [5.8676, 11.4801], Actual Selectivity: 0.2006, Predicted Selectivity: 0.2519\n",
      "Range: [21.5988, 23.9955], Actual Selectivity: 0.0738, Predicted Selectivity: 0.0953\n",
      "Range: [16.2579, 23.9637], Actual Selectivity: 0.2509, Predicted Selectivity: 0.3748\n",
      "Range: [12.2748, 20.9305], Actual Selectivity: 0.3734, Predicted Selectivity: 0.4032\n",
      "Range: [6.1281, 12.4817], Actual Selectivity: 0.2054, Predicted Selectivity: 0.2879\n"
     ]
    }
   ],
   "source": [
    "# now evaluate the model on the test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    test_loss = criterion(y_pred, y_test)\n",
    "    print(f\"Test loss: {test_loss.item()}\")\n",
    "\n",
    "\n",
    "# show side by side comparison of actual selectivity and predicted selectivity for all test data, along with the range\n",
    "y_pred_array = y_pred.numpy().flatten()\n",
    "y_test_array = y_test.numpy().flatten()\n",
    "X_test_array = X_test.numpy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    a, b = X_test_array[i]\n",
    "    print(f\"Range: [{a:.4f}, {b:.4f}], Actual Selectivity: {y_test_array[i]:.4f}, Predicted Selectivity: {y_pred_array[i]:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison with Online Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectivityModelLR:\n",
    "\n",
    "    def __init__(self, table_name, attribute_name, lambda_reg=0.1, epsilon=1e-8):\n",
    "        self.table_name = table_name\n",
    "        self.attribute_name = attribute_name\n",
    "       \n",
    "        # set feature dimensions\n",
    "        self.features_per_attribute = 2\n",
    "        self.feature_dims = self.features_per_attribute  \n",
    "            \n",
    "        self.V = lambda_reg * np.eye(self.feature_dims)\n",
    "        self.b = np.zeros(self.feature_dims)\n",
    "        self.theta = np.zeros(self.feature_dims)\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.epsilon = epsilon\n",
    "        self.loss_history = []\n",
    "\n",
    "    def update(self, input, target, verbose=False):\n",
    "        x = np.array(input)\n",
    "        #print(f\"predicate: {predicate}, x: {x}\")\n",
    "        self.V += np.outer(x, x)\n",
    "        self.b += target * x\n",
    "        # add small epsilon to diagonal of V for conditioning\n",
    "        #self.theta = np.linalg.solve(self.V + self.epsilon*np.eye(self.feature_dims), self.b)\n",
    "        self.theta = np.linalg.solve(self.V, self.b)\n",
    "        loss, y_pred = self.compute_loss(input, target)\n",
    "        if verbose:\n",
    "            print(f\"Actual selectivity: {target}, predicted selectivity: {y_pred:.3f}, loss incurred: {loss}\")\n",
    "\n",
    "    \n",
    "    def predict(self, input):\n",
    "        x = np.array(input)\n",
    "        # need to constrain the predicted selectivity to be between 0 and 1\n",
    "        y_pred = np.dot(self.theta, x)\n",
    "        y_pred = min(max(0, y_pred), 1)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "    def compute_loss(self, input, target):\n",
    "        y_pred = self.predict(input)\n",
    "        mse = (target - y_pred)**2\n",
    "        reg = self.lambda_reg * np.dot(self.theta, self.theta)\n",
    "        loss = mse + reg\n",
    "        self.loss_history.append(loss)\n",
    "        return loss, y_pred    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple linear regression model for the same attribute\n",
    "table_name = \"customer\"\n",
    "column_name = \"c_nationkey\"\n",
    "actual_attribute_stats = actual_stats[table_name][column_name]\n",
    "min_value = actual_attribute_stats['min']\n",
    "max_value = actual_attribute_stats['max']\n",
    "\n",
    "# generate training data\n",
    "data = generate_range_predicate_samples(actual_stats, table_name, column_name, num_samples=100, fraction_eq=0.2)\n",
    "\n",
    "# split into training and testing data\n",
    "train_size = int(0.8 * num_samples)\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lr(model, train_data, val_data, val_every=10, verbose=False):\n",
    "    #with tqdm(total=num_epochs, desc='Training Progress') as pbar:\n",
    "        total_train_loss = 0\n",
    "        mae_train = 0\n",
    "        with tqdm(total=len(train_data), desc='Training Progress') as pbar:\n",
    "            for i, (input, target) in enumerate(train_data):\n",
    "                loss, y_pred = model.compute_loss(input, target)\n",
    "                total_train_loss += loss\n",
    "                mae_train += abs(target - y_pred)\n",
    "                model.update(input, target)\n",
    "                pbar.update(1)\n",
    "\n",
    "                if (i + 1) % val_every == 0:\n",
    "                    total_val_loss = 0\n",
    "                    mae_val = 0\n",
    "                    for input, target in val_data:\n",
    "                        loss, y_pred = model.compute_loss(input, target)\n",
    "                        total_val_loss += loss\n",
    "                        mae_val += abs(target - y_pred)\n",
    "\n",
    "                    total_val_loss /= len(val_data)\n",
    "                    mae_val /= len(val_data)\n",
    "                    \n",
    "                pbar.set_postfix({'Train loss': f'{total_train_loss/(i+1):.4f}', 'Train MAE': f'{mae_train/(i+1):.4f}', 'Val loss': f'{total_val_loss:.4f}', 'Val MAE': f'{mae_val:.4f}'})\n",
    "\n",
    "                if verbose: print(f\"Train loss: {total_train_loss/(i+1):.4f}, Train MAE: {mae_train/(i+1):.4f}, Val loss: {total_val_loss:.4f}, Val MAE: {mae_val:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the LR model\n",
    "lr_model = SelectivityModelLR(table_name, column_name, lambda_reg=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 80/80 [00:00<00:00, 1461.86it/s, Train loss=0.0013, Train MAE=0.0285, Val loss=0.0014, Val MAE=0.0296]\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "train_lr(lr_model, train_data, test_data, val_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range: [2.8650, 4.2191], Actual Selectivity: 0.1033, Predicted Selectivity: 0.0550\n",
      "Range: [7.0000, 7.0000], Actual Selectivity: 0.0296, Predicted Selectivity: 0.0000\n",
      "Range: [15.0112, 18.2667], Actual Selectivity: 0.1109, Predicted Selectivity: 0.1310\n",
      "Range: [20.5279, 20.8555], Actual Selectivity: 0.0000, Predicted Selectivity: 0.0100\n",
      "Range: [4.0000, 4.0000], Actual Selectivity: 0.0467, Predicted Selectivity: 0.0000\n",
      "Range: [18.9405, 19.7190], Actual Selectivity: 0.0296, Predicted Selectivity: 0.0288\n",
      "Range: [1.4614, 5.0490], Actual Selectivity: 0.1743, Predicted Selectivity: 0.1468\n",
      "Range: [20.8057, 23.7549], Actual Selectivity: 0.1035, Predicted Selectivity: 0.1174\n",
      "Range: [19.2745, 21.0633], Actual Selectivity: 0.0673, Predicted Selectivity: 0.0701\n",
      "Range: [10.3486, 13.5541], Actual Selectivity: 0.1315, Predicted Selectivity: 0.1297\n",
      "Range: [0.5859, 4.2437], Actual Selectivity: 0.1965, Predicted Selectivity: 0.1498\n",
      "Range: [7.0000, 7.0000], Actual Selectivity: 0.0296, Predicted Selectivity: 0.0000\n",
      "Range: [6.3175, 23.5766], Actual Selectivity: 0.6822, Predicted Selectivity: 0.7064\n",
      "Range: [21.3847, 22.8966], Actual Selectivity: 0.0346, Predicted Selectivity: 0.0584\n",
      "Range: [0.9886, 15.1193], Actual Selectivity: 0.6626, Predicted Selectivity: 0.5790\n",
      "Range: [22.0000, 22.0000], Actual Selectivity: 0.0346, Predicted Selectivity: 0.0000\n",
      "Range: [12.1708, 15.1704], Actual Selectivity: 0.1953, Predicted Selectivity: 0.1209\n",
      "Range: [4.2737, 19.2440], Actual Selectivity: 0.6066, Predicted Selectivity: 0.6129\n",
      "Range: [0.0025, 12.3100], Actual Selectivity: 0.4674, Predicted Selectivity: 0.5045\n",
      "Range: [19.0000, 19.0000], Actual Selectivity: 0.0296, Predicted Selectivity: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# show side by side comparison of actual selectivity and LR model predicted selectivity for all test data, along with the range\n",
    "for input, target in test_data:\n",
    "    a, b = input\n",
    "    y_pred = lr_model.predict(input)\n",
    "    print(f\"Range: [{a:.4f}, {b:.4f}], Actual Selectivity: {target:.4f}, Predicted Selectivity: {y_pred:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on artifically generated data distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for computing selectivity of one-sided range predicates using actual stats\n",
    "def exact_selectivity_range_dist(boundary_left, boundary_right, total_rows, min_value, max_value, histogram=None):\n",
    "    \n",
    "    # find all values that fall within the range\n",
    "    selectivity = 0\n",
    "    for value, count in histogram.items():\n",
    "        if boundary_left <= value <= boundary_right:\n",
    "            selectivity += count\n",
    "    \n",
    "    selectivity = selectivity / total_rows\n",
    "\n",
    "    return selectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_range_predicate_samples_dist(total_rows, min_value, max_value, histogram, num_samples=100, fraction_eq=0.1):\n",
    "    data = []\n",
    "    epsilon = 1e-6 * (max_value - min_value)\n",
    "    num_eq_samples = int(num_samples * fraction_eq)\n",
    "    num_range_samples = num_samples - num_eq_samples\n",
    "    \n",
    "    # generate range predicate samples\n",
    "    for i in range(num_range_samples):\n",
    "        # generate a random start of the range\n",
    "        a = np.random.uniform(min_value, 0.9*max_value)\n",
    "        # generate a random end of the range, larger than a\n",
    "        b = np.random.uniform(a, max_value)\n",
    "        selectivity = exact_selectivity_range_dist(a, b, total_rows, min_value, max_value, histogram)\n",
    "        data.append(([a, b], selectivity))\n",
    "\n",
    "    # generate equality predicate samples\n",
    "    for i in range(num_eq_samples):\n",
    "        # draw a value from the histogram uniformly at random\n",
    "        histogram = actual_table_stats[column_name]['histogram']\n",
    "        values = list(histogram.keys())\n",
    "        a = np.random.choice(values) \n",
    "        b = a + epsilon\n",
    "        a = a - epsilon   \n",
    "        selectivity = exact_selectivity_range_dist(a, b, total_rows, min_value, max_value, histogram)\n",
    "        data.append(([a, b], selectivity))     \n",
    "\n",
    "    # shuffle the data\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning a Uniform Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniform distribution\n",
    "min_value = 0\n",
    "max_value = 99\n",
    "num_distinct_values = 100\n",
    "total_rows = 10000000\n",
    "\n",
    "# use distribution function to generate values and counts for histogram\n",
    "values = np.arange(min_value, max_value+1, (max_value+1-min_value)//num_distinct_values)\n",
    "counts = (total_rows // num_distinct_values) * np.ones(num_distinct_values)\n",
    "\n",
    "histogram = dict(zip(values, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 90, Number of testing samples: 60\n"
     ]
    }
   ],
   "source": [
    "# generate some data\n",
    "num_samples=150\n",
    "data = generate_range_predicate_samples_dist(total_rows, min_value, max_value, histogram, num_samples=num_samples, fraction_eq=0.2)\n",
    "\n",
    "# split into training and testing data\n",
    "train_size = int(0.6 * num_samples)\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "\n",
    "print(f\"Number of training samples: {len(train_data)}, Number of testing samples: {len(test_data)}\")\n",
    "\n",
    "X_train = torch.tensor([d[0] for d in train_data], dtype=torch.float32)\n",
    "y_train = torch.tensor([d[1] for d in train_data], dtype=torch.float32).view(-1, 1)\n",
    "X_test = torch.tensor([d[0] for d in test_data], dtype=torch.float32)\n",
    "y_test = torch.tensor([d[1] for d in test_data], dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate NN and LR models\n",
    "num_epochs = 1000\n",
    "hidden_size = 32\n",
    "batch_size = 32\n",
    "l2_lambda = 0.001 # l2 regularization parameter\n",
    "\n",
    "# instantiate the NN model, loss function, and optimizer\n",
    "model = SelectivityModel(hidden_size=hidden_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=l2_lambda)\n",
    "\n",
    "# Create a dataset and data loader\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)  \n",
    "\n",
    "# instantiate the LR model\n",
    "lr_model = SelectivityModelLR(table_name, column_name, lambda_reg=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 1000/1000 [00:02<00:00, 477.58it/s, Loss=0.0013, MAE=0.0162, Val Loss=0.0004, Val MAE=0.0169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 90/90 [00:00<00:00, 1253.47it/s, Train loss=0.0004, Train MAE=0.0071, Val loss=0.0000, Val MAE=0.0040]\n"
     ]
    }
   ],
   "source": [
    "# train the models\n",
    "print(f\"Training NN model...\")\n",
    "train_NN(model, criterion, optimizer, data_loader, X_test, y_test, num_epochs, val_every=10)\n",
    "print(f\"Training LR model...\")\n",
    "train_lr(lr_model, train_data, test_data, val_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Test loss: 0.00041398173198103905\n",
      "Range: [0.9999, 1.0001], Actual Selectivity: 0.0087, NN Predicted Selectivity: 0.0471, LR Predicted Selectivity: 0.0000\n",
      "Range: [77.5544, 93.3910], Actual Selectivity: 0.1600, NN Predicted Selectivity: 0.1579, LR Predicted Selectivity: 0.1583\n",
      "Range: [3.6556, 58.5532], Actual Selectivity: 0.5500, NN Predicted Selectivity: 0.5680, LR Predicted Selectivity: 0.5487\n",
      "Range: [4.6190, 76.1635], Actual Selectivity: 0.7200, NN Predicted Selectivity: 0.7389, LR Predicted Selectivity: 0.7150\n",
      "Range: [55.5863, 90.6247], Actual Selectivity: 0.3500, NN Predicted Selectivity: 0.3613, LR Predicted Selectivity: 0.3502\n",
      "Range: [11.9999, 12.0001], Actual Selectivity: 0.0052, NN Predicted Selectivity: 0.0413, LR Predicted Selectivity: 0.0000\n",
      "Range: [9.9999, 10.0001], Actual Selectivity: 0.0057, NN Predicted Selectivity: 0.0421, LR Predicted Selectivity: 0.0000\n",
      "Range: [17.5276, 34.9693], Actual Selectivity: 0.1700, NN Predicted Selectivity: 0.1828, LR Predicted Selectivity: 0.1743\n",
      "Range: [1.7454, 56.4385], Actual Selectivity: 0.5500, NN Predicted Selectivity: 0.5653, LR Predicted Selectivity: 0.5466\n",
      "Range: [59.6825, 91.1278], Actual Selectivity: 0.3200, NN Predicted Selectivity: 0.3264, LR Predicted Selectivity: 0.3143\n",
      "Range: [40.5685, 97.2625], Actual Selectivity: 0.5700, NN Predicted Selectivity: 0.5956, LR Predicted Selectivity: 0.5666\n",
      "Range: [31.4622, 42.1625], Actual Selectivity: 0.1100, NN Predicted Selectivity: 0.1192, LR Predicted Selectivity: 0.1070\n",
      "Range: [10.6929, 58.0106], Actual Selectivity: 0.4800, NN Predicted Selectivity: 0.4825, LR Predicted Selectivity: 0.4729\n",
      "Range: [30.0455, 86.1886], Actual Selectivity: 0.5600, NN Predicted Selectivity: 0.5867, LR Predicted Selectivity: 0.5611\n",
      "Range: [38.8234, 94.0765], Actual Selectivity: 0.5600, NN Predicted Selectivity: 0.5791, LR Predicted Selectivity: 0.5522\n",
      "Range: [20.5457, 43.4890], Actual Selectivity: 0.2300, NN Predicted Selectivity: 0.2339, LR Predicted Selectivity: 0.2293\n",
      "Range: [8.9999, 9.0001], Actual Selectivity: 0.0051, NN Predicted Selectivity: 0.0425, LR Predicted Selectivity: 0.0000\n",
      "Range: [48.3139, 85.5634], Actual Selectivity: 0.3700, NN Predicted Selectivity: 0.3814, LR Predicted Selectivity: 0.3723\n",
      "Range: [20.9999, 21.0001], Actual Selectivity: 0.0045, NN Predicted Selectivity: 0.0378, LR Predicted Selectivity: 0.0000\n",
      "Range: [31.1276, 34.3550], Actual Selectivity: 0.0300, NN Predicted Selectivity: 0.0532, LR Predicted Selectivity: 0.0323\n",
      "Range: [16.6332, 40.8234], Actual Selectivity: 0.2400, NN Predicted Selectivity: 0.2434, LR Predicted Selectivity: 0.2418\n",
      "Range: [78.3855, 86.7803], Actual Selectivity: 0.0800, NN Predicted Selectivity: 0.0735, LR Predicted Selectivity: 0.0839\n",
      "Range: [82.7665, 97.0230], Actual Selectivity: 0.1500, NN Predicted Selectivity: 0.1396, LR Predicted Selectivity: 0.1425\n",
      "Range: [62.6674, 62.9113], Actual Selectivity: 0.0000, NN Predicted Selectivity: 0.0273, LR Predicted Selectivity: 0.0025\n",
      "Range: [23.9999, 24.0001], Actual Selectivity: 0.0036, NN Predicted Selectivity: 0.0368, LR Predicted Selectivity: 0.0000\n",
      "Range: [36.2537, 48.7763], Actual Selectivity: 0.1200, NN Predicted Selectivity: 0.1350, LR Predicted Selectivity: 0.1252\n",
      "Range: [11.9587, 62.2411], Actual Selectivity: 0.5100, NN Predicted Selectivity: 0.5168, LR Predicted Selectivity: 0.5025\n",
      "Range: [24.5298, 24.5684], Actual Selectivity: 0.0000, NN Predicted Selectivity: 0.0368, LR Predicted Selectivity: 0.0004\n",
      "Range: [55.5831, 91.5725], Actual Selectivity: 0.3600, NN Predicted Selectivity: 0.3712, LR Predicted Selectivity: 0.3597\n",
      "Range: [27.1848, 89.6141], Actual Selectivity: 0.6200, NN Predicted Selectivity: 0.6542, LR Predicted Selectivity: 0.6239\n",
      "Range: [45.1112, 79.8453], Actual Selectivity: 0.3400, NN Predicted Selectivity: 0.3537, LR Predicted Selectivity: 0.3472\n",
      "Range: [73.9806, 85.7746], Actual Selectivity: 0.1200, NN Predicted Selectivity: 0.1177, LR Predicted Selectivity: 0.1179\n",
      "Range: [2.0378, 46.0209], Actual Selectivity: 0.4400, NN Predicted Selectivity: 0.4428, LR Predicted Selectivity: 0.4396\n",
      "Range: [22.5024, 78.2399], Actual Selectivity: 0.5600, NN Predicted Selectivity: 0.5808, LR Predicted Selectivity: 0.5571\n",
      "Range: [40.5942, 92.1017], Actual Selectivity: 0.5200, NN Predicted Selectivity: 0.5378, LR Predicted Selectivity: 0.5148\n",
      "Range: [12.9999, 13.0001], Actual Selectivity: 0.0103, NN Predicted Selectivity: 0.0409, LR Predicted Selectivity: 0.0000\n",
      "Range: [35.2303, 55.3215], Actual Selectivity: 0.2000, NN Predicted Selectivity: 0.2103, LR Predicted Selectivity: 0.2008\n",
      "Range: [70.6462, 84.7285], Actual Selectivity: 0.1400, NN Predicted Selectivity: 0.1412, LR Predicted Selectivity: 0.1408\n",
      "Range: [56.2602, 62.6596], Actual Selectivity: 0.0600, NN Predicted Selectivity: 0.0670, LR Predicted Selectivity: 0.0640\n",
      "Range: [26.6365, 31.6796], Actual Selectivity: 0.0500, NN Predicted Selectivity: 0.0705, LR Predicted Selectivity: 0.0504\n",
      "Range: [47.0247, 83.0070], Actual Selectivity: 0.3600, NN Predicted Selectivity: 0.3675, LR Predicted Selectivity: 0.3596\n",
      "Range: [65.2417, 85.5702], Actual Selectivity: 0.2000, NN Predicted Selectivity: 0.2104, LR Predicted Selectivity: 0.2032\n",
      "Range: [76.6318, 77.0387], Actual Selectivity: 0.0100, NN Predicted Selectivity: 0.0249, LR Predicted Selectivity: 0.0041\n",
      "Range: [35.9192, 64.0326], Actual Selectivity: 0.2900, NN Predicted Selectivity: 0.2850, LR Predicted Selectivity: 0.2810\n",
      "Range: [16.9999, 17.0001], Actual Selectivity: 0.0058, NN Predicted Selectivity: 0.0393, LR Predicted Selectivity: 0.0000\n",
      "Range: [14.9580, 58.1295], Actual Selectivity: 0.4400, NN Predicted Selectivity: 0.4360, LR Predicted Selectivity: 0.4315\n",
      "Range: [75.4053, 77.7030], Actual Selectivity: 0.0200, NN Predicted Selectivity: 0.0327, LR Predicted Selectivity: 0.0230\n",
      "Range: [75.5945, 98.6831], Actual Selectivity: 0.2300, NN Predicted Selectivity: 0.2428, LR Predicted Selectivity: 0.2308\n",
      "Range: [14.9999, 15.0001], Actual Selectivity: 0.0153, NN Predicted Selectivity: 0.0401, LR Predicted Selectivity: 0.0000\n",
      "Range: [59.9474, 62.3335], Actual Selectivity: 0.0300, NN Predicted Selectivity: 0.0376, LR Predicted Selectivity: 0.0239\n",
      "Range: [40.2745, 51.1641], Actual Selectivity: 0.1100, NN Predicted Selectivity: 0.1188, LR Predicted Selectivity: 0.1089\n",
      "Range: [42.3393, 87.3853], Actual Selectivity: 0.4500, NN Predicted Selectivity: 0.4651, LR Predicted Selectivity: 0.4502\n",
      "Range: [56.1453, 98.5531], Actual Selectivity: 0.4200, NN Predicted Selectivity: 0.4412, LR Predicted Selectivity: 0.4239\n",
      "Range: [6.9999, 7.0001], Actual Selectivity: 0.0044, NN Predicted Selectivity: 0.0434, LR Predicted Selectivity: 0.0000\n",
      "Range: [19.9999, 20.0001], Actual Selectivity: 0.0056, NN Predicted Selectivity: 0.0382, LR Predicted Selectivity: 0.0000\n",
      "Range: [58.4545, 73.5262], Actual Selectivity: 0.1500, NN Predicted Selectivity: 0.1552, LR Predicted Selectivity: 0.1507\n",
      "Range: [26.4315, 85.1656], Actual Selectivity: 0.5900, NN Predicted Selectivity: 0.6146, LR Predicted Selectivity: 0.5870\n",
      "Range: [23.1404, 63.9642], Actual Selectivity: 0.4000, NN Predicted Selectivity: 0.4111, LR Predicted Selectivity: 0.4080\n",
      "Range: [69.5222, 94.7018], Actual Selectivity: 0.2500, NN Predicted Selectivity: 0.2706, LR Predicted Selectivity: 0.2517\n",
      "Range: [43.2016, 72.0480], Actual Selectivity: 0.2900, NN Predicted Selectivity: 0.2948, LR Predicted Selectivity: 0.2883\n"
     ]
    }
   ],
   "source": [
    "# evaluate both models on the test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    test_loss = criterion(y_pred, y_test)\n",
    "    print(f\"NN Test loss: {test_loss.item()}\")\n",
    "\n",
    "# show side by side comparison of actual selectivity and predicted selectivity for all test data, along with the range\n",
    "y_pred_array = y_pred.numpy().flatten()\n",
    "y_test_array = y_test.numpy().flatten()\n",
    "X_test_array = X_test.numpy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    a, b = X_test_array[i]\n",
    "    lr_pred = lr_model.predict(X_test_array[i])\n",
    "    print(f\"Range: [{a:.4f}, {b:.4f}], Actual Selectivity: {y_test_array[i]:.4f}, NN Predicted Selectivity: {y_pred_array[i]:.4f}, LR Predicted Selectivity: {lr_pred:.4f}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning a Gaussian Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncated normal distribution\n",
    "def normal_distribution(total_rows, min_value, max_value, x):\n",
    "    # set mean and std deviation\n",
    "    mean = (min_value + max_value) / 2\n",
    "    std = (max_value - min_value) / 6\n",
    "\n",
    "    # compute value of gaussian pdf at x\n",
    "    pdf = np.exp(-0.5 * ((x - mean) / std)**2) / (std * np.sqrt(2 * np.pi)) \n",
    "    # convert to count\n",
    "    count = pdf * total_rows\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gaussian distribution\n",
    "min_value = -200\n",
    "max_value = 2000\n",
    "total_rows = 1000000\n",
    "num_distinct_values = total_rows // 100\n",
    "\n",
    "# use distribution function to generate values and counts for histogram\n",
    "values = np.linspace(min_value, max_value, num_distinct_values)\n",
    "counts = np.array([normal_distribution(total_rows, min_value, max_value, x) for x in values])\n",
    "\n",
    "# normaize the counts so that they are integers and sum to total_rows\n",
    "counts = counts / np.sum(counts) * total_rows\n",
    "counts = np.round(counts)\n",
    "\n",
    "histogram = dict(zip(values, counts))\n",
    "\n",
    "# plot the histogram\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.plot(values, counts)\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Gaussian Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 90, Number of testing samples: 60\n"
     ]
    }
   ],
   "source": [
    "# generate some data\n",
    "num_samples=150\n",
    "data = generate_range_predicate_samples_dist(total_rows, min_value, max_value, histogram, num_samples=num_samples, fraction_eq=0.2)\n",
    "\n",
    "# split into training and testing data\n",
    "train_size = int(0.6 * num_samples)\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "\n",
    "print(f\"Number of training samples: {len(train_data)}, Number of testing samples: {len(test_data)}\")\n",
    "\n",
    "X_train = torch.tensor([d[0] for d in train_data], dtype=torch.float32)\n",
    "y_train = torch.tensor([d[1] for d in train_data], dtype=torch.float32).view(-1, 1)\n",
    "X_test = torch.tensor([d[0] for d in test_data], dtype=torch.float32)\n",
    "y_test = torch.tensor([d[1] for d in test_data], dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# normalize the input data for NN\n",
    "X_train_normalized = X_train # (X_train - min_value) / (max_value - min_value)\n",
    "X_test_normalized = X_test # (X_test - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate NN and LR models\n",
    "num_epochs = 5000\n",
    "hidden_size = 32\n",
    "batch_size = 32\n",
    "l2_lambda = 0.001 # l2 regularization parameter\n",
    "\n",
    "# instantiate the NN model, loss function, and optimizer\n",
    "model = SelectivityModel(hidden_size=hidden_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=l2_lambda)\n",
    "\n",
    "# Create a dataset and data loader\n",
    "dataset = TensorDataset(X_train_normalized, y_train)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)  \n",
    "\n",
    "# instantiate the LR model\n",
    "lr_model = SelectivityModelLR(table_name, column_name, lambda_reg=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 5000/5000 [00:09<00:00, 504.96it/s, Loss=0.0207, MAE=0.0519, Val Loss=0.0092, Val MAE=0.0706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 90/90 [00:00<00:00, 1315.36it/s, Train loss=0.0132, Train MAE=0.0882, Val loss=0.0118, Val MAE=0.0861]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Test loss: 0.009218425489962101\n",
      "Range: [490.3493, 1045.8795], Actual Selectivity: 0.5241, NN Predicted Selectivity: 0.3272, LR Predicted Selectivity: 0.3226\n",
      "Range: [742.7738, 1944.2501], Actual Selectivity: 0.6657, NN Predicted Selectivity: 0.7899, LR Predicted Selectivity: 0.7115\n",
      "Range: [922.7987, 964.7094], Actual Selectivity: 0.0453, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0000\n",
      "Range: [845.1585, 1912.3763], Actual Selectivity: 0.5580, NN Predicted Selectivity: 0.6738, LR Predicted Selectivity: 0.6240\n",
      "Range: [128.3185, 609.1077], Actual Selectivity: 0.1967, NN Predicted Selectivity: 0.3836, LR Predicted Selectivity: 0.2920\n",
      "Range: [9.9978, 10.0022], Actual Selectivity: 0.0571, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0000\n",
      "Range: [12.9978, 13.0022], Actual Selectivity: 0.1032, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0000\n",
      "Range: [12.9978, 13.0022], Actual Selectivity: 0.1032, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0000\n",
      "Range: [1633.4266, 1769.8011], Actual Selectivity: 0.0139, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0141\n",
      "Range: [-0.0022, 0.0022], Actual Selectivity: 0.0477, NN Predicted Selectivity: 0.0723, LR Predicted Selectivity: 0.0000\n",
      "Range: [1209.7059, 1778.1271], Actual Selectivity: 0.1913, NN Predicted Selectivity: 0.1850, LR Predicted Selectivity: 0.2997\n",
      "Range: [717.4053, 1485.3344], Actual Selectivity: 0.6373, NN Predicted Selectivity: 0.4476, LR Predicted Selectivity: 0.4443\n",
      "Range: [1473.5472, 1642.6014], Actual Selectivity: 0.0375, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0412\n",
      "Range: [23.9978, 24.0022], Actual Selectivity: 0.0360, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0000\n",
      "Range: [1029.9355, 1682.1508], Actual Selectivity: 0.3459, NN Predicted Selectivity: 0.2732, LR Predicted Selectivity: 0.3593\n",
      "Range: [931.9563, 1651.1802], Actual Selectivity: 0.4463, NN Predicted Selectivity: 0.3482, LR Predicted Selectivity: 0.4049\n",
      "Range: [926.2706, 1042.6128], Actual Selectivity: 0.1232, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0321\n",
      "Range: [645.7556, 872.5086], Actual Selectivity: 0.2268, NN Predicted Selectivity: 0.1110, LR Predicted Selectivity: 0.1125\n",
      "Range: [1549.1428, 1724.2458], Actual Selectivity: 0.0261, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0417\n",
      "Range: [736.1591, 1029.4630], Actual Selectivity: 0.3113, NN Predicted Selectivity: 0.1254, LR Predicted Selectivity: 0.1498\n",
      "Range: [458.7024, 998.0737], Actual Selectivity: 0.4925, NN Predicted Selectivity: 0.3222, LR Predicted Selectivity: 0.3140\n",
      "Range: [174.7567, 498.5660], Actual Selectivity: 0.1131, NN Predicted Selectivity: 0.2242, LR Predicted Selectivity: 0.1928\n",
      "Range: [1302.2184, 1828.2184], Actual Selectivity: 0.1310, NN Predicted Selectivity: 0.1494, LR Predicted Selectivity: 0.2694\n",
      "Range: [1493.9656, 1709.1440], Actual Selectivity: 0.0390, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0689\n",
      "Range: [13.9978, 14.0022], Actual Selectivity: 0.0365, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0000\n",
      "Range: [875.5369, 905.6971], Actual Selectivity: 0.0329, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0000\n",
      "Range: [1633.5969, 1818.2787], Actual Selectivity: 0.0166, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0440\n",
      "Range: [1034.3739, 1082.3945], Actual Selectivity: 0.0476, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0000\n",
      "Range: [410.0826, 1328.0859], Actual Selectivity: 0.7900, NN Predicted Selectivity: 0.5821, LR Predicted Selectivity: 0.5504\n",
      "Range: [9.9978, 10.0022], Actual Selectivity: 0.0571, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0000\n",
      "Range: [17.9978, 18.0022], Actual Selectivity: 0.0617, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0000\n",
      "Range: [1397.6846, 1698.4784], Actual Selectivity: 0.0728, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.1260\n",
      "Range: [1579.5262, 1822.0439], Actual Selectivity: 0.0261, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0821\n",
      "Range: [837.9988, 1448.2814], Actual Selectivity: 0.5012, NN Predicted Selectivity: 0.2862, LR Predicted Selectivity: 0.3416\n",
      "Range: [1201.6833, 1413.6901], Actual Selectivity: 0.1251, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0795\n",
      "Range: [212.3341, 1387.9578], Actual Selectivity: 0.8804, NN Predicted Selectivity: 0.8744, LR Predicted Selectivity: 0.7183\n",
      "Range: [1741.3098, 1917.3885], Actual Selectivity: 0.0081, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0340\n",
      "Range: [169.5511, 1263.1232], Actual Selectivity: 0.8180, NN Predicted Selectivity: 0.8231, LR Predicted Selectivity: 0.6693\n",
      "Range: [734.4420, 1728.0677], Actual Selectivity: 0.6640, NN Predicted Selectivity: 0.6420, LR Predicted Selectivity: 0.5832\n",
      "Range: [101.8379, 536.2155], Actual Selectivity: 0.1463, NN Predicted Selectivity: 0.3605, LR Predicted Selectivity: 0.2644\n",
      "Range: [3.9978, 4.0022], Actual Selectivity: 0.0701, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0000\n",
      "Range: [1240.5490, 1289.8748], Actual Selectivity: 0.0327, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0000\n",
      "Range: [1382.5250, 1585.2885], Actual Selectivity: 0.0635, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0660\n",
      "Range: [18.9978, 19.0022], Actual Selectivity: 0.0444, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0000\n",
      "Range: [311.4922, 859.1036], Actual Selectivity: 0.4024, NN Predicted Selectivity: 0.3609, LR Predicted Selectivity: 0.3254\n",
      "Range: [375.7660, 804.5547], Actual Selectivity: 0.3218, NN Predicted Selectivity: 0.2594, LR Predicted Selectivity: 0.2491\n",
      "Range: [375.1016, 1544.6873], Actual Selectivity: 0.8870, NN Predicted Selectivity: 0.8430, LR Predicted Selectivity: 0.7075\n",
      "Range: [456.2251, 1748.9873], Actual Selectivity: 0.8790, NN Predicted Selectivity: 0.8690, LR Predicted Selectivity: 0.7803\n",
      "Range: [1125.7294, 1156.6654], Actual Selectivity: 0.0273, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0000\n",
      "Range: [4.9978, 5.0022], Actual Selectivity: 0.0534, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0000\n",
      "Range: [-0.0022, 0.0022], Actual Selectivity: 0.0477, NN Predicted Selectivity: 0.0723, LR Predicted Selectivity: 0.0000\n",
      "Range: [3.9978, 4.0022], Actual Selectivity: 0.0701, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0000\n",
      "Range: [1754.1021, 1835.1334], Actual Selectivity: 0.0045, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.0000\n",
      "Range: [683.4985, 1490.8774], Actual Selectivity: 0.6709, NN Predicted Selectivity: 0.4925, LR Predicted Selectivity: 0.4702\n",
      "Range: [1654.7096, 1950.9045], Actual Selectivity: 0.0177, NN Predicted Selectivity: 0.0721, LR Predicted Selectivity: 0.1121\n",
      "Range: [983.8475, 1312.4236], Actual Selectivity: 0.2799, NN Predicted Selectivity: 0.1097, LR Predicted Selectivity: 0.1610\n",
      "Range: [471.6146, 1967.0455], Actual Selectivity: 0.8793, NN Predicted Selectivity: 0.9425, LR Predicted Selectivity: 0.9050\n",
      "Range: [566.2136, 1376.2319], Actual Selectivity: 0.7236, NN Predicted Selectivity: 0.5278, LR Predicted Selectivity: 0.4768\n",
      "Range: [957.9086, 1857.8911], Actual Selectivity: 0.4340, NN Predicted Selectivity: 0.4989, LR Predicted Selectivity: 0.5157\n",
      "Range: [-193.2858, 422.4598], Actual Selectivity: 0.0953, NN Predicted Selectivity: 0.2188, LR Predicted Selectivity: 0.3893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train the models\n",
    "print(f\"Training NN model...\")\n",
    "train_NN(model, criterion, optimizer, data_loader, X_test_normalized, y_test, num_epochs, val_every=10)\n",
    "print(f\"Training LR model...\")\n",
    "train_lr(lr_model, train_data, test_data, val_every=1)\n",
    "\n",
    "# evaluate both models on the test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    test_loss = criterion(y_pred, y_test)\n",
    "    print(f\"NN Test loss: {test_loss.item()}\")\n",
    "\n",
    "# show side by side comparison of actual selectivity and predicted selectivity for all test data, along with the range\n",
    "y_pred_array = y_pred.numpy().flatten()\n",
    "y_test_array = y_test.numpy().flatten()\n",
    "X_test_array = X_test.numpy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    a, b = X_test_array[i]\n",
    "    lr_pred = lr_model.predict(X_test_array[i])\n",
    "    print(f\"Range: [{a:.4f}, {b:.4f}], Actual Selectivity: {y_test_array[i]:.4f}, NN Predicted Selectivity: {y_pred_array[i]:.4f}, LR Predicted Selectivity: {lr_pred:.4f}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Zipfian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skewed distribution - zipfian\n",
    "def zipfian_distribution(total_rows, min_value, max_value, x, skew=2):\n",
    "    a = min_value\n",
    "    b = max_value\n",
    "    k = skew\n",
    "    count = min(total_rows, total_rows / (0.1*(x-min_value))**k)\n",
    "    return count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_286261/2579596726.py:6: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  count = min(total_rows, total_rows / (0.1*(x-min_value))**k)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc8AAAGJCAYAAADsebhaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9f0lEQVR4nO3deVxU9f4/8NfMAAPIDsKAgeKGloqoRXjVUEnE3MpyyfVGapZL2na9NxWr+yNtM4207r1ilmbXvmrl7WpuiBmSGxpqXDEQFxATYRiU/fP7Q+fkCKgDM3Nmhtfz8ZjHg7PMOe9zFF9+zvmcz1EIIQSIiIjoninlLoCIiMjWMDyJiIiMxPAkIiIyEsOTiIjISAxPIiIiIzE8iYiIjMTwJCIiMhLDk4iIyEgMTyIiIiMxPKnZUygUSEhIaNR3q6ur8eqrryI4OBhKpRIjR45s8jYtbcqUKWjTpo1F9tWmTRtMmTJFml6zZg0UCgUOHTpkkf1HR0cjOjraIvsi+8bwJLujUCju+jFVsK1evRrvvPMOnnzySXz22WeYO3euSbbbWAkJCQbH6erqipCQEAwbNgzJycmoqKgwyX5OnjyJhIQE5ObmmmR7pmTNtZH9cJC7ACJT+/zzzxtclpCQgDNnziAyMlKad/36dTg4NO5XYffu3WjVqhU++OADg/lN2aYprFy5Em5ubqioqMCFCxewfft2PPPMM1i2bBm2bt2K4OBgad1//OMfqK2tNWr7J0+exOLFixEdHW1UqzUrKwtKpXn/z36n2n744Qez7puaD4Yn2Z0JEybUO/+f//wnzpw5g1mzZiEuLk6a7+zs3Oh9FRYWwsvLq878pmzTFJ588kn4+flJ0wsXLsS6deswadIkPPXUUzhw4IC0zNHR0ay1CCFQXl4OFxcXqNVqs+7rbpycnGTdP9kPXralZuHEiROYPXs2IiIi8M477xgsu/0yrv7S56+//orRo0fDw8MDvr6+mDNnDsrLywEAubm5UCgU2LNnD06cOCFdJk1JSal3m2fPnsXzzz+PsLAwuLi4wNfXF0899VSdS4v6e4D79+/HvHnz0LJlS7Ro0QKPP/44Ll++3KRzMH78eDz77LNIT0/Hjh07pPn13fPcsGEDevbsCXd3d3h4eKBr16748MMPpRqfeuopAED//v3rHHubNm0wdOhQbN++Hb169YKLiws++eQTadmt9zz1rl27hunTp8PX1xceHh6YNGkSrl69arBOQ5fbb93m3Wqr755nYWEh4uPjERAQAGdnZ4SHh+Ozzz4zWEf/5/3uu+/i008/Rbt27aBWq/Hggw/i4MGD9Z5vsm9seZLdu3btGkaPHg2VSoUNGzbcc+tn9OjRaNOmDRITE3HgwAEsX74cV69exdq1a9GyZUt8/vnn+Pvf/w6dTofExEQAQOfOnevd1sGDB/HTTz9h7NixuO+++5Cbm4uVK1ciOjoaJ0+ehKurq8H6s2bNgre3NxYtWoTc3FwsW7YMM2fOxFdffdWkczFx4kR8+umn+OGHH/Doo4/Wu86OHTswbtw4DBw4EEuWLAEAnDp1Cvv378ecOXPQr18/zJ49G8uXL8df//pX6ZhvPfasrCyMGzcO06dPx9SpUxEWFnbHumbOnAkvLy8kJCQgKysLK1euxNmzZ5GSkgKFQnHPx3cvtd3q+vXriI6ORnZ2NmbOnInQ0FBs3LgRU6ZMQXFxMebMmWOw/vr161FaWorp06dDoVBg6dKleOKJJ/Dbb7+ZvQVPVkYQ2blnnnlGABCfffZZvcsBiEWLFknTixYtEgDE8OHDDdZ7/vnnBQBx7Ngxad4jjzwiHnjggbtu89q1a3XWSUtLEwDE2rVrpXnJyckCgIiJiRG1tbXS/Llz5wqVSiWKi4vveKz62i9fvlzv8qtXrwoA4vHHH5fmTZ48WbRu3VqanjNnjvDw8BDV1dUN7mfjxo0CgNizZ0+dZa1btxYAxLZt2+pdNnnyZGlaf7w9e/YUlZWV0vylS5cKAOKbb76R5t1+Thva5p1qe+SRR8QjjzwiTS9btkwAEF988YU0r7KyUkRFRQk3Nzeh1WqFEELk5OQIAMLX11cUFRVJ637zzTcCgPjuu+/q7IvsGy/bkl1bv349Vq9ejYkTJ2LSpElGffeFF14wmJ41axYA4Pvvvze6DhcXF+nnqqoqXLlyBe3bt4eXlxeOHDlSZ/1p06YZtLj69u2LmpoanD171uh938rNzQ0AUFpa2uA6Xl5eKCsrM7i0a6zQ0FDExsbe8/rTpk0zaLnNmDEDDg4OjTrXxvj++++h0Wgwbtw4aZ6joyNmz54NnU6HvXv3Gqw/ZswYeHt7S9N9+/YFAPz2229mrZOsD8OT7Nbp06fx3HPPoWPHjvj444+N/n6HDh0Mptu1awelUtmoRyCuX7+OhQsXIjg4GGq1Gn5+fmjZsiWKi4tRUlJSZ/2QkBCDaf0/2LffBzSWTqcDALi7uze4zvPPP4+OHTsiLi4O9913H5555hls27bNqP2EhoYatf7t59rNzQ2BgYFmf9zk7Nmz6NChQ50ewPrLvLf/Z8Vcfy5kexieZJcqKiowZswYVFZWYsOGDVKLqymMufd2u1mzZuHvf/87Ro8ejX//+9/44YcfsGPHDvj6+tb7mIhKpap3O0KIRtcAAJmZmQCA9u3bN7iOv78/MjIy8O2332L48OHYs2cP4uLiMHny5Hvez60tbXOrqamx2L7M9edCtofhSXbp5ZdfxtGjR7F06VJEREQ0ahunT582mM7OzkZtbW2jRuP5+uuvMXnyZLz33nt48skn8eijj6JPnz4oLi5uVG2NpX8G9m6XVJ2cnDBs2DB8/PHHOHPmDKZPn461a9ciOzsbQNP+I1Gf28+1TqdDfn6+wbn29vauc74qKyuRn59vMM+Y2lq3bo3Tp0/X+Q/Mr7/+Ki0nqg/Dk+zO5s2b8dFHH2H48OGYPXt2o7eTlJRkML1ixQoAMHhG9F6pVKo6rZMVK1ZYtNW0fv16/POf/0RUVBQGDhzY4HpXrlwxmFYqlejWrRsASCMUtWjRAgBMFv6ffvopqqqqpOmVK1eiurra4Fy3a9cOqampdb53+zk0prYhQ4agoKDAoBdzdXU1VqxYATc3NzzyyCONORxqBvioCtmV/Px8xMfHQ6VSYeDAgfjiiy/qXa9du3aIioq647ZycnIwfPhwDB48GGlpafjiiy/w9NNPIzw83Oi6hg4dis8//xyenp64//77kZaWhp07d8LX19fobd2Lr7/+Gm5ubqisrJRGGNq/fz/Cw8OxcePGO3732WefRVFREQYMGID77rsPZ8+exYoVK9C9e3fpXmD37t2hUqmwZMkSlJSUQK1WY8CAAfD3929UvZWVlRg4cCBGjx6NrKwsfPzxx+jTpw+GDx9uUNdzzz2HUaNG4dFHH8WxY8ewfft2g8EgjK1t2rRp+OSTTzBlyhQcPnwYbdq0wddff439+/dj2bJld7w3TM0bw5PsSlZWltR54/Zn9G41efLku4bnV199hYULF+Ivf/kLHBwcMHPmzDoDLNyrDz/8ECqVCuvWrUN5eTn+9Kc/YefOnUb1SDXGjBkzANwY6cjPzw/du3fH6tWr8fTTT9/1OdcJEybg008/xccff4zi4mJoNBqMGTMGCQkJUscajUaDVatWITExEfHx8aipqcGePXsaHZ4fffQR1q1bh4ULF6Kqqgrjxo3D8uXLDS7BTp06FTk5OfjXv/6Fbdu2oW/fvtixY0edVrQxtbm4uCAlJQV/+ctf8Nlnn0Gr1SIsLAzJycn1DuZApKcQvNNNZCAhIQGLFy/G5cuX67RqiIgA3vMkIiIyGsOTiIjISAxPIiIiI/GeJxERkZHY8iQiIjISw5OIiMhIfM4TQG1tLS5evAh3d3eTDztGRES2QQiB0tJSBAUF1XlZQH0ry2bv3r1i6NChIjAwUAAQmzdvlpZVVlaKV199VXTp0kW4urqKwMBAMXHiRHHhwgWDbejfHXjrJzEx0ag6zp07V2cb/PDDDz/8NM/PuXPn7pobsrY8y8rKEB4ejmeeeQZPPPGEwbJr167hyJEjWLBgAcLDw3H16lXMmTMHw4cPx6FDhwzWfeONNzB16lRp2tghtfTrnzt3Dh4eHo08GiIismVarRbBwcH3lCGyhmdcXFyDg2x7enrWeRnvRx99hIceegh5eXkG79Vzd3eHRqNpdB36S7UeHh4MTyKiZu5ebt/ZVIehkpISKBQKeHl5Gcx/++234evri4iICLzzzjuorq6+43YqKiqg1WoNPkRERPfKZjoMlZeX47XXXsO4ceMMWoezZ89Gjx494OPjg59++gnz589Hfn4+3n///Qa3lZiYiMWLF1uibCIiskNWM0iCQqHA5s2bMXLkyDrLqqqqMGrUKJw/fx4pKSl3vLS6evVqTJ8+HTqdrsG3R1RUVEjvJQT+uM5dUlLCy7ZERM2UVquFp6fnPWWB1bc8q6qqMHr0aJw9exa7d+++6wFFRkaiuroaubm5CAsLq3cdtVp919cyERERNcSqw1MfnKdPn8aePXvu6cXBGRkZUCqVjX6vIBER0d3IGp46nQ7Z2dnSdE5ODjIyMuDj44PAwEA8+eSTOHLkCLZu3YqamhoUFBQAAHx8fODk5IS0tDSkp6ejf//+cHd3R1paGubOnYsJEybA29tbrsMiIiI7J+s9z5SUFPTv37/O/MmTJyMhIQGhoaH1fm/Pnj2Ijo7GkSNH8Pzzz+PXX39FRUUFQkNDMXHiRMybN8+oy7LGXOcmIiL7ZEwWWE2HITkxPImIyJgssKnnPImIiKyBVXcYsiUZ54pRUHIdABDo6YLwYC95CyIiIrNheJrI6h9z8O2xi9L01ll90KWVp4wVERGRufCyrYmE+rVAr9beaOGkAgDkl5TLXBEREZkLw9NE5j7aEV/P6I1OgTduMtfUNvt+WEREdovhaWKqm6Px17ITMxGR3WJ4mpj+5eNseRIR2S+Gp4mplGx5EhHZO4aniSlvXrZly5OIyH4xPE1M3/JkeBIR2S+Gp4mxwxARkf1jeJqY4mZ4/lpQKnMlRERkLgxPEysqqwAAFGorZK6EiIjMheFpYpFtb7yw28mBp5aIyF7xX3gT823hBIAdhoiI7BnD08Sk3rbsMEREZLcYniYmDZLAlicRkd1ieJoYB0kgIrJ/DE8T4/B8RET2j+FpYiq2PImI7B7D08SUUochmQshIiKzYXiamOrmGU3932UIXrolIrJLDE8Ta+PbQvq5mpduiYjsEsPTxNr7u0k/874nEZF9YniamL63LcAet0RE9orhaWL65zwBtjyJiOwVw9PEDFqetTIWQkREZsPwNDHVrS1PXrYlIrJLDE8TUyp52ZaIyN4xPM2AQ/QREdk3hqcZ6C/dVlbzpicRkT1ieJpB9c2eQv/5JV/mSoiIyBwYnmbg7KgCwJYnEZG9YniawRM9WgFghyEiInvF8DQD/T1PdhgiIrJPDE8zkF5LxpYnEZFdYniagfRCbLY8iYjskqzhmZqaimHDhiEoKAgKhQJbtmyRllVVVeG1115D165d0aJFCwQFBWHSpEm4ePGiwTaKioowfvx4eHh4wMvLC/Hx8dDpdBY+EkPSc55seRIR2SVZw7OsrAzh4eFISkqqs+zatWs4cuQIFixYgCNHjmDTpk3IysrC8OHDDdYbP348Tpw4gR07dmDr1q1ITU3FtGnTLHUI9frjsq2sZRARkZk4yLnzuLg4xMXF1bvM09MTO3bsMJj30Ucf4aGHHkJeXh5CQkJw6tQpbNu2DQcPHkSvXr0AACtWrMCQIUPw7rvvIigoyOzHUB92GCIism82dc+zpKQECoUCXl5eAIC0tDR4eXlJwQkAMTExUCqVSE9Pb3A7FRUV0Gq1Bh9T0rc8vzhw1qTbJSIi62Az4VleXo7XXnsN48aNg4eHBwCgoKAA/v7+Bus5ODjAx8cHBQUFDW4rMTERnp6e0ic4ONiktXq6OAIAqmsFKqprTLptIiKSn02EZ1VVFUaPHg0hBFauXNnk7c2fPx8lJSXS59y5cyao8g9P9rhP+rm6hpduiYjsjaz3PO+FPjjPnj2L3bt3S61OANBoNCgsLDRYv7q6GkVFRdBoNA1uU61WQ61Wm61mteMf/yfh4ypERPbHqlue+uA8ffo0du7cCV9fX4PlUVFRKC4uxuHDh6V5u3fvRm1tLSIjIy1drkR1yzs9+bgKEZH9kbXlqdPpkJ2dLU3n5OQgIyMDPj4+CAwMxJNPPokjR45g69atqKmpke5j+vj4wMnJCZ07d8bgwYMxdepUrFq1ClVVVZg5cybGjh0rW09b4I/etgBHGSIiskeyhuehQ4fQv39/aXrevHkAgMmTJyMhIQHffvstAKB79+4G39uzZw+io6MBAOvWrcPMmTMxcOBAKJVKjBo1CsuXL7dI/Q1R3tLy5GVbIiL7I2t4RkdHQ9whXO60TM/Hxwfr1683ZVkmoVIqUFMrUMuBEoiI7I5V3/O0ZRzflojIfjE8zUR588yywxARkf1heJqJvuWZvD9X3kKIiMjkGJ5mUnWzxXn2SpnMlRARkakxPM3krZFdAPCeJxGRPWJ4monUYYj3PImI7A7D00ykF2Kz5UlEZHcYnmbyxwuxGZ5ERPaG4Wkm0guxOUgCEZHdYXiaiermmWWHISIi+8PwNBPVzVESeNmWiMj+MDzNRN/yzDhXjMpqXrslIrInDE8zcXZQST//35HzMlZCRESmxvA0k15tfKSfC7UVMlZCRESmxvA0EycHJSY+3BoAOw0REdkbhqcZSQMlsNMQEZFdYXiakZLv9CQisksMTzNS8Z2eRER2ieFpRhyij4jIPjE8zUjFy7ZERHaJ4WlG7DBERGSfGJ5mpO8w9FnaWRSWlstcDRERmQrD04w0ns7Szz+cuCRjJUREZEoMTzN6sud9cHd2AABUcHxbIiK7wfA0I0eVEjGdAwDwvicRkT1heJoZB0ogIrI/DE8zk16KzZYnEZHdYHiaGR9XISKyPwxPM+NlWyIi+8PwNDO2PImI7A/D08z0LU9tebXMlRARkakwPM1M3/Jc81Muvv8lX+ZqiIjIFBieZtang5/086HcqzJWQkREpsLwNLP+Yf54ProdAKCWnYaIiOwCw9MCHPSdhhieRER2geFpAXwpNhGRfWF4WoD+pdhseRIR2QeGpwWw5UlEZF9kDc/U1FQMGzYMQUFBUCgU2LJli8HyTZs2YdCgQfD19YVCoUBGRkadbURHR0OhUBh8nnvuOcscwD1SSeEpcyFERGQSsoZnWVkZwsPDkZSU1ODyPn36YMmSJXfcztSpU5Gfny99li5dao5yG42XbYmI7IuDnDuPi4tDXFxcg8snTpwIAMjNzb3jdlxdXaHRaExZmknpL9tuPnoBswa0R9uWbjJXRERETWEX9zzXrVsHPz8/dOnSBfPnz8e1a9fuuH5FRQW0Wq3Bx5xcHFXSz899cdis+yIiIvOTteVpCk8//TRat26NoKAgHD9+HK+99hqysrKwadOmBr+TmJiIxYsXW6zGuC4abMm4gJ9zinBFV2mx/RIRkXnYfHhOmzZN+rlr164IDAzEwIEDcebMGbRr167e78yfPx/z5s2TprVaLYKDg81Wo3cLJ/x9ZBc8+kEqX01GRGQHbD48bxcZGQkAyM7ObjA81Wo11Gq1Jcvi4ypERHbELu553kr/OEtgYKC8hdxG6nHL8CQisnmytjx1Oh2ys7Ol6ZycHGRkZMDHxwchISEoKipCXl4eLl68CADIysoCAGg0Gmg0Gpw5cwbr16/HkCFD4Ovri+PHj2Pu3Lno168funXrJssxNUR61pOXbYmIbJ6sLc9Dhw4hIiICERERAIB58+YhIiICCxcuBAB8++23iIiIwGOPPQYAGDt2LCIiIrBq1SoAgJOTE3bu3IlBgwahU6dOeOmllzBq1Ch899138hzQHegv29ZyoAQiIpunEIJNIa1WC09PT5SUlMDDw8Ms+ygoKcfDibugUipw5v8NMcs+iIio8YzJAru752mtlDfPNDsMERHZPoanheg7DAHApNU/I7uwVMZqiIioKRieFuLm7AB35xv9s1L/dxlbjl6UuSIiImoshqeFqB1U+M+svojpHAAAqOQrVoiIbBbD04JCfF3Rzr8FAD7vSURkyxieFqa/98nnPYmIbBfD08JUSo40RERk6xieFqZky5OIyOYxPC1MGqaP/YWIiGwWw9PCeNmWiMj2MTwtTH/ZVldRjZJrVTJXQ0REjcHwtDDVzTP+n1/y0eOtHUjJKpS3ICIiMhrD08J6t/NDS3c1FIob49z+cr5E7pKIiMhIDE8L69LKEwf/FoOnHwoBwF63RES2iOEpE3YcIiKyXQxPmfB5TyIi28XwlAmf9yQisl0MT5lIl23Z8iQisjkMT5lIl215z5OIyOYwPGWif96T4UlEZHsYnjLRv5rslwsl+Efqb8j5vUzmioiI6F45yF1Ac+WqvnHqD5+9isNnr2LbiQL834zeMldFRET3guEpk1E97kNBSTlyfi/D3v9dxtWySrlLIiKie8TLtjJp6a5GwvAHMGtAewB83pOIyJYwPGWm5CMrREQ2h+EpM33HoVoOlkBEZDMYnjL7Y6QhtjyJiGwFw1NmHOOWiMj2NCo827ZtiytXrtSZX1xcjLZt2za5qOaEb1chIrI9jQrP3Nxc1NTU1JlfUVGBCxcuNLmo5kQaaYgtTyIim2HUc57ffvut9PP27dvh6ekpTdfU1GDXrl1o06aNyYprDvSXbbXXqzB0xT44qpR46dEw9OngJ3NlRETUEKPCc+TIkQAAhUKByZMnGyxzdHREmzZt8N5775msuObAz10NZ0clyqtqkXlBCwBY//NZhicRkRUzKjxrbz5PERoaioMHD8LPj//AN5WHsyN2zH0EZy7rsPd/l5G8PxeV1byES0RkzRo1PF9OTo6p62jWgn1cEezjikJtBQAOmEBEZO0aPbbtrl27sGvXLhQWFkotUr3Vq1c3ubDmSMlnPomIbEKjwnPx4sV444030KtXLwQGBkJxs9MLNY2+5y1bnkRE1q1R4blq1SqsWbMGEydONHU9zZo0YAJbnkREVq1Rz3lWVlaid++mv3syNTUVw4YNQ1BQEBQKBbZs2WKwfNOmTRg0aBB8fX2hUCiQkZFRZxvl5eV44YUX4OvrCzc3N4waNQqXLl1qcm1y4FB9RES2oVHh+eyzz2L9+vVN3nlZWRnCw8ORlJTU4PI+ffpgyZIlDW5j7ty5+O6777Bx40bs3bsXFy9exBNPPNHk2uQgDRLPy7ZERFatUZdty8vL8emnn2Lnzp3o1q0bHB0dDZa///7797SduLg4xMXFNbhcf1k4Nze33uUlJSX417/+hfXr12PAgAEAgOTkZHTu3BkHDhzAww8/fE91WAt9h6Gyihr8dlkHAAj0dIGLk0rOsoiI6DaNCs/jx4+je/fuAIDMzEyDZZbsPHT48GFUVVUhJiZGmtepUyeEhIQgLS2twfCsqKhARUWFNK3Vas1e671wuBmeJ/O1GPDeXgCAv7saqa/2h7MjA5SIyFo0Kjz37Nlj6joapaCgAE5OTvDy8jKYHxAQgIKCgga/l5iYiMWLF5u5OuNFhHgjLMAdF0uuAwBKy6tRWFqB33UVuM/bVebqiIhIr1m+kmz+/PkoKSmRPufOnZO7JACATwsnbJ/bD78kxOKXhFi43rxcyxdlExFZl0a1PPv373/Hy7O7d+9udEHG0Gg0qKysRHFxsUHr89KlS9BoNA1+T61WQ61WW6DCplHxXZ9ERFapUeGpv9+pV1VVhYyMDGRmZtYZMN6cevbsCUdHR+zatQujRo0CAGRlZSEvLw9RUVEWq8NcOOIQEZF1alR4fvDBB/XOT0hIgE6nu+ft6HQ6ZGdnS9M5OTnIyMiAj48PQkJCUFRUhLy8PFy8eBHAjWAEbrQ4NRoNPD09ER8fj3nz5sHHxwceHh6YNWsWoqKibK6nbX2kF2Wz5UlEZFVMes9zwoQJRo1re+jQIURERCAiIgIAMG/ePERERGDhwoUAbrw/NCIiAo899hgAYOzYsYiIiMCqVaukbXzwwQcYOnQoRo0ahX79+kGj0WDTpk0mPCr5cMQhIiLr1OiB4euTlpYGZ2fne14/Ojoa4g6tqilTpmDKlCl33IazszOSkpIaHGjBlunHumV4EhFZl0aF5+0j+AghkJ+fj0OHDmHBggUmKYw44hARkbVqVHh6enoaTCuVSoSFheGNN97AoEGDTFIY/dFh6Muf87Dn18sAgCAvZzzZ8z6+yYaISEaNCs/k5GRT10H1cFPf+OP58mfD51DbtnRDz9becpRERERo4j3Pw4cP49SpUwCABx54QOr4Q6bxxogu+PbYBeiv2m7LLMCVskqUXK+UtzAiomauUeFZWFiIsWPHIiUlRRqcoLi4GP3798eGDRvQsmVLU9bYbD0U6oOHQn2k6RMXtbhSVokajjhERCSrRj2qMmvWLJSWluLEiRMoKipCUVERMjMzodVqMXv2bFPXSDfxfZ9ERNahUS3Pbdu2YefOnejcubM07/7770dSUhI7DJkRe98SEVmHRrU8a2tr67zDEwAcHR1Ry1HMzUbJ5z6JiKxCo8JzwIABmDNnjjRsHgBcuHABc+fOxcCBA01WHBnicH1ERNahUeH50UcfQavVok2bNmjXrh3atWuH0NBQaLVarFixwtQ10k0cro+IyDo06p5ncHAwjhw5gp07d+LXX38FAHTu3BkxMTEmLY4MscMQEZF1UIg7DS57m927d2PmzJk4cOAAPDw8DJaVlJSgd+/eWLVqFfr27WvyQs1Jq9XC09MTJSUldY7LmsSvOYhdvxbC310ND5c/7jkHeKixYlwP+LRwkrE6IiLbZkwWGHXZdtmyZZg6dWq9G/X09MT06dPx/vvvG1ct3bPWvi0AAIWlFcgu1Emf/dlXkHbmiszVERE1H0Zdtj127BiWLFnS4PJBgwbh3XffbXJRVL+/DumEx7oFouqWURL+/p9T+OVCCarZy5mIyGKMCs9Lly7V+4iKtDEHB1y+fLnJRVH9HFTKOmPaerne+PPgfVAiIssx6rJtq1atkJmZ2eDy48ePIzAwsMlF0b1jJyIiIsszKjyHDBmCBQsWoLy8vM6y69evY9GiRRg6dKjJiqO746hDRESWZ9Rl29dffx2bNm1Cx44dMXPmTISFhQEAfv31VyQlJaGmpgZ/+9vfzFIo1U8ptTxlLoSIqBkxKjwDAgLw008/YcaMGZg/fz70T7koFArExsYiKSkJAQEBZimU6qdvedaw5UlEZDFGD5LQunVrfP/997h69Sqys7MhhECHDh3g7c2XM8tBGrKP9zyJiCym0S/D9vb2xoMPPmjKWqgR9JdtL5Zcx6l8rcEyd2cH3OftKkdZRER2rdHhSdbB4WZ4frL3N3yy97c6y1dN6IHBXdgDmojIlBo1MDxZj6HdAhHs44KW7mqDj7PjjT/arAKdzBUSEdkftjxt3MDOARjYuW4nrQVbMvH5gbPsSEREZAZsedopdiQiIjIfhqedUvIRFiIis2F42inVzT9ZtjyJiEyP4WmnlBzzlojIbBiedoojDxERmQ/D006xwxARkfnwURU7pe8wdOjsVSzZ9mu96/Tt4Ife7fwsWRYRkV1geNopd+cbf7QnLmpx4qK23nU2/JyHowsHWbIsIiK7wPC0U0/1DIauohra69V1ll2rrMaGg+egLa+7jIiI7o7haac8XR3xYkzHepcVlpZjw8Fz7IlLRNRI7DDUDOl74gLsUERE1BgMz2ZI3xMX4KMsRESNwfBshpS3hGctw5OIyGiyhmdqaiqGDRuGoKAgKBQKbNmyxWC5EAILFy5EYGAgXFxcEBMTg9OnTxus06ZNGygUCoPP22+/bcGjsD2Gl21lLISIyEbJGp5lZWUIDw9HUlJSvcuXLl2K5cuXY9WqVUhPT0eLFi0QGxuL8vJyg/XeeOMN5OfnS59Zs2ZZonybxcu2RERNI2tv27i4OMTFxdW7TAiBZcuW4fXXX8eIESMAAGvXrkVAQAC2bNmCsWPHSuu6u7tDo9FYpGZ7oLyl5cket0RExrPaR1VycnJQUFCAmJgYaZ6npyciIyORlpZmEJ5vv/023nzzTYSEhODpp5/G3Llz4eDQ8KFVVFSgoqJCmtZq6x9EwF7d2vKMW5ZqcA/0dhEh3lg+tjsUiobXISJqbqw2PAsKCgAAAQEBBvMDAgKkZQAwe/Zs9OjRAz4+Pvjpp58wf/585Ofn4/33329w24mJiVi8eLF5CrcBSgUQ6tcCOb+X4WJJ+R3XPX/1Ov42pDM0ns4Wqo6IyPpZbXjeq3nz5kk/d+vWDU5OTpg+fToSExOhVqvr/c78+fMNvqfVahEcHGz2Wq2FQqHA1ll9cLpQd8f1Rq9KQ2VNLarZq4iIyIDVhqf+HualS5cQGBgozb906RK6d+/e4PciIyNRXV2N3NxchIWF1buOWq1uMFibixZqB3QP9rrjOg4qBSpr2COXiOh2VvucZ2hoKDQaDXbt2iXN02q1SE9PR1RUVIPfy8jIgFKphL+/vyXKtGt8JygRUf1kbXnqdDpkZ2dL0zk5OcjIyICPjw9CQkLw4osv4q233kKHDh0QGhqKBQsWICgoCCNHjgQApKWlIT09Hf3794e7uzvS0tIwd+5cTJgwAd7e3jIdlf3QdyRij1wiIkOyhuehQ4fQv39/aVp/H3Ly5MlYs2YNXn31VZSVlWHatGkoLi5Gnz59sG3bNjg73+i8olarsWHDBiQkJKCiogKhoaGYO3euwf1MajzphdpseRIRGVAIwX8ZtVotPD09UVJSAg8PD7nLsRq93tqJ33UV+O+cvugcyPNCRPbNmCyw2nueJD/Vzb8dvGxLRGTIanvbkvz0HYZO5WtRVXP3LrcaT2cEerqYuywiItkxPKlBDjebnq98ffye1lcqgF0vRSPUr4U5yyIikh3Dkxo08eHW+PzAWQjc/bJtQUk5qmoEcq+UMTyJyO4xPKlBU/u1xdR+be9p3eEf/Yjj50tQy/ujRNQMsMMQmYT+TS3sXEREzQHDk0yCz4QSUXPC8CSTkIby4zi4RNQMMDzJJJQ3/yax5UlEzQHDk0yCl22JqDlheJJJsMMQETUnfFSFTELf8tx89AJ+uVBi1Hf7h/mjX8eW5iiLiMgsGJ5kEp4ujgCAfad/x77Tvxv13W8zLuLwgkfNURYRkVkwPMkkXh4Uhja+Le5pDFw9XUU11qadRWlFtRkrIyIyPYYnmUSwjyvmPtrRqO8UlJRjbdpZjkpERDaHHYZINvrHW2rYQ5eIbAzDk2SjH1hBCIDvZCciW8LwJNnoe+gCfMSFiGwLw5Nko7w1PNnyJCIbwvAk2egv2wJALcfEJSIbwvAk2ajY8iQiG8VHVUg2yltano8s3QPFLdPGcFAqMPfRDhjzYIipSiMiuiOGJ8nGUaVA25Yt8NvlMlwpq2zStjYducDwJCKLYXiSbBQKBb6f3Re5V8oavY392Vfw5taT7K1LRBbF8CRZOTuq0Enj0ejv5125BoD3TInIsthhiGya9B5RtjyJyIIYnmTT9M+KsuVJRJbE8CSbppJewi1zIUTUrDA8yabxsi0RyYHhSTZN/6woL9sSkSWxty3ZNH3Ls6yiGmlnrphsu75uTugY4G6y7RGRfWF4kk1zUN0Iz/yScoz7xwGTbnvNnx9EdJi/SbdJRPaB4Uk2rUuQJx69PwC5vzd+oIXb5ZeUQ1dRjbyiaybbJhHZF4Yn2TQnByX+MamXSbf5wvoj+M/xfI5aREQNYochotv88fgLw5OI6sfwJLqN9PgLe/ASUQMYnkS3UXLgBSK6C4Yn0W1UN38r2PIkoobIGp6pqakYNmwYgoKCoFAosGXLFoPlQggsXLgQgYGBcHFxQUxMDE6fPm2wTlFREcaPHw8PDw94eXkhPj4eOp3OgkdB9oajFhHR3cganmVlZQgPD0dSUlK9y5cuXYrly5dj1apVSE9PR4sWLRAbG4vy8nJpnfHjx+PEiRPYsWMHtm7ditTUVEybNs1Sh0B2iKMWEdHdKISwjn8hFAoFNm/ejJEjRwK40eoMCgrCSy+9hJdffhkAUFJSgoCAAKxZswZjx47FqVOncP/99+PgwYPo1evG4wrbtm3DkCFDcP78eQQFBdW7r4qKClRUVEjTWq0WwcHBKCkpgYdH498tSfZh4TeZWJt2Fl1aeaDbfV5m248CwLDwIDzc1tds+yCie6fVauHp6XlPWWC1z3nm5OSgoKAAMTEx0jxPT09ERkYiLS0NY8eORVpaGry8vKTgBICYmBgolUqkp6fj8ccfr3fbiYmJWLx4sdmPgWyTl6sTACDzghaZF7Rm3deh3KvYPrefWfdBRKZnteFZUFAAAAgICDCYHxAQIC0rKCiAv7/h8GkODg7w8fGR1qnP/PnzMW/ePGla3/IkAoBn/tQGHs4OuFZZY7Z9FGjLsT49D7qKarPtg4jMx2rD05zUajXUarXcZZCV8nJ1wrN925p1H7+cL8H69Dz26CWyUVb7qIpGowEAXLp0yWD+pUuXpGUajQaFhYUGy6urq1FUVCStQ2SNlDd/8ziKEZFtstrwDA0NhUajwa5du6R5Wq0W6enpiIqKAgBERUWhuLgYhw8fltbZvXs3amtrERkZafGaie4VRzEism2yXrbV6XTIzs6WpnNycpCRkQEfHx+EhITgxRdfxFtvvYUOHTogNDQUCxYsQFBQkNQjt3Pnzhg8eDCmTp2KVatWoaqqCjNnzsTYsWMb7GlLZA04fi6RbZM1PA8dOoT+/ftL0/pOPJMnT8aaNWvw6quvoqysDNOmTUNxcTH69OmDbdu2wdnZWfrOunXrMHPmTAwcOBBKpRKjRo3C8uXLLX4sRMZQKhmeRLbMap7zlJMxz/YQmULu72WIfjcFbmoHZC6OlbscIoJxWWC19zyJ7JmKLU8im9YsH1Uhkpv+su31qhp0XbRdlho0ns7YMO1h+LrxsS0iYzE8iWTg5+YEjYczCrTlKJVpoITSQh2O5BXj0fsD7r4yERlgeBLJQO2gQsor0cgvKb/7ymYw68sjyLyg5WVjokZieBLJxNlRhVC/FrLs29Xxxq8+nzMlahx2GCJqhjjCEVHTMDyJmiGOcETUNAxPomZIyRGOiJqE4UnUDPE5U6KmYXgSNUP6sXV52ZaocdjblqgZ0g/ScCq/FHuyCu+ytuW19nFF25ZucpdB1CCGJ1Ez5KS6cdFpzU+5WPNTrrzF1EOpAH58bQCCvFzkLoWoXgxPomZofGQICrTlqKyulbuUOrIKSlFZU4v8knKGJ1kthidRM9S7vR96t/eTu4x69X83BTm/l/F+LFk1dhgiIqty83YsewKTVWN4EpFVkQZwYHiSFWN4EpFVkQZw4GVbsmIMTyKyKhzAgWwBw5OIrArH3SVbwPAkIquikMbdlbkQojvgoypEZFVUN3vb/uvH3/DfzHx5i2kkD2dHzBzQHn5uarlLITNheBKRVfFpcSNwDvxWJHMlTdPKywVT+7WVuwwyE4YnEVmVN0Y8gKh2vqiptc3rtv/NLMDRvGJcq6yRuxQyI4YnEVmVIC8XxPcJlbuMRssruoajecV81MbOscMQEZEJSa9746M2do3hSURkQvrXvbHlad8YnkREJsSWZ/PA8CQiMiGOkNQ8MDyJiEyIl22bB4YnEZEJ6S/bMjvtGx9VISIyIX3L87O0XKxLPytzNZbh4eyIf0zuhR4h3nKXYjEMTyIiE+oe7AmVUoGaWoGqmubR/LxSVokfT//O8CQiosYZ0CkAR15/FNeqquUuxSLe2ZaFTUcvNLsOUgxPIiIT83R1hCcc5S7DItycb8RIc3uFHDsMERFRoykVzfPRHIYnERE1mqqZPprD8CQiokbTh2dzG1HJ6sOztLQUL774Ilq3bg0XFxf07t0bBw8elJZPmTIFCoXC4DN48GAZKyYiaj7+uGwrcyEWZvUdhp599llkZmbi888/R1BQEL744gvExMTg5MmTaNWqFQBg8ODBSE5Olr6jVvPt7URElqC62QRrbh2GrDo8r1+/jv/7v//DN998g379+gEAEhIS8N1332HlypV46623ANwIS41GI2epRETNkn5EpZzfy7AtM1/WWlq6q9GztY9F9mXV4VldXY2amho4OzsbzHdxccGPP/4oTaekpMDf3x/e3t4YMGAA3nrrLfj6+ja43YqKClRUVEjTWq3W9MUTETUDTg43mp57/3cZe/93WdZa+oe1RPKfH7LIvqw6PN3d3REVFYU333wTnTt3RkBAAL788kukpaWhffv2AG5csn3iiScQGhqKM2fO4K9//Svi4uKQlpYGlUpV73YTExOxePFiSx4KEZFdGhYehCN5xdBer5K7FHQIcLfYvhRCWPeF6jNnzuCZZ55BamoqVCoVevTogY4dO+Lw4cM4depUnfV/++03tGvXDjt37sTAgQPr3WZ9Lc/g4GCUlJTAw8PDbMdCRETWS6vVwtPT856ywOp727Zr1w579+6FTqfDuXPn8PPPP6Oqqgpt27atd/22bdvCz88P2dnZDW5TrVbDw8PD4ENERHSvrD489Vq0aIHAwEBcvXoV27dvx4gRI+pd7/z587hy5QoCAwMtXCERETUXVn3PEwC2b98OIQTCwsKQnZ2NV155BZ06dcKf//xn6HQ6LF68GKNGjYJGo8GZM2fw6quvon379oiNjZW7dCIislNW3/IsKSnBCy+8gE6dOmHSpEno06cPtm/fDkdHR6hUKhw/fhzDhw9Hx44dER8fj549e2Lfvn181pOIiMzG6jsMWYIxN4mJiMg+2VWHISIiImvD8CQiIjISw5OIiMhIDE8iIiIjMTyJiIiMxPAkIiIyktUPkmAJ+qd1+HYVIqLmS58B9/IEJ8MTQGlpKQAgODhY5kqIiEhupaWl8PT0vOM6HCQBQG1tLS5evAh3d3cobr7Y1dbo3wxz7tw5DvTQCDx/Tcdz2DQ8f01jivMnhEBpaSmCgoKgVN75riZbngCUSiXuu+8+ucswCb4lpml4/pqO57BpeP6apqnn724tTj12GCIiIjISw5OIiMhIDE87oVarsWjRIr5NppF4/pqO57BpeP6axtLnjx2GiIiIjMSWJxERkZEYnkREREZieBIRERmJ4UlERGQkhqedSEpKQps2beDs7IzIyEj8/PPPcpcku4SEBCgUCoNPp06dpOXl5eV44YUX4OvrCzc3N4waNQqXLl0y2EZeXh4ee+wxuLq6wt/fH6+88gqqq6stfSgWk5qaimHDhiEoKAgKhQJbtmwxWC6EwMKFCxEYGAgXFxfExMTg9OnTBusUFRVh/Pjx8PDwgJeXF+Lj46HT6QzWOX78OPr27QtnZ2cEBwdj6dKl5j40i7jb+ZsyZUqdv5ODBw82WKe5nr/ExEQ8+OCDcHd3h7+/P0aOHImsrCyDdUz1O5uSkoIePXpArVajffv2WLNmjfEFC7J5GzZsEE5OTmL16tXixIkTYurUqcLLy0tcunRJ7tJktWjRIvHAAw+I/Px86XP58mVp+XPPPSeCg4PFrl27xKFDh8TDDz8sevfuLS2vrq4WXbp0ETExMeLo0aPi+++/F35+fmL+/PlyHI5FfP/99+Jvf/ub2LRpkwAgNm/ebLD87bffFp6enmLLli3i2LFjYvjw4SI0NFRcv35dWmfw4MEiPDxcHDhwQOzbt0+0b99ejBs3TlpeUlIiAgICxPjx40VmZqb48ssvhYuLi/jkk08sdZhmc7fzN3nyZDF48GCDv5NFRUUG6zTX8xcbGyuSk5NFZmamyMjIEEOGDBEhISFCp9NJ65jid/a3334Trq6uYt68eeLkyZNixYoVQqVSiW3bthlVL8PTDjz00EPihRdekKZrampEUFCQSExMlLEq+S1atEiEh4fXu6y4uFg4OjqKjRs3SvNOnTolAIi0tDQhxI1/CJVKpSgoKJDWWblypfDw8BAVFRVmrd0a3P6Pf21trdBoNOKdd96R5hUXFwu1Wi2+/PJLIYQQJ0+eFADEwYMHpXX++9//CoVCIS5cuCCEEOLjjz8W3t7eBufwtddeE2FhYWY+IstqKDxHjBjR4Hd4/v5QWFgoAIi9e/cKIUz3O/vqq6+KBx54wGBfY8aMEbGxsUbVx8u2Nq6yshKHDx9GTEyMNE+pVCImJgZpaWkyVmYdTp8+jaCgILRt2xbjx49HXl4eAODw4cOoqqoyOG+dOnVCSEiIdN7S0tLQtWtXBAQESOvExsZCq9XixIkTlj0QK5CTk4OCggKDc+bp6YnIyEiDc+bl5YVevXpJ68TExECpVCI9PV1ap1+/fnBycpLWiY2NRVZWFq5evWqho5FPSkoK/P39ERYWhhkzZuDKlSvSMp6/P5SUlAAAfHx8AJjudzYtLc1gG/p1jP33kuFp437//XfU1NQY/GUBgICAABQUFMhUlXWIjIzEmjVrsG3bNqxcuRI5OTno27cvSktLUVBQACcnJ3h5eRl859bzVlBQUO951S9rbvTHfKe/awUFBfD39zdY7uDgAB8fH55XAIMHD8batWuxa9cuLFmyBHv37kVcXBxqamoA8Pzp1dbW4sUXX8Sf/vQndOnSBQBM9jvb0DparRbXr1+/5xr5VhWyW3FxcdLP3bp1Q2RkJFq3bo1///vfcHFxkbEyaq7Gjh0r/dy1a1d069YN7dq1Q0pKCgYOHChjZdblhRdeQGZmJn788Ue5S2kQW542zs/PDyqVqk6Ps0uXLkGj0chUlXXy8vJCx44dkZ2dDY1Gg8rKShQXFxusc+t502g09Z5X/bLmRn/Md/q7ptFoUFhYaLC8uroaRUVFPK/1aNu2Lfz8/JCdnQ2A5w8AZs6cia1bt2LPnj0Gr4o01e9sQ+t4eHgY9Z9qhqeNc3JyQs+ePbFr1y5pXm1tLXbt2oWoqCgZK7M+Op0OZ86cQWBgIHr27AlHR0eD85aVlYW8vDzpvEVFReGXX34x+Mdsx44d8PDwwP3332/x+uUWGhoKjUZjcM60Wi3S09MNzllxcTEOHz4srbN7927U1tYiMjJSWic1NRVVVVXSOjt27EBYWBi8vb0tdDTW4fz587hy5QoCAwMBNO/zJ4TAzJkzsXnzZuzevRuhoaEGy031OxsVFWWwDf06Rv972ZheUGRdNmzYINRqtVizZo04efKkmDZtmvDy8jLocdYcvfTSSyIlJUXk5OSI/fv3i5iYGOHn5ycKCwuFEDe6vYeEhIjdu3eLQ4cOiaioKBEVFSV9X9/tfdCgQSIjI0Ns27ZNtGzZ0q4fVSktLRVHjx4VR48eFQDE+++/L44ePSrOnj0rhLjxqIqXl5f45ptvxPHjx8WIESPqfVQlIiJCpKenix9//FF06NDB4FGL4uJiERAQICZOnCgyMzPFhg0bhKurq80/aiHEnc9faWmpePnll0VaWprIyckRO3fuFD169BAdOnQQ5eXl0jaa6/mbMWOG8PT0FCkpKQaP8ly7dk1axxS/s/pHVV555RVx6tQpkZSUxEdVmrMVK1aIkJAQ4eTkJB566CFx4MABuUuS3ZgxY0RgYKBwcnISrVq1EmPGjBHZ2dnS8uvXr4vnn39eeHt7C1dXV/H444+L/Px8g23k5uaKuLg44eLiIvz8/MRLL70kqqqqLH0oFrNnzx4BoM5n8uTJQogbj6ssWLBABAQECLVaLQYOHCiysrIMtnHlyhUxbtw44ebmJjw8PMSf//xnUVpaarDOsWPHRJ8+fYRarRatWrUSb7/9tqUO0azudP6uXbsmBg0aJFq2bCkcHR1F69atxdSpU+v8J7e5nr/6zhsAkZycLK1jqt/ZPXv2iO7duwsnJyfRtm1bg33cK76SjIiIyEi850lERGQkhicREZGRGJ5ERERGYngSEREZieFJRERkJIYnERGRkRieRERERmJ4EhERGYnhSUSIjo7Giy++KHcZRDaD4Ulk44YNG4bBgwfXu2zfvn1QKBQ4fvy4hasism8MTyIbFx8fjx07duD8+fN1liUnJ6NXr17o1q2bDJUR2S+GJ5GNGzp0KFq2bIk1a9YYzNfpdNi4cSNGjhyJcePGoVWrVnB1dUXXrl3x5Zdf3nGbCoUCW7ZsMZjn5eVlsI9z585h9OjR8PLygo+PD0aMGIHc3FzTHBSRlWN4Etk4BwcHTJo0CWvWrMGt73nYuHEjampqMGHCBPTs2RP/+c9/kJmZiWnTpmHixIn4+eefG73PqqoqxMbGwt3dHfv27cP+/fvh5uaGwYMHo7Ky0hSHRWTVGJ5EduCZZ57BmTNnsHfvXmlecnIyRo0ahdatW+Pll19G9+7d0bZtW8yaNQuDBw/Gv//970bv76uvvkJtbS3++c9/omvXrujcuTOSk5ORl5eHlJQUExwRkXVjeBLZgU6dOqF3795YvXo1ACA7Oxv79u1DfHw8ampq8Oabb6Jr167w8fGBm5sbtm/fjry8vEbv79ixY8jOzoa7uzvc3Nzg5uYGHx8flJeX48yZM6Y6LCKr5SB3AURkGvHx8Zg1axaSkpKQnJyMdu3a4ZFHHsGSJUvw4YcfYtmyZejatStatGiBF1988Y6XVxUKBW5/1W9VVZX0s06nQ8+ePbFu3bo6323ZsqXpDorISjE8iezE6NGjMWfOHKxfvx5r167FjBkzoFAosH//fowYMQITJkwAANTW1uJ///sf7r///ga31bJlS+Tn50vTp0+fxrVr16TpHj164KuvvoK/vz88PDzMd1BEVoqXbYnshJubG8aMGYP58+cjPz8fU6ZMAQB06NABO3bswE8//YRTp05h+vTpuHTp0h23NWDAAHz00Uc4evQoDh06hOeeew6Ojo7S8vHjx8PPzw8jRozAvn37kJOTg5SUFMyePbveR2aI7A3Dk8iOxMfH4+rVq4iNjUVQUBAA4PXXX0ePHj0QGxuL6OhoaDQajBw58o7bee+99xAcHIy+ffvi6aefxssvvwxXV1dpuaurK1JTUxESEoInnngCnTt3Rnx8PMrLy9kSpWZBIW6/sUFERER3xJYnERGRkRieRERERmJ4EhERGYnhSUREZCSGJxERkZEYnkREREZieBIRERmJ4UlERGQkhicREZGRGJ5ERERGYngSEREZ6f8D3pdj09BIDkIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_value = -200\n",
    "max_value = 2000\n",
    "total_rows = 10000000\n",
    "num_distinct_values = total_rows // 100\n",
    "\n",
    "# use distribution function to generate values and counts for histogram\n",
    "values = np.linspace(min_value, max_value, num_distinct_values)\n",
    "counts = np.array([zipfian_distribution(total_rows, min_value, max_value, x, skew=0.05) for x in values])\n",
    "\n",
    "# normaize the counts so that they are integers and sum to total_rows\n",
    "counts = total_rows * counts / np.sum(counts) \n",
    "counts = np.round(counts)\n",
    "\n",
    "histogram = dict(zip(values, counts))\n",
    "\n",
    "# plot the histogram\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.plot(values, counts)\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Zipfian Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 90, Number of testing samples: 60\n"
     ]
    }
   ],
   "source": [
    "# generate some data\n",
    "num_samples=150\n",
    "data = generate_range_predicate_samples_dist(total_rows, min_value, max_value, histogram, num_samples=num_samples, fraction_eq=0.2)\n",
    "\n",
    "# split into training and testing data\n",
    "train_size = int(0.6 * num_samples)\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "\n",
    "print(f\"Number of training samples: {len(train_data)}, Number of testing samples: {len(test_data)}\")\n",
    "\n",
    "X_train = torch.tensor([d[0] for d in train_data], dtype=torch.float32)\n",
    "y_train = torch.tensor([d[1] for d in train_data], dtype=torch.float32).view(-1, 1)\n",
    "X_test = torch.tensor([d[0] for d in test_data], dtype=torch.float32)\n",
    "y_test = torch.tensor([d[1] for d in test_data], dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# normalize the input data for NN\n",
    "X_train_normalized = X_train # (X_train - min_value) / (max_value - min_value)\n",
    "X_test_normalized = X_test # (X_test - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate NN and LR models\n",
    "num_epochs = 10000\n",
    "hidden_size = 32\n",
    "batch_size = 32\n",
    "l2_lambda = 0.0001 # l2 regularization parameter\n",
    "\n",
    "# instantiate the NN model, loss function, and optimizer\n",
    "model = SelectivityModel(hidden_size=hidden_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=l2_lambda)\n",
    "\n",
    "# Create a dataset and data loader\n",
    "dataset = TensorDataset(X_train_normalized, y_train)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)  \n",
    "\n",
    "# instantiate the LR model\n",
    "lr_model = SelectivityModelLR(table_name, column_name, lambda_reg=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 10000/10000 [00:19<00:00, 511.45it/s, Loss=0.2909, MAE=0.3171, Val Loss=0.1097, Val MAE=0.2352]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 90/90 [00:00<00:00, 1341.60it/s, Train loss=0.0022, Train MAE=0.0099, Val loss=0.0000, Val MAE=0.0047]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Test loss: 0.10967909544706345\n",
      "Range: [239.6909, 1731.7086], Actual Selectivity: 0.6674, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.6701\n",
      "Range: [-0.0022, 0.0022], Actual Selectivity: 0.0048, NN Predicted Selectivity: 0.0564, LR Predicted Selectivity: 0.0000\n",
      "Range: [189.3964, 619.5093], Actual Selectivity: 0.1984, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.1928\n",
      "Range: [157.7209, 1541.4644], Actual Selectivity: 0.6230, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.6217\n",
      "Range: [-155.2860, 101.8129], Actual Selectivity: 0.1268, NN Predicted Selectivity: 0.0317, LR Predicted Selectivity: 0.1161\n",
      "Range: [1028.8894, 1487.7338], Actual Selectivity: 0.2024, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.2031\n",
      "Range: [779.7436, 1410.0322], Actual Selectivity: 0.2799, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.2810\n",
      "Range: [171.1622, 1076.2080], Actual Selectivity: 0.4118, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.4064\n",
      "Range: [849.6814, 1611.7924], Actual Selectivity: 0.3365, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.3400\n",
      "Range: [10.9978, 11.0022], Actual Selectivity: 0.0042, NN Predicted Selectivity: 0.0073, LR Predicted Selectivity: 0.0000\n",
      "Range: [1404.6572, 1598.3495], Actual Selectivity: 0.0846, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.0827\n",
      "Range: [-77.1264, 659.9765], Actual Selectivity: 0.3453, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.3317\n",
      "Range: [1327.4481, 1469.4536], Actual Selectivity: 0.0624, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.0597\n",
      "Range: [887.7039, 1008.4155], Actual Selectivity: 0.0538, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.0515\n",
      "Range: [916.6349, 1155.1906], Actual Selectivity: 0.1061, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.1044\n",
      "Range: [342.8230, 799.0447], Actual Selectivity: 0.2078, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.2041\n",
      "Range: [-0.0022, 0.0022], Actual Selectivity: 0.0048, NN Predicted Selectivity: 0.0564, LR Predicted Selectivity: 0.0000\n",
      "Range: [-177.9619, 1211.0101], Actual Selectivity: 0.6433, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.6251\n",
      "Range: [1423.7241, 1954.9330], Actual Selectivity: 0.2311, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.2344\n",
      "Range: [9.9978, 10.0022], Actual Selectivity: 0.0057, NN Predicted Selectivity: 0.0089, LR Predicted Selectivity: 0.0000\n",
      "Range: [20.9978, 21.0022], Actual Selectivity: 0.0045, NN Predicted Selectivity: 0.0011, LR Predicted Selectivity: 0.0000\n",
      "Range: [1549.7371, 1785.1606], Actual Selectivity: 0.1027, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.1010\n",
      "Range: [760.7758, 1289.4286], Actual Selectivity: 0.2352, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.2353\n",
      "Range: [1439.8707, 1848.9730], Actual Selectivity: 0.1783, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.1795\n",
      "Range: [1186.6261, 1746.1975], Actual Selectivity: 0.2452, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.2479\n",
      "Range: [731.5384, 1929.6823], Actual Selectivity: 0.5277, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.5365\n",
      "Range: [14.9978, 15.0022], Actual Selectivity: 0.0153, NN Predicted Selectivity: 0.0034, LR Predicted Selectivity: 0.0000\n",
      "Range: [131.1516, 1961.8781], Actual Selectivity: 0.8182, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.8228\n",
      "Range: [1711.5397, 1720.0396], Actual Selectivity: 0.0037, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.0000\n",
      "Range: [379.7578, 725.8856], Actual Selectivity: 0.1578, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.1545\n",
      "Range: [1477.9148, 1487.7443], Actual Selectivity: 0.0043, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.0000\n",
      "Range: [7.9978, 8.0022], Actual Selectivity: 0.0062, NN Predicted Selectivity: 0.0129, LR Predicted Selectivity: 0.0000\n",
      "Range: [820.0840, 1195.4081], Actual Selectivity: 0.1671, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.1662\n",
      "Range: [804.4464, 1180.8761], Actual Selectivity: 0.1677, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.1668\n",
      "Range: [14.9978, 15.0022], Actual Selectivity: 0.0153, NN Predicted Selectivity: 0.0034, LR Predicted Selectivity: 0.0000\n",
      "Range: [390.8358, 1296.9143], Actual Selectivity: 0.4069, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.4062\n",
      "Range: [831.4432, 1255.3722], Actual Selectivity: 0.1884, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.1880\n",
      "Range: [323.2115, 1596.8938], Actual Selectivity: 0.5697, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.5717\n",
      "Range: [238.8484, 1697.4213], Actual Selectivity: 0.6528, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.6551\n",
      "Range: [202.1130, 1419.2827], Actual Selectivity: 0.5487, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.5467\n",
      "Range: [12.9740, 293.7601], Actual Selectivity: 0.1331, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.1262\n",
      "Range: [1249.4961, 1618.1428], Actual Selectivity: 0.1616, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.1619\n",
      "Range: [1056.4448, 1489.3203], Actual Selectivity: 0.1908, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.1913\n",
      "Range: [726.9438, 1011.4539], Actual Selectivity: 0.1274, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.1257\n",
      "Range: [209.5278, 1604.5032], Actual Selectivity: 0.6260, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.6266\n",
      "Range: [340.5160, 1986.5800], Actual Selectivity: 0.7308, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.7391\n",
      "Range: [23.9978, 24.0022], Actual Selectivity: 0.0036, NN Predicted Selectivity: 0.0006, LR Predicted Selectivity: 0.0000\n",
      "Range: [306.5205, 1891.1528], Actual Selectivity: 0.7053, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.7116\n",
      "Range: [14.9978, 15.0022], Actual Selectivity: 0.0153, NN Predicted Selectivity: 0.0034, LR Predicted Selectivity: 0.0000\n",
      "Range: [4.9978, 5.0022], Actual Selectivity: 0.0053, NN Predicted Selectivity: 0.0227, LR Predicted Selectivity: 0.0000\n",
      "Range: [629.3790, 823.0159], Actual Selectivity: 0.0874, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.0851\n",
      "Range: [-166.6593, 903.0319], Actual Selectivity: 0.5005, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.4815\n",
      "Range: [10.9978, 11.0022], Actual Selectivity: 0.0042, NN Predicted Selectivity: 0.0073, LR Predicted Selectivity: 0.0000\n",
      "Range: [466.1037, 1796.6423], Actual Selectivity: 0.5909, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.5968\n",
      "Range: [0.9978, 1.0022], Actual Selectivity: 0.0087, NN Predicted Selectivity: 0.0476, LR Predicted Selectivity: 0.0000\n",
      "Range: [1388.7810, 1563.7507], Actual Selectivity: 0.0765, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.0743\n",
      "Range: [1534.9025, 1961.3615], Actual Selectivity: 0.1853, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.1870\n",
      "Range: [1525.8021, 1592.4286], Actual Selectivity: 0.0291, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.0252\n",
      "Range: [1301.5038, 1600.9288], Actual Selectivity: 0.1312, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.1306\n",
      "Range: [306.2796, 514.5713], Actual Selectivity: 0.0960, NN Predicted Selectivity: 0.0000, LR Predicted Selectivity: 0.0927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train the models\n",
    "print(f\"Training NN model...\")\n",
    "train_NN(model, criterion, optimizer, data_loader, X_test_normalized, y_test, num_epochs, val_every=10)\n",
    "print(f\"Training LR model...\")\n",
    "train_lr(lr_model, train_data, test_data, val_every=1)\n",
    "\n",
    "# evaluate both models on the test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    test_loss = criterion(y_pred, y_test)\n",
    "    print(f\"NN Test loss: {test_loss.item()}\")\n",
    "\n",
    "# show side by side comparison of actual selectivity and predicted selectivity for all test data, along with the range\n",
    "y_pred_array = y_pred.numpy().flatten()\n",
    "y_test_array = y_test.numpy().flatten()\n",
    "X_test_array = X_test.numpy()\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    a, b = X_test_array[i]\n",
    "    lr_pred = lr_model.predict(X_test_array[i])\n",
    "    print(f\"Range: [{a:.4f}, {b:.4f}], Actual Selectivity: {y_test_array[i]:.4f}, NN Predicted Selectivity: {y_pred_array[i]:.4f}, LR Predicted Selectivity: {lr_pred:.4f}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clone_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
