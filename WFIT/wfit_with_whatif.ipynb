{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WFIT Algorithm Implementation (Schnaitter 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "import IPython\n",
    "notebook_path = IPython.get_ipython().starting_dir\n",
    "target_subdirectory_path = os.path.abspath(os.path.join(os.path.dirname(notebook_path), 'PostgreSQL'))\n",
    "sys.path.append(target_subdirectory_path)\n",
    "\n",
    "from pg_utils import *\n",
    "from ssb_qgen_class import *\n",
    "\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index Benefit Graph (IBG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, id, indexes):\n",
    "        self.id = id\n",
    "        self.indexes = indexes\n",
    "        self.children = []\n",
    "        self.parents = []\n",
    "        self.built = False\n",
    "        self.cost = None\n",
    "        self.used = None\n",
    "\n",
    "\n",
    "# class for creating and storing the IBG\n",
    "class IBG:\n",
    "    def __init__(self, query_object, C):\n",
    "        self.q = query_object\n",
    "        self.C = C\n",
    "        print(f\"Number of candidate indexes: {len(self.C)}\")\n",
    "        #print(f\"Candidate indexes: {self.C}\")\n",
    "        \n",
    "        # map index_id to integer\n",
    "        self.idx2id = {index.index_id:i for i, index in enumerate(self.C)}\n",
    "        self.idx2index = {index.index_id:index for index in self.C}\n",
    "        \n",
    "        # create a hash table for keeping track of all created nodes\n",
    "        self.nodes = {}\n",
    "        # create a root node\n",
    "        self.root = Node(self.get_configuration_id(self.C), self.C)\n",
    "        self.nodes[self.root.id] = self.root\n",
    "        print(f\"Created root node with id: {self.root.id}\")\n",
    "        # start the IBG construction\n",
    "        print(\"Constructing IBG...\")\n",
    "        self.construct_ibg(self.root)\n",
    "        # compute all pair degree of interaction\n",
    "        print(f\"Computing all pair degree of interaction...\")\n",
    "        self.doi = self.compute_all_pair_doi()\n",
    "\n",
    "\n",
    "    # assign unique string id to a configuration\n",
    "    def get_configuration_id(self, indexes):\n",
    "        # get sorted list of integer ids\n",
    "        ids = sorted([self.idx2id[idx.index_id] for idx in indexes])\n",
    "        return \"_\".join([str(i) for i in ids])\n",
    "    \n",
    "\n",
    "    # obtain cost and used indexes for a given configuration\n",
    "    def _get_cost_used(self, indexes):\n",
    "        conn = create_connection()\n",
    "        # create hypothetical indexes\n",
    "        hypo_indexes = bulk_create_hypothetical_indexes(conn, indexes)\n",
    "        # map oid to index object\n",
    "        oid2index = {}\n",
    "        for i in range(len(hypo_indexes)):\n",
    "            oid2index[hypo_indexes[i][0]] = indexes[i]\n",
    "        # get cost and used indexes\n",
    "        cost, indexes_used = get_query_cost_estimate_hypo_indexes(conn, self.q.query_string, show_plan=False)\n",
    "        # map used index oids to index objects\n",
    "        used = [oid2index[oid] for oid,scan_type,scan_cost in indexes_used]\n",
    "        # drop hypothetical indexes\n",
    "        bulk_drop_hypothetical_indexes(conn)\n",
    "        close_connection(conn)   \n",
    "        return cost, used\n",
    "\n",
    "    # recursive IBG construction algorithm\n",
    "    def construct_ibg(self, Y):\n",
    "        if Y.built:\n",
    "            return \n",
    "        \n",
    "        # obtain query optimizers cost and used indexes\n",
    "        cost, used = self._get_cost_used(Y.indexes)\n",
    "        Y.cost = cost\n",
    "        Y.used = used\n",
    "        Y.built = True\n",
    "        \n",
    "        #print(f\"Creating node for configuration: {[idx.index_id for idx in Y.indexes]}\")\n",
    "        #print(f\"Cost: {cost}, Used indexes:\")\n",
    "        #for idx in used:\n",
    "        #    print(f\"{idx}\")\n",
    "\n",
    "        # create children\n",
    "        for a in Y.used:\n",
    "            # create a new configuration with index a removed from Y\n",
    "            X_indexes = [index for index in Y.indexes if index != a]\n",
    "            X_id = self.get_configuration_id(X_indexes)\n",
    "            \n",
    "            # if X is not in the hash table, create a new node and recursively build it\n",
    "            if X_id not in self.nodes:\n",
    "                X = Node(X_id, X_indexes)\n",
    "                X.parents.append(Y)\n",
    "                self.nodes[X_id] = X\n",
    "                Y.children.append(X)\n",
    "                self.construct_ibg(X)\n",
    "\n",
    "            else:\n",
    "                X = self.nodes[X_id]\n",
    "                Y.children.append(X)\n",
    "                X.parents.append(Y)\n",
    "\n",
    "\n",
    "    # use IBG to obtain estimated cost and used indexes for arbitrary subset of C\n",
    "    def get_cost_used(self, X):\n",
    "        # get id of the configuration\n",
    "        id = self.get_configuration_id(X)\n",
    "        # check if the configuration is in the IBG\n",
    "        if id in self.nodes:\n",
    "            cost, used = self.nodes[id].cost, self.nodes[id].used\n",
    "        \n",
    "        # if not in the IBG, traverse the IBG to find a covering node\n",
    "        else:\n",
    "            Y = self.find_covering_node(X)              \n",
    "            cost, used = Y.cost, Y.used\n",
    "\n",
    "        return cost, used    \n",
    "\n",
    "\n",
    "    # traverses the IBG to find a node that removes indexes not in X (i.e. a covering node for X)\n",
    "    def find_covering_node(self, X):\n",
    "        X_indexes = set([index.index_id for index in X])\n",
    "        Y = self.root\n",
    "        Y_indexes = set([index.index_id for index in Y.indexes])\n",
    "        # traverse IBG to find covering node\n",
    "        while (len(Y_indexes - X_indexes) != 0) or (len(Y.children) > 0):               \n",
    "            # traverse down to the child node that removes an index not in X\n",
    "            child_found = False\n",
    "            for child in Y.children:\n",
    "                child_indexes = set([index.index_id for index in child.indexes])\n",
    "                child_indexes_removed = Y_indexes - child_indexes\n",
    "                child_indexes_removed_not_in_X = child_indexes_removed - X_indexes\n",
    "        \n",
    "                # check if child removes an index not in X\n",
    "                if len(child_indexes_removed_not_in_X) > 0:\n",
    "                    Y = child\n",
    "                    Y_indexes = child_indexes\n",
    "                    child_found = True\n",
    "                    break\n",
    "\n",
    "            # if no children remove indexes not in X    \n",
    "            if not child_found:\n",
    "                break    \n",
    "    \n",
    "        return Y        \n",
    "\n",
    "    # compute benefit of an index for a given configuration \n",
    "    # input X is a list of index objects and 'a' is a single index object\n",
    "    # X must not contain 'a'\n",
    "    def compute_benefit(self, a, X):\n",
    "        if a in X:\n",
    "            # zero benefit if 'a' is already in X\n",
    "            #raise ValueError(\"Index 'a' is already in X\")\n",
    "            return 0\n",
    "        \n",
    "        # get cost  for X\n",
    "        cost_X = self.get_cost_used(X)[0]\n",
    "        # create a new configuration with index a added to X\n",
    "        X_a = X + [a]\n",
    "        # get cost for X + {a}\n",
    "        cost_X_a = self.get_cost_used(X_a)[0]\n",
    "        # compute benefit\n",
    "        benefit = cost_X - cost_X_a\n",
    "        return benefit \n",
    "\n",
    "\n",
    "    # compute maximum benefit of adding an index to any possibe configuration\n",
    "    def compute_max_benefit(self, a):\n",
    "        max_benefit = float('-inf')\n",
    "        for id, node in self.nodes.items():\n",
    "            #print(f\"Computing benefit for node: {[index.index_id for index in node.indexes]}\")\n",
    "            benefit = self.compute_benefit(a, node.indexes)\n",
    "            if benefit > max_benefit:\n",
    "                max_benefit = benefit\n",
    "\n",
    "        return max_benefit\n",
    "    \n",
    "    # compute the degree of interaction between two indexes a,b in configuration X \n",
    "    def compute_doi_configuration(self, a, b, X):\n",
    "        # X must not contain a or b\n",
    "        if a in X or b in X:\n",
    "            raise ValueError(\"a or b is already in X\")\n",
    "\n",
    "        doi = abs(self.compute_benefit(a, X) - self.compute_benefit(a, X + [b]))\n",
    "        doi /= self.get_cost_used(X + [a,b])[0]   \n",
    "        return doi\n",
    "   \n",
    "    \n",
    "    # computes the degree of interaction between all pairs of indexes (a,b) in candidate set C\n",
    "    # Note: doi is symmetric, i.e. doi(a,b) = doi(b,a)\n",
    "    def compute_all_pair_doi(self):\n",
    "        # hash table for storing doi values\n",
    "        doi = {}\n",
    "        # intialize doi values to zero\n",
    "        for i in range(len(self.C)):\n",
    "            for j in range(i+1, len(self.C)):\n",
    "                doi[(self.C[i].index_id, self.C[j].index_id)] = 0\n",
    "\n",
    "        S_idxs = set([index.index_id for index in self.C])\n",
    "\n",
    "        # iterate over each IBG node\n",
    "        for Y in self.nodes.values():\n",
    "            # remove Y.used from S\n",
    "            Y_idxs = set([index.index_id for index in Y.indexes])\n",
    "            S_Y = list(S_idxs - Y_idxs)\n",
    "            # iterate over all pairs of indexes in S_Y\n",
    "            for i in range(len(S_Y)):\n",
    "                for j in range(i+1, len(S_Y)):\n",
    "                    a_idx = S_Y[i]\n",
    "                    b_idx = S_Y[j]\n",
    "                     \n",
    "                    # find Ya covering node in IBG\n",
    "                    Ya = (Y_idxs - {a_idx, b_idx}) | {a_idx}\n",
    "                    Ya = [self.idx2index[idx] for idx in Ya]\n",
    "                    Ya = self.find_covering_node(Ya).indexes\n",
    "                    # find Yab covering node in IBG\n",
    "                    Yab = (Y_idxs - {a_idx, b_idx}) | {a_idx, b_idx}\n",
    "                    Yab = [self.idx2index[idx] for idx in Yab]\n",
    "                    Yab = self.find_covering_node(Yab).indexes\n",
    "\n",
    "                    used_Y = self.get_cost_used(Y.indexes)[1]\n",
    "                    used_Ya = self.get_cost_used(Ya)[1]\n",
    "                    used_Yab = self.get_cost_used(Yab)[1]\n",
    "                    \n",
    "                    Uab = set([index.index_id for index in used_Y]) | set([index.index_id for index in used_Ya]) | set([index.index_id for index in used_Yab]) \n",
    "                    # find Yb_minus covering node in IBG \n",
    "                    Yb_minus = list((Uab - {a_idx, b_idx}) | {b_idx})\n",
    "                    Yb_minus = [self.idx2index[idx] for idx in Yb_minus]\n",
    "                    Yb_minus = self.find_covering_node(Yb_minus).indexes\n",
    "                    # find Yb_plus covering node in IBG\n",
    "                    Yb_plus = list((Y_idxs - {a_idx, b_idx}) | {b_idx})\n",
    "                    Yb_plus = [self.idx2index[idx] for idx in Yb_plus]\n",
    "                    Yb_plus = self.find_covering_node(Yb_plus).indexes\n",
    "\n",
    "                    # generate quadruples\n",
    "                    quadruples = [(Y.indexes, Ya, Yb_minus, Yab), (Y.indexes, Ya, Yb_plus, Yab)]\n",
    "\n",
    "                    # compute doi using the quadruples\n",
    "                    for Y_indexes, Ya_indexes, Yb_indexes, Yab_indexes in quadruples:\n",
    "                        cost_Y = self.get_cost_used(Y_indexes)[0]\n",
    "                        cost_Ya = self.get_cost_used(Ya_indexes)[0]\n",
    "                        cost_Yb = self.get_cost_used(Yb_indexes)[0]\n",
    "                        cost_Yab = self.get_cost_used(Yab_indexes)[0]\n",
    "                        d = abs(cost_Y - cost_Ya - cost_Yb + cost_Yab) / cost_Yab\n",
    "                        if (a_idx, b_idx) in doi:\n",
    "                            doi[(a_idx,b_idx)] = max(doi[(a_idx,b_idx)], d)\n",
    "                        elif (b_idx, a_idx) in doi:\n",
    "                            doi[(b_idx,a_idx)] = max(doi[(b_idx,a_idx)], d)\n",
    "                        else:\n",
    "                            raise ValueError(\"Invalid pair of indexes\")    \n",
    "                            \n",
    "        \n",
    "        return doi\n",
    "\n",
    "\n",
    "    # get precomputed degree of interaction between a pair of indexes\n",
    "    def get_doi_pair(self, a, b):\n",
    "        if (a.index_id, b.index_id) in self.doi:\n",
    "            return self.doi[(a.index_id, b.index_id)]\n",
    "        elif (b.index_id, a.index_id) in self.doi:\n",
    "            return self.doi[(b.index_id, a.index_id)]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid pair of indexes\")\n",
    "\n",
    "\n",
    "    # function for printing the IBG, using BFS level order traversal\n",
    "    def print_ibg(self):\n",
    "        q = [self.root]\n",
    "        # traverse level by level, print all node ids in a level in a single line before moving to the next level\n",
    "        while len(q) > 0:\n",
    "            next_q = []\n",
    "            for node in q:\n",
    "                print(f\"{node.id} -> \", end=\"\")\n",
    "                for child in node.children:\n",
    "                    next_q.append(child)\n",
    "            print()\n",
    "            q = next_q  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an SSB query generator object\n",
    "qg = QGEN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template id: 14, query: \n",
      "                SELECT lo_linenumber, lo_quantity, lo_orderdate  \n",
      "                FROM lineorder\n",
      "                WHERE lo_linenumber >= 3 AND lo_linenumber <= 4\n",
      "                AND lo_quantity = 32;\n",
      "            , payload: {'lineorder': ['lo_linenumber', 'lo_quantity', 'lo_orderdate']}, predicates: {'lineorder': ['lo_linenumber', 'lo_quantity']}, order by: {}, group by: {}\n",
      "Number of candidate indexes: 12\n",
      "Created root node with id: 0_1_2_3_4_5_6_7_8_9_10_11\n",
      "Constructing IBG...\n",
      "No index scans were explicitly noted in the query plan.\n",
      "Computing all pair degree of interaction...\n",
      "0_1_2_3_4_5_6_7_8_9_10_11 -> \n",
      "0_1_2_3_4_5_6_7_8_9_10 -> \n",
      "0_1_2_3_4_5_6_8_9_10 -> \n",
      "0_1_2_3_4_5_6_8_10 -> \n",
      "0_1_2_4_5_6_8_10 -> \n",
      "0_1_2_4_5_6_8 -> \n",
      "IBG     --> Cost: 21589.56, Used indexes: ['IXN_lineorder_lo_quantity_lo_linenumber_lo_o']\n",
      "What-if --> Cost: 21589.56, Used indexes: ['IXN_lineorder_lo_quantity_lo_linenumber_lo_o']\n",
      "\n",
      "Maximum benefit of adding index IX_lineorder_lo_linenumber: 0\n",
      "\n",
      "DOI between indexes IX_lineorder_lo_linenumber and IX_lineorder_lo_quantity : 0.0\n",
      "in configuration ['IXN_lineorder_lo_linenumber_lo_o', 'IXN_lineorder_lo_linenumber_lo_q', 'IXN_lineorder_lo_quantity_lo_l', 'IXN_lineorder_lo_quantity_lo_o', 'IX_lineorder_lo_linenumber_lo_quantity']\n",
      "\n",
      "DOI between indexes IX_lineorder_lo_linenumber and IX_lineorder_lo_quantity : 0\n"
     ]
    }
   ],
   "source": [
    "# test IBG \n",
    "\n",
    "query = qg.generate_query(14)\n",
    "print(query)\n",
    "\n",
    "C = extract_query_indexes(qg.generate_query(14), include_cols=True)  \n",
    "\n",
    "ibg = IBG(query, C)\n",
    "\n",
    "ibg.print_ibg()\n",
    "\n",
    "# pick random subset of candidate indexes\n",
    "X = random.sample(ibg.C, 8)\n",
    "cost, used = ibg.get_cost_used(X)\n",
    "print(f\"IBG     --> Cost: {cost}, Used indexes: {[idx.index_id for idx in used]}\")\n",
    "\n",
    "cost, used = ibg._get_cost_used(X)\n",
    "print(f\"What-if --> Cost: {cost}, Used indexes: {[idx.index_id for idx in used]}\")\n",
    "\n",
    "# pick two indexes and a configuration\n",
    "a = ibg.C[0]\n",
    "b = ibg.C[4] \n",
    "X = [ibg.C[1], ibg.C[2], ibg.C[5], ibg.C[6], ibg.C[8]]\n",
    "\n",
    "# compute maximum benefit of adding index 'a' \n",
    "max_benefit = ibg.compute_max_benefit(a)\n",
    "print(f\"\\nMaximum benefit of adding index {a.index_id}: {max_benefit}\")\n",
    "\n",
    "# compute degree of interaction between indexes 'a' and 'b' in configuration X\n",
    "doi = ibg.compute_doi_configuration(a, b, X)\n",
    "print(f\"\\nDOI between indexes {a.index_id} and {b.index_id} : {doi}\")\n",
    "print(f\"in configuration {[idx.index_id for idx in X]}\")\n",
    "\n",
    "# compute configuration independent degree of interaction between indexes 'a' and 'b'\n",
    "doi = ibg.get_doi_pair(a, b)\n",
    "print(f\"\\nDOI between indexes {a.index_id} and {b.index_id} : {doi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for key, value in ibg.doi.items():\n",
    "#    print(f\"doi({key[0]},   {key[1]}) = {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WFIT class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WFIT:\n",
    "\n",
    "    def __init__(self, idxCnt=1000, stateCnt=1000, histSize=100):\n",
    "        # parameter for maximum number of candidate indexes tracked \n",
    "        self.idxCnt = idxCnt\n",
    "        # parameter for maximum number of MTS states/configurations\n",
    "        self.stateCnt = stateCnt\n",
    "        # parameter for maximum number of historical index statistics kept\n",
    "        self.histSize = histSize\n",
    "        # growing list of candidate indexes\n",
    "        self.U = {}\n",
    "        # index benefit and interaction statistics\n",
    "        self.idxStats = defaultdict(list)\n",
    "        self.intStats = defaultdict(list)\n",
    "        # list of currently monitored indexes\n",
    "        self.C = {}\n",
    "        # list of currently materialized indexes\n",
    "        self.M = {}\n",
    "\n",
    "\n",
    "    # compute index benefit graph for the given query and candidate indexes\n",
    "    def compute_IBG(self, query_object, candidate_indexes):\n",
    "        return IBG(query_object, candidate_indexes)\n",
    "    \n",
    "\n",
    "    # extract candidate indexes from given query\n",
    "    def extract_indexes(self, query_object, include_cols=True):\n",
    "        return extract_query_indexes(query_object, include_cols)\n",
    "\n",
    "\n",
    "    # generate stable partitions/sets of indexes for next query in workload\n",
    "    def choose_candidates(self, n, query_object):\n",
    "        # extract new candidate indexes from the query\n",
    "        new_indexes = self.extract_indexes(query_object)\n",
    "        # add new indexes to the list of all candidate indexes\n",
    "        for index in new_indexes:\n",
    "            if index.index_id not in self.U:\n",
    "                self.U[index.index_id] = index\n",
    "\n",
    "        # TODO: check if the number of candidate indexes exceeds the limit, then need to evict some indexes\n",
    "        \n",
    "        # compute index benefit graph for the query\n",
    "        ibg = self.compute_IBG(query_object, list(self.U.values()))\n",
    "        \n",
    "        # update statistics for the candidate indexes (n is the position of the query in the workload sequence)\n",
    "        self.update_stats(n, ibg)\n",
    "\n",
    "        # determine new set of candidate indexes to monitor for upcoming workload queries\n",
    "\n",
    "\n",
    "    # update candidate index statistics\n",
    "    def update_stats(self, n, ibg):\n",
    "        # update index benefit statistics\n",
    "        for index in self.U.values():\n",
    "            max_benefit = ibg.compute_max_benefit(index)\n",
    "            self.idxStats[index.index_id].append((n, max_benefit))\n",
    "\n",
    "            # TODO: evict old stats if the size exceeds histSize\n",
    "        \n",
    "        # update index interaction statistics\n",
    "        for (a_idx, b_idx) in ibg.doi.keys():\n",
    "            d = ibg.doi[(a_idx, b_idx)]\n",
    "            if d > 0:\n",
    "                self.intStats[(a_idx, b_idx)].append((n, doi))\n",
    "\n",
    "            # TODO: evict old stats if the size exceeds histSize\n",
    "        \n",
    "\n",
    "    # choose at most num_indexes indexes from X with highest potential benefit\n",
    "    def top_indexes(self, N_workload, X, num_indexes):\n",
    "        # compute \"current benefit\" of each index in X (these are derived from statistics of observed benefits from recent queries)\n",
    "        score = {}\n",
    "        for index in X:\n",
    "            if len(self.idxStats[index.index_id]) == 0:\n",
    "                # zero current benefit if no statistics are available\n",
    "                current_benefit = 0\n",
    "            else:\n",
    "                benefits = []\n",
    "                b_total = 0\n",
    "                for (n, b) in self.idxStats[index.index_id]:\n",
    "                    b_total += b \n",
    "                    # cumulative average benefit of index up to query n (higher weight/smaller denominator for more recent queries)\n",
    "                    benefit = b_total / (N_workload - n + 1)\n",
    "                    benefits.append(benefit)\n",
    "\n",
    "                # take the maximum over all cumulative average benefits \n",
    "                current_benefit = max(benefits)    \n",
    "\n",
    "            # use current benefit to compute a score for the index\n",
    "            if index.index_id in self.C:\n",
    "                # if index already being monitored, then score is just current benefit\n",
    "                score[index.index_id] = current_benefit\n",
    "            else:\n",
    "                # if index not being monitored, then score is current benefit minus cost of creating the index\n",
    "                score[index.index_id] = current_benefit - self.get_index_creation_cost(index)\n",
    "\n",
    "        # get the top num_indexes indexes with highest scores\n",
    "        top_indexes = sorted(score, key=score.get, reverse=True)[:num_indexes]\n",
    "        return top_indexes    \n",
    "\n",
    "\n",
    "    # TODO: return index creation cost\n",
    "    def get_index_creation_cost(self, index):\n",
    "        raise NotImplementedError(\"Method not implemented\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clone_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
