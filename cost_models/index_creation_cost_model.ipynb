{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index Creation Cost Model -  Online Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import datetime\n",
    "import os\n",
    "import subprocess\n",
    "import uuid\n",
    "\n",
    "import pyodbc\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import re\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import itertools\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import IPython\n",
    "notebook_path = IPython.get_ipython().starting_dir\n",
    "target_subdirectory_path = os.path.abspath(os.path.join(os.path.dirname(notebook_path), 'database'))\n",
    "sys.path.append(target_subdirectory_path)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate all possible indexes for each table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Function for generating all possible configurations (i.e. subsets of indixes)\n",
    "\"\"\"\n",
    "def generate_all_configurations(connection, MAX_COLS=2, with_includes=False, verbose=False):\n",
    "    # first, generate all possible indices\n",
    "    tables = get_all_tables(connection)\n",
    "    all_indices = {} \n",
    "    # tqdm bar around table loop\n",
    "    for table_name, table in tqdm(tables.items(), desc=\"Generating all indices for table:\"):\n",
    "        columns = table.get_columns()\n",
    "        if verbose:\n",
    "            print(f\"Table --> {table_name} with columns --> {columns}\")\n",
    "        # get all possible permutations of columns, up to MAX_KEY_COLS columns\n",
    "        for num_columns in range(1, MAX_COLS+1):\n",
    "            col_permutations = list(itertools.permutations(columns, num_columns))\n",
    "            # also generate permutations of columns with include columns\n",
    "            for cp in col_permutations:\n",
    "                if with_includes:\n",
    "                    # get columns not in cp\n",
    "                    include_columns = list(set(columns) - set(cp))\n",
    "                    # get all comnbination of include columns on remaining columns\n",
    "                    include_col_combinations = list(itertools.combinations(include_columns, MAX_COLS-num_columns))\n",
    "                    for icp in include_col_combinations:\n",
    "                        index_id = get_index_id(cp, table_name, include_columns)\n",
    "                        if index_id not in all_indices:\n",
    "                            index_size = get_estimated_index_size(connection, table_name, list(cp) + include_columns)\n",
    "                            # create index object\n",
    "                            all_indices[index_id] = Index(table_name, index_id, cp, index_size, tuple(icp))\n",
    "                else:\n",
    "                    index_id = get_index_id(cp, table_name)\n",
    "                    if index_id not in all_indices:\n",
    "                        index_size = get_estimated_index_size(connection, table_name, list(cp))\n",
    "                        # create index object\n",
    "                        all_indices[index_id] = Index(table_name, index_id, cp, index_size)\n",
    "\n",
    "    print(f\"Total number of indices generated: {len(all_indices)}, total estimated size: {sum([i.size for i in all_indices.values()]):.2f} Mb\")\n",
    "   \n",
    "    return all_indices, tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating all indices for table:: 100%|██████████| 8/8 [00:00<00:00, 504.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of indices generated: 5585, total estimated size: 824332.61 Mb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "connection = start_connection()\n",
    "\n",
    "all_indices, tables = generate_all_configurations(connection, MAX_COLS=3, with_includes=False)\n",
    "\n",
    "\n",
    "\n",
    "# get all columns\n",
    "all_columns, num_columns = get_all_columns(connection)\n",
    "\n",
    "columns_to_idx = {}\n",
    "i = 0\n",
    "for table_name, columns in all_columns.items():\n",
    "    for column in columns:\n",
    "        columns_to_idx[column] = i\n",
    "        i += 1\n",
    "\n",
    "idx_to_columns = {v: k for k, v in columns_to_idx.items()}  \n",
    "\n",
    "close_connection(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create feature vector for each index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: customer, Row Count: 150000, PK Columns: ['c_custkey']\n"
     ]
    }
   ],
   "source": [
    "# show all\n",
    "print(tables['customer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_stats(connection, table_name):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(f\"\"\"\n",
    "                        SELECT SUM(row_count) as total_rows, SUM(used_page_count) * 8 / 1024.0 as size_mb\n",
    "                        FROM sys.dm_db_partition_stats\n",
    "                        WHERE object_id = OBJECT_ID('{table_name}')\n",
    "                    \"\"\")\n",
    "    row_count, table_size_mb = cursor.fetchone()\n",
    "    table_size_mb = float(table_size_mb) if table_size_mb is not None else 0.0\n",
    "\n",
    "    cursor.execute(f\"\"\"\n",
    "            SELECT AVG(avg_fragmentation_in_percent)\n",
    "            FROM sys.dm_db_index_physical_stats(DB_ID(), OBJECT_ID('{table_name}'), NULL, NULL, 'LIMITED')\n",
    "        \"\"\")\n",
    "    avg_fragmentation = cursor.fetchone()[0]\n",
    "    avg_fragmentation = float(avg_fragmentation) if avg_fragmentation is not None else 0.0\n",
    "\n",
    "    #cursor.execute(\"SELECT cpu_count FROM sys.dm_os_sys_info\")\n",
    "    #cpu_count = cursor.fetchone()[0]\n",
    "\n",
    "    num_columns = len(all_columns[table_name])\n",
    "    return (num_columns, row_count, table_size_mb, avg_fragmentation)\n",
    "    \n",
    "\n",
    "def column_feature_encoding(index, c=10):\n",
    "    index_columns_encoding = np.zeros(len(columns_to_idx), dtype=float)\n",
    "    # encoding for index columns\n",
    "    for j, column_name in enumerate(index.index_columns):\n",
    "        column_position_in_index = j\n",
    "        index_columns_encoding[columns_to_idx[column_name]] = 1/(c**column_position_in_index)\n",
    "    \n",
    "    if len(index.include_columns) > 0:\n",
    "        # encoding for include columns\n",
    "        include_columns_encoding = np.zeros(len(columns_to_idx), dtype=float)\n",
    "        for j, column_name in enumerate(index.include_columns):\n",
    "            include_columns_encoding[columns_to_idx[column_name]] = 1\n",
    "\n",
    "        # concatenate the two context vectors\n",
    "        columns_encoding = np.hstack((index_columns_encoding, include_columns_encoding))\n",
    "        return columns_encoding\n",
    "    else:\n",
    "\n",
    "        return index_columns_encoding \n",
    "    \n",
    "\n",
    "\n",
    "def create_feature_vectors(all_indices, connection):\n",
    "\n",
    "    print(f\"Obtain table stats...\")    \n",
    "    table_stats = {}\n",
    "    for index in all_indices.values():\n",
    "        table_name = index.table_name\n",
    "        if table_name not in table_stats:\n",
    "            table_stats[table_name] = get_table_stats(connection, table_name)\n",
    "    \n",
    "    print(f\"Creating feature vectors...\")\n",
    "    feature_vectors = {}\n",
    "    for index in all_indices.values():\n",
    "        columns_encoding = column_feature_encoding(index)\n",
    "        index_size_mb = index.size\n",
    "        num_columns, row_count, table_size_mb, avg_fragmentation = table_stats[index.table_name]\n",
    "        table_features = np.array([num_columns, row_count, table_size_mb/index_size_mb, avg_fragmentation])\n",
    "        feature_vectors[index.index_id] = np.concatenate((table_features, columns_encoding))\n",
    "        \n",
    "    return feature_vectors  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtain table stats...\n",
      "Creating feature vectors...\n"
     ]
    }
   ],
   "source": [
    "connection = start_connection()\n",
    "\n",
    "feature_vectors = create_feature_vectors(all_indices, connection)\n",
    "\n",
    "close_connection(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clone_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
