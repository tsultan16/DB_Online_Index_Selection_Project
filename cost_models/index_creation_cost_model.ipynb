{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index Creation Cost Model -  Online Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "import os\n",
    "import subprocess\n",
    "import uuid\n",
    "\n",
    "import pyodbc\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import re\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import itertools\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import IPython\n",
    "notebook_path = IPython.get_ipython().starting_dir\n",
    "target_subdirectory_path = os.path.abspath(os.path.join(os.path.dirname(notebook_path), 'database'))\n",
    "sys.path.append(target_subdirectory_path)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate all possible indexes for each table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Function for generating all possible configurations (i.e. subsets of indixes)\n",
    "\"\"\"\n",
    "def generate_all_configurations(connection, MAX_COLS=2, with_includes=False, verbose=False):\n",
    "    # first, generate all possible indices\n",
    "    tables = get_all_tables(connection)\n",
    "    all_indices = {} \n",
    "    # tqdm bar around table loop\n",
    "    for table_name, table in tqdm(tables.items(), desc=\"Generating all indices for table:\"):\n",
    "        columns = table.get_columns()\n",
    "        if verbose:\n",
    "            print(f\"Table --> {table_name} with columns --> {columns}\")\n",
    "        # get all possible permutations of columns, up to MAX_KEY_COLS columns\n",
    "        for num_columns in range(1, MAX_COLS+1):\n",
    "            col_permutations = list(itertools.permutations(columns, num_columns))\n",
    "            # also generate permutations of columns with include columns\n",
    "            for cp in col_permutations:\n",
    "                if with_includes:\n",
    "                    # get columns not in cp\n",
    "                    include_columns = list(set(columns) - set(cp))\n",
    "                    # get all comnbination of include columns on remaining columns\n",
    "                    include_col_combinations = list(itertools.combinations(include_columns, MAX_COLS-num_columns))\n",
    "                    for icp in include_col_combinations:\n",
    "                        index_id = get_index_id(cp, table_name, include_columns)\n",
    "                        if index_id not in all_indices:\n",
    "                            index_size = get_estimated_index_size(connection, table_name, list(cp) + include_columns)\n",
    "                            # create index object\n",
    "                            all_indices[index_id] = Index(table_name, index_id, cp, index_size, tuple(icp))\n",
    "                else:\n",
    "                    index_id = get_index_id(cp, table_name)\n",
    "                    if index_id not in all_indices:\n",
    "                        index_size = get_estimated_index_size(connection, table_name, list(cp))\n",
    "                        # create index object\n",
    "                        all_indices[index_id] = Index(table_name, index_id, cp, index_size)\n",
    "\n",
    "    print(f\"Total number of indices generated: {len(all_indices)}, total estimated size: {sum([i.size for i in all_indices.values()]):.2f} Mb\")\n",
    "   \n",
    "    return all_indices, tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating all indices for table:: 100%|██████████| 8/8 [00:00<00:00, 525.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of indices generated: 5585, total estimated size: 824332.61 Mb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "connection = start_connection()\n",
    "\n",
    "all_indices, tables = generate_all_configurations(connection, MAX_COLS=3, with_includes=False)\n",
    "\n",
    "\n",
    "# get all columns\n",
    "all_columns, num_columns = get_all_columns(connection)\n",
    "\n",
    "columns_to_idx = {}\n",
    "i = 0\n",
    "for table_name, columns in all_columns.items():\n",
    "    for column in columns:\n",
    "        columns_to_idx[column] = i\n",
    "        i += 1\n",
    "\n",
    "idx_to_columns = {v: k for k, v in columns_to_idx.items()}  \n",
    "\n",
    "close_connection(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create feature vector for each index:\n",
    "\n",
    "Feature vector consists of two parts: (1) Encoding of index and include columns, (2) Table stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_stats(connection, table_name):\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(f\"\"\"\n",
    "                        SELECT SUM(row_count) as total_rows, SUM(used_page_count) * 8 / 1024.0 as size_mb\n",
    "                        FROM sys.dm_db_partition_stats\n",
    "                        WHERE object_id = OBJECT_ID('{table_name}')\n",
    "                    \"\"\")\n",
    "    row_count, table_size_mb = cursor.fetchone()\n",
    "    table_size_mb = float(table_size_mb) if table_size_mb is not None else 0.0\n",
    "\n",
    "    cursor.execute(f\"\"\"\n",
    "            SELECT AVG(avg_fragmentation_in_percent)\n",
    "            FROM sys.dm_db_index_physical_stats(DB_ID(), OBJECT_ID('{table_name}'), NULL, NULL, 'LIMITED')\n",
    "        \"\"\")\n",
    "    avg_fragmentation = cursor.fetchone()[0]\n",
    "    avg_fragmentation = float(avg_fragmentation) if avg_fragmentation is not None else 0.0\n",
    "\n",
    "    #cursor.execute(\"SELECT cpu_count FROM sys.dm_os_sys_info\")\n",
    "    #cpu_count = cursor.fetchone()[0]\n",
    "\n",
    "    num_columns = len(all_columns[table_name])\n",
    "    return (num_columns, row_count, table_size_mb, avg_fragmentation)\n",
    "    \n",
    "\n",
    "def column_feature_encoding(index, c=10):\n",
    "    index_columns_encoding = np.zeros(len(columns_to_idx), dtype=float)\n",
    "    # encoding for index columns\n",
    "    for j, column_name in enumerate(index.index_columns):\n",
    "        column_position_in_index = j\n",
    "        index_columns_encoding[columns_to_idx[column_name]] = 1/(c**column_position_in_index)\n",
    "    \n",
    "    if len(index.include_columns) > 0:\n",
    "        # encoding for include columns\n",
    "        include_columns_encoding = np.zeros(len(columns_to_idx), dtype=float)\n",
    "        for j, column_name in enumerate(index.include_columns):\n",
    "            include_columns_encoding[columns_to_idx[column_name]] = 1\n",
    "\n",
    "        # concatenate the two context vectors\n",
    "        columns_encoding = np.hstack((index_columns_encoding, include_columns_encoding))\n",
    "        return columns_encoding\n",
    "    else:\n",
    "\n",
    "        return index_columns_encoding \n",
    "    \n",
    "\n",
    "def create_feature_vectors(all_indices, connection):\n",
    "\n",
    "    print(f\"Obtain table stats...\")    \n",
    "    table_stats = {}\n",
    "    for index in all_indices.values():\n",
    "        table_name = index.table_name\n",
    "        if table_name not in table_stats:\n",
    "            table_stats[table_name] = get_table_stats(connection, table_name)\n",
    "    \n",
    "    \n",
    "    print(f\"Creating feature vectors...\")\n",
    "    feature_vectors = {}\n",
    "    for index in all_indices.values():\n",
    "        columns_encoding = column_feature_encoding(index)\n",
    "        index_size_mb = index.size\n",
    "        num_columns, row_count, table_size_mb, avg_fragmentation = table_stats[index.table_name]\n",
    "        table_features = np.array([num_columns, row_count, table_size_mb/index_size_mb, avg_fragmentation])\n",
    "        feature_vectors[index.index_id] = np.concatenate((table_features, columns_encoding))\n",
    "        \n",
    "    return feature_vectors  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtain table stats...\n",
      "Creating feature vectors...\n"
     ]
    }
   ],
   "source": [
    "connection = start_connection()\n",
    "\n",
    "feature_vectors = create_feature_vectors(all_indices, connection)\n",
    "\n",
    "close_connection(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training indexes: 155, number of test indexes: 5430\n"
     ]
    }
   ],
   "source": [
    "# group the indexes by table\n",
    "indexes_by_table = defaultdict(list)\n",
    "for index in all_indices.values():\n",
    "    indexes_by_table[index.table_name].append(index)\n",
    "\n",
    "\n",
    "# create train test splits for the indexes, from each table pick 10 indexes for training\n",
    "train_indexes = []\n",
    "test_indexes = []\n",
    "split_idx = 20\n",
    "for table_name, indexes in indexes_by_table.items():\n",
    "    random.shuffle(indexes)\n",
    "    train_indexes.extend(indexes[:split_idx])\n",
    "    test_indexes.extend(indexes[split_idx:])\n",
    "\n",
    "print(f\"Number of training indexes: {len(train_indexes)}, number of test indexes: {len(test_indexes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring index creation cost::  28%|██▊       | 43/155 [02:44<23:18, 12.49s/it]"
     ]
    }
   ],
   "source": [
    "# measure actual creation times of training indexes\n",
    "connection = start_connection()\n",
    "\n",
    "index_creation_cost = {}\n",
    "for index in tqdm(train_indexes, desc=\"Measuring index creation cost:\"):\n",
    "    index_creation_cost[index.index_id] = create_nonclustered_index_object(connection, index)\n",
    "    drop_noncluster_index_object(connection, index)\n",
    "\n",
    "close_connection(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Online Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, feature_vectors, all_indices, lambda_reg=0.1, epsilon=1e-8):\n",
    "        self.feature_vectors = feature_vectors\n",
    "        self.all_indices = all_indices\n",
    "        self.feature_dims = feature_vectors[list(feature_vectors.keys())[0]].shape[0]\n",
    "        self.V = lambda_reg * np.eye(self.feature_dims)\n",
    "        self.b = np.zeros(self.feature_dims)\n",
    "        self.theta = np.zeros(self.feature_dims)\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.epsilon = epsilon\n",
    "        self.loss_history = []\n",
    "        #self.scaler = StandardScaler()\n",
    "        #self.normalize_features()\n",
    "\n",
    "    #def normalize_features(self):\n",
    "    #    all_features = np.array(list(self.feature_vectors.values()))\n",
    "    #    self.scaler.fit(all_features)\n",
    "    #    for key in self.feature_vectors:\n",
    "    #        self.feature_vectors[key] = self.scaler.transform([self.feature_vectors[key]])[0]\n",
    "\n",
    "    def update(self, index, cost, verbose=False):\n",
    "        x = self.feature_vectors[index.index_id]    \n",
    "        y = cost\n",
    "        self.V += np.outer(x, x)\n",
    "        self.b += y * x\n",
    "        # add small epsilon to diagonal of V for conditioning\n",
    "        self.theta = np.linalg.solve(self.V + self.epsilon*np.eye(self.feature_dims), self.b)\n",
    "        loss, y_pred = self.compute_loss(x, y)\n",
    "        if verbose:\n",
    "            print(f\"Update for index: {index.index_id}, actual cost: {cost}, predicted cost: {y_pred:.3f}, loss incurred: {loss}\")\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(self.theta, x)\n",
    "\n",
    "    def compute_loss(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        mse = (y - y_pred)**2\n",
    "        reg = self.lambda_reg * np.dot(self.theta, self.theta)\n",
    "        loss = mse + reg\n",
    "        self.loss_history.append(loss)\n",
    "        return loss, y_pred    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(feature_vectors, all_indices, lambda_reg=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating model for index: IX_customer_c_mktsegment_c_name_c_address, actual cost: 0.301, predicted cost: 0.30099741081318554 ,loss incurred: 7.79337437804942e-07\n",
      "Updating model for index: IX_customer_c_nationkey_c_address_c_phone, actual cost: 0.312, predicted cost: 0.31199738692936674 ,loss incurred: 1.5718298842523257e-06\n",
      "Updating model for index: IX_customer_c_comment_c_nationkey_c_name, actual cost: 0.538, predicted cost: 0.5379957130886399 ,loss incurred: 3.6776598295508275e-06\n",
      "Updating model for index: IX_customer_c_acctbal_c_name_c_mktsegment, actual cost: 0.29, predicted cost: 0.2899977891743089 ,loss incurred: 4.243116251952923e-06\n",
      "Updating model for index: IX_customer_c_acctbal_c_name_c_custkey, actual cost: 0.312, predicted cost: 0.31129903962324723 ,loss incurred: 2.1661407411699993e-05\n",
      "Updating model for index: IX_customer_c_name_c_nationkey_c_address, actual cost: 0.395, predicted cost: 0.39499800946791414 ,loss incurred: 2.162131410482356e-05\n",
      "Updating model for index: IX_customer_c_acctbal_c_phone_c_custkey, actual cost: 0.426, predicted cost: 0.4258829342435775 ,loss incurred: 3.7596500588928325e-05\n",
      "Updating model for index: IX_customer_c_phone_c_nationkey_c_address, actual cost: 0.285, predicted cost: 0.28587893170219114 ,loss incurred: 0.000706569321012786\n",
      "Updating model for index: IX_customer_c_acctbal_c_custkey_c_address, actual cost: 0.442, predicted cost: 0.4399732964420876 ,loss incurred: 0.0002505977593601556\n",
      "Updating model for index: IX_customer_c_phone_c_acctbal_c_nationkey, actual cost: 0.351, predicted cost: 0.3656634315648361 ,loss incurred: 0.0004125665810176425\n",
      "Updating model for index: IX_orders_o_totalprice_o_orderstatus_o_orderpriority, actual cost: 2.833, predicted cost: 2.832967734076451 ,loss incurred: 0.00029131113062849445\n",
      "Updating model for index: IX_orders_o_shippriority_o_totalprice_o_orderpriority, actual cost: 6.568, predicted cost: 6.5679281333581905 ,loss incurred: 0.0007459210693481565\n",
      "Updating model for index: IX_orders_o_orderkey, actual cost: 0.833, predicted cost: 0.832997560414211 ,loss incurred: 0.0007466387826894891\n",
      "Updating model for index: IX_orders_o_orderdate_o_clerk, actual cost: 4.846, predicted cost: 4.845947183771959 ,loss incurred: 0.0009961697736884502\n",
      "Updating model for index: IX_orders_o_totalprice_o_shippriority_o_orderstatus, actual cost: 4.408, predicted cost: 4.4067326644454585 ,loss incurred: 0.002119283983440643\n",
      "Updating model for index: IX_orders_o_comment_o_orderstatus_o_shippriority, actual cost: 6.141, predicted cost: 6.140919014965044 ,loss incurred: 0.002693523925672347\n",
      "Updating model for index: IX_orders_o_orderpriority_o_totalprice_o_comment, actual cost: 7.633, predicted cost: 7.632902435628147 ,loss incurred: 0.003513542362258523\n",
      "Updating model for index: IX_orders_o_clerk_o_shippriority_o_orderstatus, actual cost: 5.072, predicted cost: 5.071955301269659 ,loss incurred: 0.0036875487775718035\n",
      "Updating model for index: IX_orders_o_orderpriority_o_clerk_o_shippriority, actual cost: 8.574, predicted cost: 8.300776644118036 ,loss incurred: 0.085981220695202\n",
      "Updating model for index: IX_orders_o_orderkey_o_orderdate, actual cost: 1.128, predicted cost: 1.1108186179816888 ,loss incurred: 0.016954168761189513\n",
      "Updating model for index: IX_lineitem_l_discount_l_linestatus_l_orderkey, actual cost: 15.61, predicted cost: 15.609381143891788 ,loss incurred: 0.02602685433284977\n",
      "Updating model for index: IX_lineitem_l_shipinstruct_l_extendedprice_l_receiptdate, actual cost: 26.808, predicted cost: 26.80686391228047 ,loss incurred: 0.0575289833389318\n",
      "Updating model for index: IX_lineitem_l_shipmode, actual cost: 14.674, predicted cost: 14.673345492979136 ,loss incurred: 0.06794996860657306\n",
      "Updating model for index: IX_lineitem_l_linestatus_l_partkey_l_linenumber, actual cost: 26.202, predicted cost: 26.20092575235163 ,loss incurred: 0.09614415482977288\n",
      "Updating model for index: IX_lineitem_l_orderkey_l_extendedprice_l_discount, actual cost: 10.245, predicted cost: 10.244440455017289 ,loss incurred: 0.10360781704385422\n",
      "Updating model for index: IX_lineitem_l_linenumber_l_commitdate_l_shipmode, actual cost: 16.358, predicted cost: 16.357162332446865 ,loss incurred: 0.1204510466173467\n",
      "Updating model for index: IX_lineitem_l_receiptdate_l_partkey_l_tax, actual cost: 8.593, predicted cost: 8.59242838462916 ,loss incurred: 0.12813110737664188\n",
      "Updating model for index: IX_lineitem_l_linenumber_l_linestatus_l_quantity, actual cost: 19.141, predicted cost: 19.14156247333497 ,loss incurred: 0.12817273230394474\n",
      "Updating model for index: IX_lineitem_l_shipinstruct_l_shipdate_l_extendedprice, actual cost: 32.292, predicted cost: 32.2788373244881 ,loss incurred: 0.2079042894789003\n",
      "Updating model for index: IX_lineitem_l_shipdate_l_tax, actual cost: 10.137, predicted cost: 10.138563742743687 ,loss incurred: 0.23377913616135182\n",
      "Updating model for index: IX_part_p_size_p_comment_p_retailprice, actual cost: 0.491, predicted cost: 0.49079430484648334 ,loss incurred: 0.23734873167515735\n",
      "Updating model for index: IX_part_p_partkey_p_comment_p_mfgr, actual cost: 0.181, predicted cost: 0.18080261148844823 ,loss incurred: 0.24062148640705228\n",
      "Updating model for index: IX_part_p_retailprice_p_name, actual cost: 0.443, predicted cost: 0.4428064233217799 ,loss incurred: 0.24376875687631588\n",
      "Updating model for index: IX_part_p_container_p_partkey_p_size, actual cost: 0.71, predicted cost: 0.7098397715608411 ,loss incurred: 0.24590829081825172\n",
      "Updating model for index: IX_part_p_mfgr_p_name_p_retailprice, actual cost: 1.226, predicted cost: 1.2258061603061003 ,loss incurred: 0.24905519719209018\n",
      "Updating model for index: IX_part_p_container_p_size_p_comment, actual cost: 0.709, predicted cost: 0.6475593569773039 ,loss incurred: 0.2853318105067423\n",
      "Updating model for index: IX_part_p_brand_p_retailprice_p_name, actual cost: 0.572, predicted cost: 0.571849729674816 ,loss incurred: 0.28357411291166384\n",
      "Updating model for index: IX_part_p_comment_p_brand_p_retailprice, actual cost: 0.572, predicted cost: 0.5732011657461985 ,loss incurred: 0.24556477795396628\n",
      "Updating model for index: IX_part_p_container_p_mfgr_p_brand, actual cost: 1.052, predicted cost: 1.019625450666291 ,loss incurred: 0.255801330269013\n",
      "Updating model for index: IX_part_p_mfgr_p_comment_p_name, actual cost: 1.417, predicted cost: 1.4387649180584567 ,loss incurred: 0.24870589755151273\n",
      "Updating model for index: IX_supplier_s_comment_s_nationkey_s_phone, actual cost: 0.06, predicted cost: 0.05991311802933197 ,loss incurred: 0.2494162235816941\n",
      "Updating model for index: IX_supplier_s_phone_s_comment, actual cost: 0.024, predicted cost: 0.023921701772880777 ,loss incurred: 0.2503685673979018\n",
      "Updating model for index: IX_supplier_s_acctbal_s_address_s_comment, actual cost: 0.033, predicted cost: 0.03291152516158302 ,loss incurred: 0.25159227633983894\n",
      "Updating model for index: IX_supplier_s_nationkey_s_comment_s_name, actual cost: 0.026, predicted cost: 0.025923542873586225 ,loss incurred: 0.2524731055351624\n",
      "Updating model for index: IX_supplier_s_acctbal_s_name_s_nationkey, actual cost: 0.022, predicted cost: 0.02197152733991581 ,loss incurred: 0.25247555894793083\n",
      "Updating model for index: IX_supplier_s_suppkey_s_comment_s_address, actual cost: 0.017, predicted cost: 0.016915876204450564 ,loss incurred: 0.25356990052869993\n",
      "Updating model for index: IX_supplier_s_name_s_suppkey_s_nationkey, actual cost: 0.028, predicted cost: 0.027836974485284438 ,loss incurred: 0.25558625679939445\n",
      "Updating model for index: IX_supplier_s_acctbal_s_phone_s_nationkey, actual cost: 0.025, predicted cost: 0.03017765757722435 ,loss incurred: 0.255633108282883\n",
      "Updating model for index: IX_supplier_s_comment_s_nationkey_s_acctbal, actual cost: 0.062, predicted cost: 0.06168027564549994 ,loss incurred: 0.25560638900140553\n",
      "Updating model for index: IX_supplier_s_address_s_nationkey, actual cost: 0.034, predicted cost: 0.036223659740358904 ,loss incurred: 0.25564208266504973\n",
      "Updating model for index: IX_partsupp_ps_partkey_ps_supplycost_ps_comment, actual cost: 1.687, predicted cost: 1.6869514773112546 ,loss incurred: 0.25643606196243685\n",
      "Updating model for index: IX_partsupp_ps_partkey_ps_supplycost_ps_suppkey, actual cost: 1.28, predicted cost: 1.2868062348400524 ,loss incurred: 0.2595686072773023\n",
      "Updating model for index: IX_partsupp_ps_suppkey_ps_availqty, actual cost: 1.315, predicted cost: 1.3147820597956605 ,loss incurred: 0.26710772974285285\n",
      "Updating model for index: IX_partsupp_ps_partkey_ps_suppkey, actual cost: 0.597, predicted cost: 0.5976383033166472 ,loss incurred: 0.26845704362937417\n",
      "Updating model for index: IX_partsupp_ps_supplycost_ps_availqty_ps_suppkey, actual cost: 1.611, predicted cost: 1.6355822694429247 ,loss incurred: 0.2896535276046097\n",
      "Updating model for index: IX_partsupp_ps_suppkey_ps_supplycost_ps_comment, actual cost: 2.448, predicted cost: 2.4502945656160002 ,loss incurred: 0.27399368279801145\n",
      "Updating model for index: IX_partsupp_ps_availqty_ps_suppkey_ps_comment, actual cost: 4.135, predicted cost: 4.115837475995273 ,loss incurred: 0.29021851895352874\n",
      "Updating model for index: IX_partsupp_ps_suppkey_ps_availqty_ps_supplycost, actual cost: 1.279, predicted cost: 1.426924760863653 ,loss incurred: 0.3166385876681875\n",
      "Updating model for index: IX_partsupp_ps_availqty_ps_comment_ps_suppkey, actual cost: 2.378, predicted cost: 2.4459858122866383 ,loss incurred: 0.2759833757249879\n",
      "Updating model for index: IX_partsupp_ps_supplycost_ps_comment_ps_availqty, actual cost: 2.75, predicted cost: 2.211023145742873 ,loss incurred: 0.5624304189820657\n",
      "Updating model for index: IX_nation_n_regionkey_n_comment, actual cost: 0.0, predicted cost: -2.0122326127136603e-05 ,loss incurred: 0.27219128456006286\n",
      "Updating model for index: IX_nation_n_regionkey_n_name, actual cost: 0.0, predicted cost: -0.00011872172541638193 ,loss incurred: 0.2723464684719389\n",
      "Updating model for index: IX_nation_n_regionkey_n_nationkey, actual cost: 0.0, predicted cost: -0.0004974177071375152 ,loss incurred: 0.27437385724247365\n",
      "Updating model for index: IX_nation_n_name_n_comment_n_regionkey, actual cost: 0.0, predicted cost: -9.12791113965028e-05 ,loss incurred: 0.27633177885347504\n",
      "Updating model for index: IX_nation_n_regionkey_n_comment_n_name, actual cost: 0.0, predicted cost: 0.07261559539926044 ,loss incurred: 0.2821201874930673\n",
      "Updating model for index: IX_nation_n_name_n_regionkey, actual cost: 0.0, predicted cost: -0.020584467540199824 ,loss incurred: 0.2773514821001123\n",
      "Updating model for index: IX_nation_n_comment_n_name_n_regionkey, actual cost: 0.0, predicted cost: -0.07178393469150013 ,loss incurred: 0.2719538274657334\n",
      "Updating model for index: IX_nation_n_name_n_nationkey_n_comment, actual cost: 0.0, predicted cost: 0.2300219800015013 ,loss incurred: 0.32106230023326277\n",
      "Updating model for index: IX_nation_n_comment_n_name_n_nationkey, actual cost: 0.0, predicted cost: -0.00383815859038128 ,loss incurred: 0.26815410295843317\n",
      "Updating model for index: IX_nation_n_nationkey_n_comment, actual cost: 0.0, predicted cost: 0.023944948760048157 ,loss incurred: 0.2759843930110202\n",
      "Updating model for index: IX_region_r_regionkey_r_name_r_comment, actual cost: 0.0, predicted cost: -1.938587599603636e-05 ,loss incurred: 0.2756331978445306\n",
      "Updating model for index: IX_region_r_name, actual cost: 0.0, predicted cost: -1.688694589363493e-05 ,loss incurred: 0.2757958829666447\n",
      "Updating model for index: IX_region_r_regionkey_r_comment, actual cost: 0.0, predicted cost: -0.00022275731632448448 ,loss incurred: 0.2760299412666335\n",
      "Updating model for index: IX_region_r_comment_r_name_r_regionkey, actual cost: 0.0, predicted cost: 0.008950837896714137 ,loss incurred: 0.26593417108577044\n",
      "Updating model for index: IX_region_r_name_r_regionkey_r_comment, actual cost: 0.0, predicted cost: 0.0623236766388402 ,loss incurred: 0.26932359198502936\n",
      "Updating model for index: IX_region_r_comment_r_name, actual cost: 0.0, predicted cost: 0.018894766097559135 ,loss incurred: 0.26557512886494544\n",
      "Updating model for index: IX_region_r_comment_r_regionkey, actual cost: 0.0, predicted cost: -0.04256941769771583 ,loss incurred: 0.26683140985598325\n",
      "Updating model for index: IX_region_r_regionkey_r_comment_r_name, actual cost: 0.0, predicted cost: 0.012350665533618077 ,loss incurred: 0.2651393507555273\n",
      "Updating model for index: IX_region_r_name_r_comment_r_regionkey, actual cost: 0.0, predicted cost: 0.029386970658834777 ,loss incurred: 0.2664881781010205\n",
      "Updating model for index: IX_region_r_comment_r_regionkey_r_name, actual cost: 0.0, predicted cost: -0.00021950082627597567 ,loss incurred: 0.2656242634554517\n"
     ]
    }
   ],
   "source": [
    "for index_id, cost in index_creation_cost.items():\n",
    "    index = all_indices[index_id]\n",
    "    model.update(index, cost, verbose=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clone_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
