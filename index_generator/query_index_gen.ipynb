{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-clustered Index configuration generator\n",
    "\n",
    "Given a query, we will use it's properties (predicates, payload) to generate a list of candidate index configuration that could benefit the execution of that query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import datetime\n",
    "import os\n",
    "import subprocess\n",
    "import uuid\n",
    "\n",
    "import pyodbc\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import re\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import itertools\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import IPython\n",
    "notebook_path = IPython.get_ipython().starting_dir\n",
    "target_subdirectory_path = os.path.abspath(os.path.join(os.path.dirname(notebook_path), 'database'))\n",
    "sys.path.append(target_subdirectory_path)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100\n"
     ]
    }
   ],
   "source": [
    "# read workload queries from JSON file\n",
    "def read_workload(workload_filepath):\n",
    "    workload = []\n",
    "    with open(workload_filepath) as f:\n",
    "        line = f.readline()\n",
    "        # read the queries from each line\n",
    "        while line:\n",
    "            workload.append(json.loads(line))\n",
    "            line = f.readline()\n",
    "\n",
    "    return workload\n",
    "\n",
    "# Base directory containing the generated queries\n",
    "workload_filepath = '../datagen/TPCH_workloads/TPCH_static_100_workload.json'\n",
    "\n",
    "# Read the workload queries from file\n",
    "workload = read_workload(workload_filepath)\n",
    "print(len(workload))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To generate candidate index configurations that may benefit a given query, can do the following:\n",
    "\n",
    "* Look at each table in that query (If the table is too small, then full table scan is cheap so don't need to index. Also, if a table has high \"selectivity\" and also contains INCLUDE columns, then most likely a large proportion of it's rows will be returned, so again full table scan will be cheap so don't need to index)\n",
    "* For each of these tables, look at the corresponding predicate columns (these are usually columns under the WHERE clause)    \n",
    "* Identify the INCLUDE columns, which are columns that are in the payload (payload columns are usually under the SELECT clause) but are not predicate columns, i.e. columns which are needed in the query result but are not used for filtering\n",
    "* Then generate multicolumn indexes without include columns by enumerating all permutations of the predicate columns, ranging from single-column permutations up to 6-column permutations (indexes on more than 6 columns becomes impractical) \n",
    "* Similarly, we generate multicolumn indexes by considering columns that are only in the payload but not in any predicate. Here, we don't need to consider all different column combinations, we can just make a single index for all payload columns for a given table in whatever order, this will mainly just serve as a covering index \n",
    "* Finally, we create indexes on tables with both predicate and payload columns. Here we consider indexes on all permutations of the predicate columns as index columns along with the include columns.\n",
    "* For each index, we also estimate it's value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index:\n",
    "    def __init__(self, table_name, index_id, index_columns, include_columns=(), value=None):\n",
    "        self.table_name = table_name\n",
    "        self.index_id = index_id\n",
    "        self.index_columns = index_columns\n",
    "        self.include_columns = include_columns\n",
    "        self.value = value\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Index({self.table_name}, {self.index_id}, {self.index_columns}, {self.include_columns}, {self.value})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables:\n",
      "Table: customer, Row Count: 150000, PK Columns: ['c_custkey']\n",
      "Table: orders, Row Count: 1500000, PK Columns: ['o_orderkey']\n",
      "Table: lineitem, Row Count: 6001215, PK Columns: ['l_linenumber', 'l_orderkey']\n",
      "Table: part, Row Count: 200000, PK Columns: ['p_partkey']\n",
      "Table: supplier, Row Count: 10000, PK Columns: ['s_suppkey']\n",
      "Table: partsupp, Row Count: 800000, PK Columns: ['ps_partkey', 'ps_suppkey']\n",
      "Table: nation, Row Count: 25, PK Columns: ['n_nationkey']\n",
      "Table: region, Row Count: 5, PK Columns: ['r_regionkey']\n",
      "\n",
      "All columns: (defaultdict(<class 'list'>, {'customer': ['c_acctbal', 'c_address', 'c_comment', 'c_custkey', 'c_mktsegment', 'c_name', 'c_nationkey', 'c_phone'], 'orders': ['o_clerk', 'o_comment', 'o_custkey', 'o_orderdate', 'o_orderkey', 'o_orderpriority', 'o_orderstatus', 'o_shippriority', 'o_totalprice'], 'lineitem': ['l_comment', 'l_commitdate', 'l_discount', 'l_extendedprice', 'l_linenumber', 'l_linestatus', 'l_orderkey', 'l_partkey', 'l_quantity', 'l_receiptdate', 'l_returnflag', 'l_shipdate', 'l_shipinstruct', 'l_shipmode', 'l_suppkey', 'l_tax'], 'part': ['p_brand', 'p_comment', 'p_container', 'p_mfgr', 'p_name', 'p_partkey', 'p_retailprice', 'p_size', 'p_type'], 'supplier': ['s_acctbal', 's_address', 's_comment', 's_name', 's_nationkey', 's_phone', 's_suppkey'], 'partsupp': ['ps_availqty', 'ps_comment', 'ps_partkey', 'ps_suppkey', 'ps_supplycost'], 'nation': ['n_comment', 'n_name', 'n_nationkey', 'n_regionkey'], 'region': ['r_comment', 'r_name', 'r_regionkey']}), 61)\n",
      "\n",
      "\n",
      "Query: \n",
      "select\n",
      "\ts_acctbal,\n",
      "\ts_name,\n",
      "\tn_name,\n",
      "\tp_partkey,\n",
      "\tp_mfgr,\n",
      "\ts_address,\n",
      "\ts_phone,\n",
      "\ts_comment\n",
      "from\n",
      "\tpart,\n",
      "\tsupplier,\n",
      "\tpartsupp,\n",
      "\tnation,\n",
      "\tregion\n",
      "where\n",
      "\tp_partkey = ps_partkey\n",
      "\tand s_suppkey = ps_suppkey\n",
      "\tand p_size = 26\n",
      "\tand p_type like '%NICKEL'\n",
      "\tand s_nationkey = n_nationkey\n",
      "\tand n_regionkey = r_regionkey\n",
      "\tand r_name = 'EUROPE'\n",
      "\tand ps_supplycost = (\n",
      "\t\tselect\n",
      "\t\t\tmin(ps_supplycost)\n",
      "\t\tfrom\n",
      "\t\t\tpartsupp,\n",
      "\t\t\tsupplier,\n",
      "\t\t\tnation,\n",
      "\t\t\tregion\n",
      "\t\twhere\n",
      "\t\t\tp_partkey = ps_partkey\n",
      "\t\t\tand s_suppkey = ps_suppkey\n",
      "\t\t\tand s_nationkey = n_nationkey\n",
      "\t\t\tand n_regionkey = r_regionkey\n",
      "\t\t\tand r_name = 'EUROPE'\n",
      "\t)\n",
      "order by\n",
      "\ts_acctbal desc,\n",
      "\tn_name,\n",
      "\ts_name,\n",
      "\tp_partkey\n",
      "\n",
      ";\n",
      "\n",
      "Payload: {'supplier': ['s_acctbal', 's_name', 's_address', 's_phone', 's_comment'], 'nation': ['n_name'], 'part': ['p_partkey', 'p_mfgr'], 'partsupp': ['ps_supplycost']}\n",
      "\n",
      "\n",
      "Table --> part, Predicate Columns --> {'p_type', 'p_size'}, table row count --> 200000\n",
      "Include columns: ['p_mfgr', 'p_partkey']\n",
      "Query selectivity: 0.0092183\n",
      "Column permutations: \n",
      "[('p_size', 'p_type'), ('p_type', 'p_size')]\n",
      "index_id: IX_part_p_size_p_type, index columns: ('p_size', 'p_type')\n",
      "index_id: IX_part_p_type_p_size, index columns: ('p_type', 'p_size')\n",
      "\n",
      "Table --> partsupp, Predicate Columns --> {'ps_suppkey', 'ps_partkey'}, table row count --> 800000\n",
      "Include columns: ['ps_supplycost']\n",
      "Query selectivity: 1.250025e-06\n",
      "Column permutations: \n",
      "[('ps_suppkey', 'ps_partkey'), ('ps_partkey', 'ps_suppkey')]\n",
      "index_id: IX_partsupp_ps_suppkey_ps_partkey, index columns: ('ps_suppkey', 'ps_partkey')\n",
      "index_id: IX_partsupp_ps_partkey_ps_suppkey, index columns: ('ps_partkey', 'ps_suppkey')\n",
      "\n",
      "Table --> supplier, Predicate Columns --> {'s_nationkey'}, table row count --> 10000\n",
      "Include columns: ['s_acctbal', 's_address', 's_phone', 's_comment', 's_name']\n",
      "Query selectivity: 0.0001\n",
      "Column permutations: \n",
      "[('s_nationkey',)]\n",
      "index_id: IX_supplier_s_nationkey, index columns: ('s_nationkey',)\n",
      "\n",
      "Table --> nation, Predicate Columns --> {'n_regionkey'}, table row count --> 25\n",
      "Include columns: ['n_name']\n",
      "Query selectivity: 0.04\n",
      "Full table scan for table: nation is cheap, skipping\n",
      "\n",
      "Table --> region, Predicate Columns --> {'r_name'}, table row count --> 5\n",
      "Include columns: []\n",
      "Query selectivity: 0.2\n",
      "Full table scan for table: region is cheap, skipping\n",
      "\n",
      "Table --> supplier, Payload Columns --> {'r_name'}, table row count --> 10000\n",
      "Payload columns are in the predicates, skipping\n",
      "\n",
      "Table --> nation, Payload Columns --> {'r_name'}, table row count --> 25\n",
      "Payload columns are in the predicates, skipping\n",
      "\n",
      "Table --> part, Payload Columns --> {'r_name'}, table row count --> 200000\n",
      "Payload columns are in the predicates, skipping\n",
      "\n",
      "Table --> partsupp, Payload Columns --> {'r_name'}, table row count --> 800000\n",
      "Payload columns are in the predicates, skipping\n",
      "\n",
      "Table --> part, Predicate Columns --> {'p_type', 'p_size'}, table row count --> 200000\n",
      "Include columns: ['p_mfgr', 'p_partkey']\n",
      "Column permutations: \n",
      "[('p_size', 'p_type'), ('p_type', 'p_size')]\n",
      "index_id: IX_part_p_size_p_type, index columns: ('p_size', 'p_type'), include columns: ['p_mfgr', 'p_partkey']\n",
      "index_id: IX_part_p_type_p_size, index columns: ('p_type', 'p_size'), include columns: ['p_mfgr', 'p_partkey']\n",
      "\n",
      "Table --> partsupp, Predicate Columns --> {'ps_suppkey', 'ps_partkey'}, table row count --> 800000\n",
      "Include columns: ['ps_supplycost']\n",
      "Column permutations: \n",
      "[('ps_suppkey', 'ps_partkey'), ('ps_partkey', 'ps_suppkey')]\n",
      "index_id: IX_partsupp_ps_suppkey_ps_partkey, index columns: ('ps_suppkey', 'ps_partkey'), include columns: ['ps_supplycost']\n",
      "index_id: IX_partsupp_ps_partkey_ps_suppkey, index columns: ('ps_partkey', 'ps_suppkey'), include columns: ['ps_supplycost']\n",
      "\n",
      "Table --> supplier, Predicate Columns --> {'s_nationkey'}, table row count --> 10000\n",
      "Include columns: ['s_acctbal', 's_address', 's_comment', 's_name', 's_phone']\n",
      "Column permutations: \n",
      "[('s_nationkey',)]\n",
      "index_id: IX_supplier_s_nationkey, index columns: ('s_nationkey',), include columns: ['s_acctbal', 's_address', 's_comment', 's_name', 's_phone']\n",
      "\n",
      "Table --> nation, Predicate Columns --> {'n_regionkey'}, table row count --> 25\n",
      "Full table scan for table: nation is cheap, skipping\n",
      "\n",
      "Table --> region, Predicate Columns --> {'r_name'}, table row count --> 5\n",
      "Full table scan for table: region is cheap, skipping\n"
     ]
    }
   ],
   "source": [
    "# constants\n",
    "SMALL_TABLE_IGNORE = 10000\n",
    "TABLE_MIN_SELECTIVITY = 0.2\n",
    "\n",
    "connection = start_connection() \n",
    "tables = get_all_tables(connection)\n",
    "all_columns = get_all_columns(connection)\n",
    "\n",
    "# get all tables in db\n",
    "print(f\"Tables:\")\n",
    "for key in tables:\n",
    "    print(tables[key])\n",
    "\n",
    "print(f\"\\nAll columns: {all_columns}\\n\")    \n",
    "\n",
    "# pick a query from the workload, get it's predicates and payload\n",
    "i = 1\n",
    "query = workload[i]\n",
    "# convert to proper query object\n",
    "query = Query(connection, query['template_id'], query['query_string'], query['payload'], query['predicates'], query['order_bys'])\n",
    "\n",
    "query_template_id = query.template_id\n",
    "query_predicates = query.predicates\n",
    "query_payload = query.payload\n",
    "print()\n",
    "print(f\"Query: {query.query_string}\")\n",
    "print()\n",
    "print(f\"Payload: {query_payload}\")\n",
    "print()\n",
    "\n",
    "indices = []\n",
    "\n",
    "# indexes on predicate columns only\n",
    "for table_name, table_predicates in query_predicates.items():\n",
    "    table = tables[table_name]\n",
    "    print(f\"\\nTable --> {table_name}, Predicate Columns --> {set(table_predicates)}, table row count --> {table.row_count}\")\n",
    "    \n",
    "    # identify include columns\n",
    "    include_columns = []\n",
    "    if table_name in query_payload:\n",
    "        include_columns = list(set(query_payload[table_name]) - set(table_predicates))\n",
    "\n",
    "    print(f\"Include columns: {include_columns}\")\n",
    "    print(f\"Query selectivity: {query.selectivity[table_name]}\")\n",
    "\n",
    "\n",
    "    # check if conditions for cheap full table scan are met\n",
    "    if table.row_count < SMALL_TABLE_IGNORE or ((query.selectivity[table_name] > TABLE_MIN_SELECTIVITY) and (len(include_columns)>0)):\n",
    "        print(f\"Full table scan for table: {table_name} is cheap, skipping\")\n",
    "        continue\n",
    "\n",
    "    # generate all possible permutations of predicate columns, from single column up to 6-column indices\n",
    "    table_predicates = list(table_predicates.keys())[0:6]\n",
    "    col_permutations = []\n",
    "    for num_columns in range(1, min(6, len(table_predicates)+1)):\n",
    "        col_permutations = list(itertools.permutations(table_predicates, num_columns)) \n",
    "    \n",
    "    print(f\"Column permutations: \\n{col_permutations}\")\n",
    "\n",
    "    # assign an id and value to each index/column permutation\n",
    "    for cp in col_permutations:\n",
    "        index_id = get_index_id(cp, table_name)\n",
    "        print(f\"index_id: {index_id}, index columns: {cp}\")\n",
    "        # assign value...\n",
    "        # create index object\n",
    "        index = Index(table_name, index_id, cp)\n",
    "        indices.append(index)\n",
    "\n",
    "\n",
    "\n",
    "# indexes on columns that are in the payload but not in the predicates\n",
    "for table_name, table_payload in query_payload.items():\n",
    "    table = tables[table_name]\n",
    "    print(f\"\\nTable --> {table_name}, Payload Columns --> {set(table_predicates)}, table row count --> {table.row_count}\")\n",
    "    \n",
    "    # skip if any of the payload columns for this table are in the predicates\n",
    "    if table_name in query_predicates:\n",
    "        print(f\"Payload columns are in the predicates, skipping\")\n",
    "        continue\n",
    "\n",
    "    # check if conditions for cheap full table scan are met\n",
    "    if table.row_count < SMALL_TABLE_IGNORE:\n",
    "        print(f\"Full table scan for table: {table_name} is cheap, skipping\")\n",
    "        continue   \n",
    "\n",
    "    # don't need to consider permutations here, just create an index with all payload columns in given order\n",
    "    index_id = get_index_id(table_payload, table_name)\n",
    "    print(f\"index_id: {index_id}, index columns: {table_payload}\")\n",
    "    # assign value... (will assign less value to these indices as they are less useful compared to predicate indices)\n",
    "    indices.append(Index(table_name, index_id, table_payload))\n",
    "\n",
    "# indexes with include columns\n",
    "for table_name, table_predicates in query_predicates.items():\n",
    "    table = tables[table_name]\n",
    "    print(f\"\\nTable --> {table_name}, Predicate Columns --> {set(table_predicates)}, table row count --> {table.row_count}\")\n",
    "    \n",
    "    # check if conditions for cheap full table scan are met\n",
    "    if table.row_count < SMALL_TABLE_IGNORE:\n",
    "        print(f\"Full table scan for table: {table_name} is cheap, skipping\")\n",
    "        continue  \n",
    "\n",
    "    # identify include columns\n",
    "    include_columns = []\n",
    "    if table_name in query_payload:\n",
    "        include_columns = sorted(list(set(query_payload[table_name]) - set(table_predicates)))\n",
    "\n",
    "    if len(include_columns)>0:    \n",
    "        print(f\"Include columns: {include_columns}\")\n",
    "\n",
    "        # generate all possible permutations of predicate columns, from single column up to 6-column indices\n",
    "        table_predicates = list(table_predicates.keys())[0:6]\n",
    "        col_permutations = list(itertools.permutations(table_predicates, len(table_predicates))) \n",
    "        \n",
    "        print(f\"Column permutations: \\n{col_permutations}\")\n",
    "\n",
    "        # assign an id and value to each index/column permutation\n",
    "        for cp in col_permutations:\n",
    "            index_id = get_index_id(cp, table_name)\n",
    "            print(f\"index_id: {index_id}, index columns: {cp}, include columns: {include_columns}\")\n",
    "            # assign value...\n",
    "            # create index object\n",
    "            index = Index(table_name, index_id, cp, tuple(include_columns))\n",
    "            indices.append(index)\n",
    "    \n",
    "\n",
    "close_connection(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(part, IX_part_p_size_p_type, ('p_size', 'p_type'), (), None)\n",
      "Index(part, IX_part_p_type_p_size, ('p_type', 'p_size'), (), None)\n",
      "Index(partsupp, IX_partsupp_ps_suppkey_ps_partkey, ('ps_suppkey', 'ps_partkey'), (), None)\n",
      "Index(partsupp, IX_partsupp_ps_partkey_ps_suppkey, ('ps_partkey', 'ps_suppkey'), (), None)\n",
      "Index(supplier, IX_supplier_s_nationkey, ('s_nationkey',), (), None)\n",
      "Index(part, IX_part_p_size_p_type, ('p_size', 'p_type'), ('p_mfgr', 'p_partkey'), None)\n",
      "Index(part, IX_part_p_type_p_size, ('p_type', 'p_size'), ('p_mfgr', 'p_partkey'), None)\n",
      "Index(partsupp, IX_partsupp_ps_suppkey_ps_partkey, ('ps_suppkey', 'ps_partkey'), ('ps_supplycost',), None)\n",
      "Index(partsupp, IX_partsupp_ps_partkey_ps_suppkey, ('ps_partkey', 'ps_suppkey'), ('ps_supplycost',), None)\n",
      "Index(supplier, IX_supplier_s_nationkey, ('s_nationkey',), ('s_acctbal', 's_address', 's_comment', 's_name', 's_phone'), None)\n"
     ]
    }
   ],
   "source": [
    "for index in indices:\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clone_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
