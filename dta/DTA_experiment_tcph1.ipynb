{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating index selection recommendations via MS SQL Database Tuning Adviser (DTA)\n",
    "\n",
    "We will use DTA to generate index recommendations on some sample TPC-H OLAP workloads. \n",
    "\n",
    "Given a workload containing N queries, we will split it up into m rounds (for simplicity we will split up evenly into disjoint subsets, we can also do overlapping). \n",
    "\n",
    "* Experiment 1: On each round, we will execute the queries in that round and measure performance.\n",
    "\n",
    "* Experiment 2: On each round, we will first use DTA to obtain recommendations, implement those recommendation (i.e. create/drop indices etc.), then execute the queries in that round and measure performance. To generate recommendations, we will use all queries that have been seen up to and including queries in the current round.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "import os\n",
    "import subprocess\n",
    "import uuid\n",
    "\n",
    "import pyodbc\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n"
     ]
    }
   ],
   "source": [
    "def read_sql_files(base_dir, instances_per_template):\n",
    "    queries = []\n",
    "    \n",
    "    # Regex to find erroneous \"where rownum <=\" lines\n",
    "    erroneous_line_pattern = re.compile(r'^\\s*where\\s+rownum\\s*<=\\s*\\d+\\s*;\\s*$', re.IGNORECASE)\n",
    "\n",
    "    # Loop through each query directory\n",
    "    for query_dir in sorted(os.listdir(base_dir)):\n",
    "        query_path = os.path.join(base_dir, query_dir)\n",
    "        \n",
    "        if os.path.isdir(query_path):\n",
    "            # Initialize a counter for the number of instances read from this template\n",
    "            instance_count = 0\n",
    "            \n",
    "            # Loop through each SQL file in the query directory\n",
    "            for sql_file in sorted(os.listdir(query_path)):\n",
    "                if instance_count >= instances_per_template:\n",
    "                    break  # Stop reading more files from this template\n",
    "                \n",
    "                sql_file_path = os.path.join(query_path, sql_file)\n",
    "                \n",
    "                if sql_file_path.endswith('.sql'):\n",
    "                    with open(sql_file_path, 'r') as file:\n",
    "                        lines = file.readlines()\n",
    "                        \n",
    "                        # Filter out the erroneous \"where rownum <=\" lines\n",
    "                        filtered_lines = [line for line in lines if not erroneous_line_pattern.match(line)]\n",
    "                        \n",
    "                        # Extract the query from the filtered lines\n",
    "                        query = ''.join(filtered_lines[3:]).strip()\n",
    "                        \n",
    "                        queries.append(query)\n",
    "                        instance_count += 1  # Increment the counter\n",
    "    \n",
    "    return queries\n",
    "\n",
    "\n",
    "# Base directory containing the generated queries\n",
    "base_dir = '../TPCH_generated_queries'\n",
    "\n",
    "# Read the SQL files and store the queries in a list\n",
    "queries = read_sql_files(base_dir, instances_per_template=20)\n",
    "\n",
    "print(len(queries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a workload file with all the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "workload_filename = 'workload_tpch_20.sql'\n",
    "\n",
    "# Write the queries to file\n",
    "with open(workload_filename, 'w') as file:\n",
    "    for query in queries:\n",
    "        file.write(query + '\\n\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define DTA recommender class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyodbc.Cursor object at 0x7f144f9c9530>\n"
     ]
    }
   ],
   "source": [
    "conn_str = (\n",
    "    \"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "    \"Server=172.16.6.196,1433;\"  # Use the IP address and port directly\n",
    "    \"Database=TPCH1;\"  \n",
    "    \"UID=wsl;\" \n",
    "    \"PWD=greatpond501;\"  \n",
    ")\n",
    "\n",
    "conn = pyodbc.connect(conn_str)\n",
    "cursor = conn.cursor()\n",
    "# test the connection\n",
    "print(cursor.execute(\"SELECT @@version;\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTA_recommender:\n",
    "    def __init__(self, queries, invoke_ta_rounds, verbose=False):\n",
    "        self.queries = queries # list of queries to be used as workload\n",
    "        self.invoke_ta_rounds = invoke_ta_rounds # list specifying the rounds to invoke TA\n",
    "        self.verbose = verbose\n",
    "        self.conn_string = (\"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "                            \"Server=172.16.6.196,1433;\"  # Use the IP address and port directly\n",
    "                            \"Database=TPCH1;\"  \n",
    "                            \"UID=wsl;\" \n",
    "                            \"PWD=greatpond501;\")\n",
    "        \n",
    "        self.server = \"172.16.6.196,1433\"\n",
    "        self.database = \"TPCH1\"\n",
    "        self.username = \"wsl\"\n",
    "        self.password = \"greatpond501\"\n",
    "\n",
    "        \n",
    "    def run_dta(self, num_rounds=1):\n",
    "\n",
    "        # establish connection to the database\n",
    "        self.conn = pyodbc.connect(self.conn_string)\n",
    "\n",
    "        # reset workload file\n",
    "        self.workload_file = \"workload_tpch1.sql\"\n",
    "        open(self.workload_file, 'w').close()\n",
    "\n",
    "        num_queries_per_round = len(self.queries) // num_rounds\n",
    "\n",
    "        # iterate over rounds\n",
    "        for i in range(num_rounds):\n",
    "            current_round_queries = self.queries[i*num_queries_per_round:(i+1)*num_queries_per_round]\n",
    "            # write the queries for current round to the workload file\n",
    "            with open(self.workload_file, 'a') as file:\n",
    "                for query in current_round_queries:\n",
    "                    file.write(query + '\\n\\n')\n",
    "\n",
    "            # invoke DTA if current round is in invoke_ta_rounds\n",
    "            if i in self.invoke_ta_rounds:\n",
    "                recommendation_cost_round, recommmendation_output_file = self.get_recommendations()      \n",
    "                if os.path.isfile(recommmendation_output_file):\n",
    "                    self.implement_recommendations(recommmendation_output_file)\n",
    "\n",
    "\n",
    "        # close the connection\n",
    "        self.conn.close()\n",
    "\n",
    "        \n",
    "    def get_recommendations(self):\n",
    "        session_name = f\"session_{uuid.uuid4()}\"\n",
    "        max_memory = 1024 # MB\n",
    "        max_time = 60 # seconds\n",
    "        recommendation_output_file = f\"recommendations_{session_name}.sql\"\n",
    "        session_output_xml_file = f\"session_output_{session_name}.xml\"        \n",
    "        dta_exe_path = '\"/mnt/c/Program Files (x86)/Microsoft SQL Server Management Studio 20/Common7/DTA.exe\"'\n",
    "        dta_command = f'{dta_exe_path} -S 172.16.6.196 -U wsl -P greatpond501 -D {self.database} -d {self.database} ' \\\n",
    "                    f'-if \"{self.workload_file}\" -s {session_name} ' \\\n",
    "                    f'-of \"{recommendation_output_file}\" ' \\\n",
    "                    f'-ox \"{session_output_xml_file}\" ' \\\n",
    "                    f'-fa NCL_IDX -fp NONE -fk CL_IDX -B {max_memory} -A {max_time} -F'\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "        subprocess.run(dta_command, shell=True)\n",
    "        end_time = datetime.datetime.now()\n",
    "        time_elapsed = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"DTA took {time_elapsed} seconds. Recommendations:\\n\")\n",
    "            # print the recommendations\n",
    "            with open(recommendation_output_file, 'r') as file:\n",
    "                recommendations = file.readlines()\n",
    "                for recommendation in recommendations:\n",
    "                    print(recommendation)\n",
    "                  \n",
    "        return time_elapsed, recommendation_output_file     \n",
    "\n",
    "\n",
    "    def implement_recommendations(self, recommendation_output_file):\n",
    "        with open(recommendation_output_file, 'r', encoding=\"utf-16\") as file:\n",
    "            query_lines = file.readlines()\n",
    "        sql = ' '.join(query_lines)\n",
    "        sql = sql.replace('go\\n', ';')            \n",
    "\n",
    "\n",
    "        #cursor = self.conn.cursor()\n",
    "        #cursor.execute(sql_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft (R) SQL Server dta\n",
      "Version 20.2.30.0\n",
      "Copyright (c) Microsoft. All rights reserved.\n",
      "\n",
      "Tuning session successfully created. Session ID is 1.\n",
      "\n",
      "Time elapsed: 00:00:00            \n",
      "Workload consumed:    0%, Estimated improvement:    0%                         \n",
      "Total time used: 00:00:00                                \n",
      "\n",
      "\n",
      "                                                                               \n",
      "                                                                                \n",
      "Tuning process finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The minimum storage space required for the existing physical design structures (PDS) you have selected to keep is larger than the storage space provided. Choose fewer PDS to keep, or set the storage space to be larger than 1173 MBs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTA took 18.633039 seconds. Recommendations:\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'recommendations_session_d98079ec-9406-4724-8988-e05e64f33b96.sql'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test dta\u001b[39;00m\n\u001b[1;32m      2\u001b[0m dta_recommender \u001b[38;5;241m=\u001b[39m DTA_recommender(queries, [\u001b[38;5;241m0\u001b[39m], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdta_recommender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_dta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 39\u001b[0m, in \u001b[0;36mDTA_recommender.run_dta\u001b[0;34m(self, num_rounds)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# invoke DTA if current round is in invoke_ta_rounds\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke_ta_rounds:\n\u001b[0;32m---> 39\u001b[0m     recommendation_cost_round, recommmendation_output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_recommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m      \n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(recommmendation_output_file):\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimplement_recommendations(recommmendation_output_file)\n",
      "Cell \u001b[0;32mIn[8], line 69\u001b[0m, in \u001b[0;36mDTA_recommender.get_recommendations\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDTA took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_elapsed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds. Recommendations:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# print the recommendations\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrecommendation_output_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     70\u001b[0m     recommendations \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m recommendation \u001b[38;5;129;01min\u001b[39;00m recommendations:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_clone_2/lib/python3.11/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'recommendations_session_d98079ec-9406-4724-8988-e05e64f33b96.sql'"
     ]
    }
   ],
   "source": [
    "# test dta\n",
    "dta_recommender = DTA_recommender(queries, [0], verbose=True)\n",
    "dta_recommender.run_dta(num_rounds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clone_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
