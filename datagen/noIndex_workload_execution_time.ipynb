{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring No-Index Query Execution Time\n",
    "\n",
    "For the TPCH-1GB database, we will now run batches of queries, i.e. small workloads, and measure the query execution time per workload. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read all the generated sample queries and store them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n"
     ]
    }
   ],
   "source": [
    "def read_sql_files(base_dir, instances_per_template):\n",
    "    queries = []\n",
    "    \n",
    "    # Regex to find erroneous \"where rownum <=\" lines\n",
    "    erroneous_line_pattern = re.compile(r'^\\s*where\\s+rownum\\s*<=\\s*\\d+\\s*;\\s*$', re.IGNORECASE)\n",
    "\n",
    "    # Loop through each query directory\n",
    "    for query_dir in sorted(os.listdir(base_dir)):\n",
    "        query_path = os.path.join(base_dir, query_dir)\n",
    "        \n",
    "        if os.path.isdir(query_path):\n",
    "            # Initialize a counter for the number of instances read from this template\n",
    "            instance_count = 0\n",
    "            \n",
    "            # Loop through each SQL file in the query directory\n",
    "            for sql_file in sorted(os.listdir(query_path)):\n",
    "                if instance_count >= instances_per_template:\n",
    "                    break  # Stop reading more files from this template\n",
    "                \n",
    "                sql_file_path = os.path.join(query_path, sql_file)\n",
    "                \n",
    "                if sql_file_path.endswith('.sql'):\n",
    "                    with open(sql_file_path, 'r') as file:\n",
    "                        lines = file.readlines()\n",
    "                        \n",
    "                        # Filter out the erroneous \"where rownum <=\" lines\n",
    "                        filtered_lines = [line for line in lines if not erroneous_line_pattern.match(line)]\n",
    "                        \n",
    "                        # Extract the query from the filtered lines\n",
    "                        query = ''.join(filtered_lines[3:]).strip()\n",
    "                        \n",
    "                        queries.append(query)\n",
    "                        instance_count += 1  # Increment the counter\n",
    "    \n",
    "    return queries\n",
    "\n",
    "\n",
    "# Base directory containing the generated queries\n",
    "base_dir = './TPCH_generated_queries'\n",
    "\n",
    "# Read the SQL files and store the queries in a list\n",
    "queries = read_sql_files(base_dir, instances_per_template=20)\n",
    "\n",
    "print(len(queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyodbc.Cursor object at 0x7fdc7aab91b0>\n"
     ]
    }
   ],
   "source": [
    "conn_str = (\n",
    "    \"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "    \"Server=172.16.6.196,1433;\"  # Use the IP address and port directly\n",
    "    \"Database=TPCH1;\"  \n",
    "    \"UID=wsl;\" \n",
    "    \"PWD=greatpond501;\"  \n",
    ")\n",
    "\n",
    "conn = pyodbc.connect(conn_str)\n",
    "cursor = conn.cursor()\n",
    "# test the connection\n",
    "print(cursor.execute(\"SELECT @@version;\"))\n",
    "\n",
    "\n",
    "def execute_queries(workload):\n",
    "    # Establish a connection to the database\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    start_time = time.time()\n",
    "    for i, query in enumerate(workload):\n",
    "        try:\n",
    "            cursor.execute(query)\n",
    "            conn.commit()\n",
    "            #print(f\"Query {i+1} executed successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing Query {i+1}: {e}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing Batches:   7%|â–‹         | 3/44 [00:58<13:37, 19.93s/it]"
     ]
    }
   ],
   "source": [
    "# shuffle the queries list\n",
    "random.shuffle(queries)\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "# now run the queries in batches and get execution times\n",
    "workload_times = []\n",
    "for i in tqdm(range(0, len(queries), batch_size), desc=\"Executing Batches\"):\n",
    "    batch = queries[i:i+batch_size]\n",
    "    elapsed_time = execute_queries(batch)\n",
    "    workload_times.append(elapsed_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clone_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
