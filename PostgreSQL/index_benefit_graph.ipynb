{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construction of Index Benefit Graph (from Schnaitter's PhD Thesis, 2011)\n",
    "\n",
    "***Definition***: The `IBG` of a query $q$ is a `DAG` in which each node $Y$ is a subset of $C$, a set of all relevant indexes that could ever be utlilized in the execution of $q$. Node $Y$ also stores the following two quantities: \n",
    "\n",
    "* $cost(q,Y)$ which is the query optimizer's estimated cost for executing $q$ under configuration $Y$  \n",
    "* $used(q,Y)$ which is the subset of indexes from $Y$ that are included in the query plan\n",
    "\n",
    "\n",
    "Recursive algorithm for constructing the IBG:\n",
    "\n",
    "```python\n",
    "construct_IBG(q, Y):\n",
    "    if Y.built:\n",
    "        return\n",
    "\n",
    "    # obtain estimated cost and determine indexes used\n",
    "    Y.cost = cost(q,Y)\n",
    "    Y.used = used(q,Y)\n",
    "    Y.built = True\n",
    "    \n",
    "    # create children (one for each index in Y.used)\n",
    "    for a in Y.used:\n",
    "        create child node: X = Y - {a}   # child node is set Y with index a removed\n",
    "        X.built = False\n",
    "        Y.add_child(X)\n",
    "        # recursively construct IBG on children\n",
    "        construct_IBG(q, X)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "# create root node\n",
    "Y = C\n",
    "Y.built = False\n",
    "\n",
    "# call construct_IBG(q, Y)\n",
    "construct_IBG(q, Y)\n",
    "```\n",
    "\n",
    "\n",
    "It is possible that some nodes may share the same child. Instead of creating a new node for that child for each different parent node, we can use a separate hash table to keep track of children that have already been created and reuse children which have already been created.\n",
    "\n",
    "Once the IBG has been constucted, we can use it to derive $cost(q, X)$ and $used(q, X)$ for any $X \\subseteq C$, even if $X$ is not in the IBG, as follows. We start from the root node in the IBG (which will contain all indexes in $X$ and possibly some additional ones not in X), iteratively traverse down to a child that corresponds to removal of a node not in $X$ until we reach a node $Y$ which is either a leaf or only contains nodes that are in $X$. Then $cost(q,X) = cost(q,Y)$ and $used(q, X) = used(q,Y)$.\n",
    "\n",
    "So the whole point of the IBG is that it gives us a compressed/efficient representation of the power-set of $C$ so that for any subset $X$ in the power-set we can compute  $cost(q, X)$ and $used(q, X)$ using the IBG, without having to maintain those quantities for every possible subset.\n",
    "\n",
    "(Later on, we will also see how to use the IGB to derive information about index interactions.)\n",
    "\n",
    "We can also use the IBG to compute the `maximum benefit` of any index $a \\in C$ as follows:\n",
    "\n",
    "$$\n",
    "\\beta = max_{X \\subseteq C} \\text{ benefit}_q(a, X)\n",
    "$$\n",
    "\n",
    "where $\\text{ benefit}_q(a, X) \\equiv cost(q,X) - cost(q,X \\cup \\set{a})$. Note that the maximization is over all possible subsets $X$, seems like a lot of work to evaluate the benefit for all of them. However, a simple and efficient way is to just find all the nodes $Y$ which don't contain the index $a$ and then just compute the benefit for all of these nodes and then get the max.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from ssb_qgen_class import *\n",
    "from pg_utils import *\n",
    "import itertools\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an SSB query generator object\n",
    "qg = QGEN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, id, indexes):\n",
    "        self.id = id\n",
    "        self.indexes = indexes\n",
    "        self.children = []\n",
    "        self.parents = []\n",
    "        self.built = False\n",
    "        self.cost = None\n",
    "        self.used = None\n",
    "\n",
    "\n",
    "# class for creating and storing the IBG\n",
    "class IBG:\n",
    "    def __init__(self, query_object, C=None):\n",
    "        self.q = query_object\n",
    "        if C is None:\n",
    "            # get all candidate indexes\n",
    "            self.C = extract_query_indexes(self.q, include_cols=True)\n",
    "        else:\n",
    "            self.C = C\n",
    "        print(f\"Number of candidate indexes: {len(self.C)}\")\n",
    "        #print(f\"Candidate indexes: {self.C}\")\n",
    "        \n",
    "        # map index_id to integer\n",
    "        self.idx2id = {index.index_id:i for i, index in enumerate(self.C)}\n",
    "        self.idx2index = {index.index_id:index for index in self.C}\n",
    "        \n",
    "        # create a hash table for keeping track of all created nodes\n",
    "        self.nodes = {}\n",
    "        # create a root node\n",
    "        self.root = Node(self.get_configuration_id(self.C), self.C)\n",
    "        self.nodes[self.root.id] = self.root\n",
    "        print(f\"Created root node with id: {self.root.id}\")\n",
    "        # start the IBG construction\n",
    "        print(\"Constructing IBG...\")\n",
    "        self.construct_ibg(self.root)\n",
    "        # compute all pair degree of interaction\n",
    "        print(f\"Computing all pair degree of interaction...\")\n",
    "        self.doi = self.compute_all_pair_doi()\n",
    "\n",
    "\n",
    "    # assign unique string id to a configuration\n",
    "    def get_configuration_id(self, indexes):\n",
    "        # get sorted list of integer ids\n",
    "        ids = sorted([self.idx2id[idx.index_id] for idx in indexes])\n",
    "        return \"_\".join([str(i) for i in ids])\n",
    "    \n",
    "\n",
    "    # obtain cost and used indexes for a given configuration\n",
    "    def _get_cost_used(self, indexes):\n",
    "        conn = create_connection()\n",
    "        # create hypothetical indexes\n",
    "        hypo_indexes = bulk_create_hypothetical_indexes(conn, indexes)\n",
    "        # map oid to index object\n",
    "        oid2index = {}\n",
    "        for i in range(len(hypo_indexes)):\n",
    "            oid2index[hypo_indexes[i][0]] = indexes[i]\n",
    "        # get cost and used indexes\n",
    "        cost, indexes_used = get_query_cost_estimate_hypo_indexes(conn, self.q.query_string, show_plan=False)\n",
    "        # map used index oids to index objects\n",
    "        used = [oid2index[oid] for oid,scan_type,scan_cost in indexes_used]\n",
    "        # drop hypothetical indexes\n",
    "        bulk_drop_hypothetical_indexes(conn)\n",
    "        close_connection(conn)   \n",
    "        return cost, used\n",
    "\n",
    "    # recursive IBG construction algorithm\n",
    "    def construct_ibg(self, Y):\n",
    "        if Y.built:\n",
    "            return \n",
    "        \n",
    "        # obtain query optimizers cost and used indexes\n",
    "        cost, used = self._get_cost_used(Y.indexes)\n",
    "        Y.cost = cost\n",
    "        Y.used = used\n",
    "        Y.built = True\n",
    "        \n",
    "        #print(f\"Creating node for configuration: {[idx.index_id for idx in Y.indexes]}\")\n",
    "        #print(f\"Cost: {cost}, Used indexes:\")\n",
    "        #for idx in used:\n",
    "        #    print(f\"{idx}\")\n",
    "\n",
    "        # create children\n",
    "        for a in Y.used:\n",
    "            # create a new configuration with index a removed from Y\n",
    "            X_indexes = [index for index in Y.indexes if index != a]\n",
    "            X_id = self.get_configuration_id(X_indexes)\n",
    "            \n",
    "            # if X is not in the hash table, create a new node and recursively build it\n",
    "            if X_id not in self.nodes:\n",
    "                X = Node(X_id, X_indexes)\n",
    "                X.parents.append(Y)\n",
    "                self.nodes[X_id] = X\n",
    "                Y.children.append(X)\n",
    "                self.construct_ibg(X)\n",
    "\n",
    "            else:\n",
    "                X = self.nodes[X_id]\n",
    "                Y.children.append(X)\n",
    "                X.parents.append(Y)\n",
    "\n",
    "\n",
    "    # use IBG to obtain estimated cost and used indexes for arbitrary subset of C\n",
    "    def get_cost_used(self, X):\n",
    "        # get id of the configuration\n",
    "        id = self.get_configuration_id(X)\n",
    "        # check if the configuration is in the IBG\n",
    "        if id in self.nodes:\n",
    "            cost, used = self.nodes[id].cost, self.nodes[id].used\n",
    "        \n",
    "        # if not in the IBG, traverse the IBG to find a covering node\n",
    "        else:\n",
    "            Y = self.find_covering_node(X)              \n",
    "            cost, used = Y.cost, Y.used\n",
    "\n",
    "        return cost, used    \n",
    "\n",
    "\n",
    "    # traverses the IBG to find a node that removes indexes not in X (i.e. a covering node for X)\n",
    "    def find_covering_node(self, X):\n",
    "        X_indexes = set([index.index_id for index in X])\n",
    "        Y = self.root\n",
    "        Y_indexes = set([index.index_id for index in Y.indexes])\n",
    "        # traverse IBG to find covering node\n",
    "        while (len(Y_indexes - X_indexes) != 0) or (len(Y.children) > 0):               \n",
    "            # traverse down to the child node that removes an index not in X\n",
    "            child_found = False\n",
    "            for child in Y.children:\n",
    "                child_indexes = set([index.index_id for index in child.indexes])\n",
    "                child_indexes_removed = Y_indexes - child_indexes\n",
    "                child_indexes_removed_not_in_X = child_indexes_removed - X_indexes\n",
    "        \n",
    "                # check if child removes an index not in X\n",
    "                if len(child_indexes_removed_not_in_X) > 0:\n",
    "                    Y = child\n",
    "                    Y_indexes = child_indexes\n",
    "                    child_found = True\n",
    "                    break\n",
    "\n",
    "            # if no children remove indexes not in X    \n",
    "            if not child_found:\n",
    "                break    \n",
    "    \n",
    "        return Y        \n",
    "\n",
    "    # compute benefit of an index for a given configuration \n",
    "    # input X is a list of index objects and 'a' is a single index object\n",
    "    # X must not contain 'a'\n",
    "    def compute_benefit(self, a, X):\n",
    "        if a in X:\n",
    "            # zero benefit if 'a' is already in X\n",
    "            #raise ValueError(\"Index 'a' is already in X\")\n",
    "            return 0\n",
    "        \n",
    "        # get cost  for X\n",
    "        cost_X = self.get_cost_used(X)[0]\n",
    "        # create a new configuration with index a added to X\n",
    "        X_a = X + [a]\n",
    "        # get cost for X + {a}\n",
    "        cost_X_a = self.get_cost_used(X_a)[0]\n",
    "        # compute benefit\n",
    "        benefit = cost_X - cost_X_a\n",
    "        return benefit \n",
    "\n",
    "\n",
    "    # compute maximum benefit of adding an index to any possibe configuration\n",
    "    def compute_max_benefit(self, a):\n",
    "        max_benefit = float('-inf')\n",
    "        for id, node in self.nodes.items():\n",
    "            #print(f\"Computing benefit for node: {[index.index_id for index in node.indexes]}\")\n",
    "            benefit = self.compute_benefit(a, node.indexes)\n",
    "            if benefit > max_benefit:\n",
    "                max_benefit = benefit\n",
    "\n",
    "        return max_benefit\n",
    "    \n",
    "    # compute the degree of interaction between two indexes a,b in configuration X \n",
    "    def compute_doi_configuration(self, a, b, X):\n",
    "        # X must not contain a or b\n",
    "        if a in X or b in X:\n",
    "            raise ValueError(\"a or b is already in X\")\n",
    "\n",
    "        doi = abs(self.compute_benefit(a, X) - self.compute_benefit(a, X + [b]))\n",
    "        doi /= self.get_cost_used(X + [a,b])[0]   \n",
    "        return doi\n",
    "   \n",
    "    \n",
    "    # computes the degree of interaction between all pairs of indexes (a,b) in candidate set C\n",
    "    # Note: doi is symmetric, i.e. doi(a,b) = doi(b,a)\n",
    "    def compute_all_pair_doi(self):\n",
    "        # hash table for storing doi values\n",
    "        doi = {}\n",
    "        # intialize doi values to zero\n",
    "        for i in range(len(self.C)):\n",
    "            for j in range(i+1, len(self.C)):\n",
    "                doi[(self.C[i].index_id, self.C[j].index_id)] = 0\n",
    "\n",
    "        S_idxs = set([index.index_id for index in self.C])\n",
    "\n",
    "        # iterate over each IBG node\n",
    "        for Y in self.nodes.values():\n",
    "            # remove Y.used from S\n",
    "            Y_idxs = set([index.index_id for index in Y.indexes])\n",
    "            S_Y = list(S_idxs - Y_idxs)\n",
    "            # iterate over all pairs of indexes in S_Y\n",
    "            for i in range(len(S_Y)):\n",
    "                for j in range(i+1, len(S_Y)):\n",
    "                    a_idx = S_Y[i]\n",
    "                    b_idx = S_Y[j]\n",
    "                     \n",
    "                    # find Ya covering node in IBG\n",
    "                    Ya = (Y_idxs - {a_idx, b_idx}) | {a_idx}\n",
    "                    Ya = [self.idx2index[idx] for idx in Ya]\n",
    "                    Ya = self.find_covering_node(Ya).indexes\n",
    "                    # find Yab covering node in IBG\n",
    "                    Yab = (Y_idxs - {a_idx, b_idx}) | {a_idx, b_idx}\n",
    "                    Yab = [self.idx2index[idx] for idx in Yab]\n",
    "                    Yab = self.find_covering_node(Yab).indexes\n",
    "\n",
    "                    used_Y = self.get_cost_used(Y.indexes)[1]\n",
    "                    used_Ya = self.get_cost_used(Ya)[1]\n",
    "                    used_Yab = self.get_cost_used(Yab)[1]\n",
    "                    \n",
    "                    Uab = set([index.index_id for index in used_Y]) | set([index.index_id for index in used_Ya]) | set([index.index_id for index in used_Yab]) \n",
    "                    # find Yb_minus covering node in IBG \n",
    "                    Yb_minus = list((Uab - {a_idx, b_idx}) | {b_idx})\n",
    "                    Yb_minus = [self.idx2index[idx] for idx in Yb_minus]\n",
    "                    Yb_minus = self.find_covering_node(Yb_minus).indexes\n",
    "                    # find Yb_plus covering node in IBG\n",
    "                    Yb_plus = list((Y_idxs - {a_idx, b_idx}) | {b_idx})\n",
    "                    Yb_plus = [self.idx2index[idx] for idx in Yb_plus]\n",
    "                    Yb_plus = self.find_covering_node(Yb_plus).indexes\n",
    "\n",
    "                    # generate quadruples\n",
    "                    quadruples = [(Y.indexes, Ya, Yb_minus, Yab), (Y.indexes, Ya, Yb_plus, Yab)]\n",
    "\n",
    "                    # compute doi using the quadruples\n",
    "                    for Y_indexes, Ya_indexes, Yb_indexes, Yab_indexes in quadruples:\n",
    "                        cost_Y = self.get_cost_used(Y_indexes)[0]\n",
    "                        cost_Ya = self.get_cost_used(Ya_indexes)[0]\n",
    "                        cost_Yb = self.get_cost_used(Yb_indexes)[0]\n",
    "                        cost_Yab = self.get_cost_used(Yab_indexes)[0]\n",
    "                        d = abs(cost_Y - cost_Ya - cost_Yb + cost_Yab) / cost_Yab\n",
    "                        if (a_idx, b_idx) in doi:\n",
    "                            doi[(a_idx,b_idx)] = max(doi[(a_idx,b_idx)], d)\n",
    "                        elif (b_idx, a_idx) in doi:\n",
    "                            doi[(b_idx,a_idx)] = max(doi[(b_idx,a_idx)], d)\n",
    "                        else:\n",
    "                            raise ValueError(\"Invalid pair of indexes\")    \n",
    "                            \n",
    "        \n",
    "        return doi\n",
    "\n",
    "\n",
    "    # get precomputed degree of interaction between a pair of indexes\n",
    "    def get_doi_pair(self, a, b):\n",
    "        if (a.index_id, b.index_id) in self.doi:\n",
    "            return self.doi[(a.index_id, b.index_id)]\n",
    "        elif (b.index_id, a.index_id) in self.doi:\n",
    "            return self.doi[(b.index_id, a.index_id)]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid pair of indexes\")\n",
    "\n",
    "\n",
    "    # function for printing the IBG, using BFS level order traversal\n",
    "    def print_ibg(self):\n",
    "        q = [self.root]\n",
    "        # traverse level by level, print all node ids in a level in a single line before moving to the next level\n",
    "        while len(q) > 0:\n",
    "            next_q = []\n",
    "            for node in q:\n",
    "                print(f\"{node.id} -> \", end=\"\")\n",
    "                for child in node.children:\n",
    "                    next_q.append(child)\n",
    "            print()\n",
    "            q = next_q  \n",
    "                     \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template id: 14, query: \n",
      "                SELECT lo_linenumber, lo_quantity, lo_orderdate  \n",
      "                FROM lineorder\n",
      "                WHERE lo_linenumber >= 4 AND lo_linenumber <= 5\n",
      "                AND lo_quantity = 32;\n",
      "            , payload: {'lineorder': ['lo_linenumber', 'lo_quantity', 'lo_orderdate']}, predicates: {'lineorder': ['lo_linenumber', 'lo_quantity']}, order by: {}, group by: {}\n"
     ]
    }
   ],
   "source": [
    "query = qg.generate_query(14)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidate indexes: 12\n",
      "Created root node with id: 0_1_2_3_4_5_6_7_8_9_10_11\n",
      "Constructing IBG...\n",
      "No index scans were explicitly noted in the query plan.\n",
      "No index scans were explicitly noted in the query plan.\n",
      "No index scans were explicitly noted in the query plan.\n",
      "No index scans were explicitly noted in the query plan.\n",
      "Computing all pair degree of interaction...\n",
      "0_1_2_3_4_5_6_7_8_9_10_11 -> \n",
      "0_1_2_3_4_5_6_7_8_9_10 -> \n",
      "0_1_2_3_4_5_6_8_9_10 -> \n",
      "0_1_2_3_4_5_6_8_10 -> \n",
      "0_1_2_4_5_6_8_10 -> \n",
      "0_1_2_4_5_6_8 -> \n",
      "1_2_4_5_6_8 -> 0_1_2_5_6_8 -> \n",
      "1_2_5_6_8 -> 0_1_2_5_8 -> \n",
      "1_2_5_8 -> 0_1_2_8 -> \n"
     ]
    }
   ],
   "source": [
    "# candidate indexes\n",
    "#C = extract_query_indexes(qg.generate_query(1), include_cols=True) + extract_query_indexes(qg.generate_query(5), include_cols=True)  + extract_query_indexes(qg.generate_query(14), include_cols=True)  \n",
    "C = extract_query_indexes(qg.generate_query(14), include_cols=True)  \n",
    "\n",
    "ibg = IBG(query, C)\n",
    "\n",
    "ibg.print_ibg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IX_lineorder_lo_linenumber': 0,\n",
       " 'IXN_lineorder_lo_linenumber_lo_o': 1,\n",
       " 'IXN_lineorder_lo_linenumber_lo_q': 2,\n",
       " 'IXN_lineorder_lo_linenumber_lo_o_lo_q': 3,\n",
       " 'IX_lineorder_lo_quantity': 4,\n",
       " 'IXN_lineorder_lo_quantity_lo_o': 5,\n",
       " 'IXN_lineorder_lo_quantity_lo_l': 6,\n",
       " 'IXN_lineorder_lo_quantity_lo_o_lo_l': 7,\n",
       " 'IX_lineorder_lo_linenumber_lo_quantity': 8,\n",
       " 'IXN_lineorder_lo_linenumber_lo_quantity_lo_o': 9,\n",
       " 'IX_lineorder_lo_quantity_lo_linenumber': 10,\n",
       " 'IXN_lineorder_lo_quantity_lo_linenumber_lo_o': 11}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibg.idx2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBG     --> Cost: 16869.05, Used indexes: ['IXN_lineorder_lo_quantity_lo_linenumber_lo_o']\n",
      "What-if --> Cost: 16869.05, Used indexes: ['IXN_lineorder_lo_quantity_lo_linenumber_lo_o']\n"
     ]
    }
   ],
   "source": [
    "# pick random subset of candidate indexes\n",
    "X = random.sample(ibg.C, 8)\n",
    "cost, used = ibg.get_cost_used(X)\n",
    "print(f\"IBG     --> Cost: {cost}, Used indexes: {[idx.index_id for idx in used]}\")\n",
    "\n",
    "cost, used = ibg._get_cost_used(X)\n",
    "print(f\"What-if --> Cost: {cost}, Used indexes: {[idx.index_id for idx in used]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum benefit of adding index IX_lineorder_lo_linenumber: 27423.550000000047\n",
      "DOI between indexes IX_lineorder_lo_linenumber and IX_lineorder_lo_quantity : 0.006491397802908922\n",
      "in configuration ['IXN_lineorder_lo_linenumber_lo_o', 'IXN_lineorder_lo_linenumber_lo_q', 'IXN_lineorder_lo_quantity_lo_o', 'IXN_lineorder_lo_quantity_lo_l', 'IX_lineorder_lo_linenumber_lo_quantity']\n",
      "DOI between indexes IX_lineorder_lo_linenumber and IX_lineorder_lo_quantity : 0.006491397802908922\n"
     ]
    }
   ],
   "source": [
    "# pick two indexes and a configuration\n",
    "a = ibg.C[0]\n",
    "b = ibg.C[4] \n",
    "X = [ibg.C[1], ibg.C[2], ibg.C[5], ibg.C[6], ibg.C[8]]\n",
    "\n",
    "# compute maximum benefit of adding index 'a' \n",
    "max_benefit = ibg.compute_max_benefit(a)\n",
    "print(f\"Maximum benefit of adding index {a.index_id}: {max_benefit}\")\n",
    "\n",
    "# compute degree of interaction between indexes 'a' and 'b' in configuration X\n",
    "doi = ibg.compute_doi_configuration(a, b, X)\n",
    "print(f\"DOI between indexes {a.index_id} and {b.index_id} : {doi}\")\n",
    "print(f\"in configuration {[idx.index_id for idx in X]}\")\n",
    "\n",
    "# compute configuration independent degree of interaction between indexes 'a' and 'b'\n",
    "doi = ibg.get_doi_pair(a, b)\n",
    "print(f\"DOI between indexes {a.index_id} and {b.index_id} : {doi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doi(IX_lineorder_lo_linenumber,   IXN_lineorder_lo_linenumber_lo_o) = 0\n",
      "doi(IX_lineorder_lo_linenumber,   IXN_lineorder_lo_linenumber_lo_q) = 0\n",
      "doi(IX_lineorder_lo_linenumber,   IXN_lineorder_lo_linenumber_lo_o_lo_q) = 0.03611588463751325\n",
      "doi(IX_lineorder_lo_linenumber,   IX_lineorder_lo_quantity) = 0.006491397802908922\n",
      "doi(IX_lineorder_lo_linenumber,   IXN_lineorder_lo_quantity_lo_o) = 0\n",
      "doi(IX_lineorder_lo_linenumber,   IXN_lineorder_lo_quantity_lo_l) = 0.012675581655948445\n",
      "doi(IX_lineorder_lo_linenumber,   IXN_lineorder_lo_quantity_lo_o_lo_l) = 0.4078833253685913\n",
      "doi(IX_lineorder_lo_linenumber,   IX_lineorder_lo_linenumber_lo_quantity) = 0\n",
      "doi(IX_lineorder_lo_linenumber,   IXN_lineorder_lo_linenumber_lo_quantity_lo_o) = 0.03972719784905223\n",
      "doi(IX_lineorder_lo_linenumber,   IX_lineorder_lo_quantity_lo_linenumber) = 0.02580542398563188\n",
      "doi(IX_lineorder_lo_linenumber,   IXN_lineorder_lo_quantity_lo_linenumber_lo_o) = 1.6256724593264023\n",
      "doi(IXN_lineorder_lo_linenumber_lo_o,   IXN_lineorder_lo_linenumber_lo_q) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_o,   IXN_lineorder_lo_linenumber_lo_o_lo_q) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_o,   IX_lineorder_lo_quantity) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_o,   IXN_lineorder_lo_quantity_lo_o) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_o,   IXN_lineorder_lo_quantity_lo_l) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_o,   IXN_lineorder_lo_quantity_lo_o_lo_l) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_o,   IX_lineorder_lo_linenumber_lo_quantity) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_o,   IXN_lineorder_lo_linenumber_lo_quantity_lo_o) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_o,   IX_lineorder_lo_quantity_lo_linenumber) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_o,   IXN_lineorder_lo_quantity_lo_linenumber_lo_o) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_q,   IXN_lineorder_lo_linenumber_lo_o_lo_q) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_q,   IX_lineorder_lo_quantity) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_q,   IXN_lineorder_lo_quantity_lo_o) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_q,   IXN_lineorder_lo_quantity_lo_l) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_q,   IXN_lineorder_lo_quantity_lo_o_lo_l) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_q,   IX_lineorder_lo_linenumber_lo_quantity) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_q,   IXN_lineorder_lo_linenumber_lo_quantity_lo_o) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_q,   IX_lineorder_lo_quantity_lo_linenumber) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_q,   IXN_lineorder_lo_quantity_lo_linenumber_lo_o) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_o_lo_q,   IX_lineorder_lo_quantity) = 0.03611588463751325\n",
      "doi(IXN_lineorder_lo_linenumber_lo_o_lo_q,   IXN_lineorder_lo_quantity_lo_o) = 0.023936582500199814\n",
      "doi(IXN_lineorder_lo_linenumber_lo_o_lo_q,   IXN_lineorder_lo_quantity_lo_l) = 0.023936582500199814\n",
      "doi(IXN_lineorder_lo_linenumber_lo_o_lo_q,   IXN_lineorder_lo_quantity_lo_o_lo_l) = 10.30370255679397\n",
      "doi(IXN_lineorder_lo_linenumber_lo_o_lo_q,   IX_lineorder_lo_linenumber_lo_quantity) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_o_lo_q,   IXN_lineorder_lo_linenumber_lo_quantity_lo_o) = 1.0035645112033795\n",
      "doi(IXN_lineorder_lo_linenumber_lo_o_lo_q,   IX_lineorder_lo_quantity_lo_linenumber) = 0.5127914345475573\n",
      "doi(IXN_lineorder_lo_linenumber_lo_o_lo_q,   IXN_lineorder_lo_quantity_lo_linenumber_lo_o) = 41.06675716771247\n",
      "doi(IX_lineorder_lo_quantity,   IXN_lineorder_lo_quantity_lo_o) = 0.012757863898860461\n",
      "doi(IX_lineorder_lo_quantity,   IXN_lineorder_lo_quantity_lo_l) = 0.012757863898860461\n",
      "doi(IX_lineorder_lo_quantity,   IXN_lineorder_lo_quantity_lo_o_lo_l) = 0.40788332536859045\n",
      "doi(IX_lineorder_lo_quantity,   IX_lineorder_lo_linenumber_lo_quantity) = 0\n",
      "doi(IX_lineorder_lo_quantity,   IXN_lineorder_lo_linenumber_lo_quantity_lo_o) = 0.03972719784905223\n",
      "doi(IX_lineorder_lo_quantity,   IX_lineorder_lo_quantity_lo_linenumber) = 0.02580542398563188\n",
      "doi(IX_lineorder_lo_quantity,   IXN_lineorder_lo_quantity_lo_linenumber_lo_o) = 1.6256724593264023\n",
      "doi(IXN_lineorder_lo_quantity_lo_o,   IXN_lineorder_lo_quantity_lo_l) = 0.012675581655948445\n",
      "doi(IXN_lineorder_lo_quantity_lo_o,   IXN_lineorder_lo_quantity_lo_o_lo_l) = 0.2703334825142289\n",
      "doi(IXN_lineorder_lo_quantity_lo_o,   IX_lineorder_lo_linenumber_lo_quantity) = 0\n",
      "doi(IXN_lineorder_lo_quantity_lo_o,   IXN_lineorder_lo_linenumber_lo_quantity_lo_o) = 0.02633005832087173\n",
      "doi(IXN_lineorder_lo_quantity_lo_o,   IX_lineorder_lo_quantity_lo_linenumber) = 0.017103102039015806\n",
      "doi(IXN_lineorder_lo_quantity_lo_o,   IXN_lineorder_lo_quantity_lo_linenumber_lo_o) = 1.0774495303529272\n",
      "doi(IXN_lineorder_lo_quantity_lo_l,   IXN_lineorder_lo_quantity_lo_o_lo_l) = 0.2703334825142298\n",
      "doi(IXN_lineorder_lo_quantity_lo_l,   IX_lineorder_lo_linenumber_lo_quantity) = 0\n",
      "doi(IXN_lineorder_lo_quantity_lo_l,   IXN_lineorder_lo_linenumber_lo_quantity_lo_o) = 0.02633005832087173\n",
      "doi(IXN_lineorder_lo_quantity_lo_l,   IX_lineorder_lo_quantity_lo_linenumber) = 0.017103102039015806\n",
      "doi(IXN_lineorder_lo_quantity_lo_l,   IXN_lineorder_lo_quantity_lo_linenumber_lo_o) = 1.0774495303529272\n",
      "doi(IXN_lineorder_lo_quantity_lo_o_lo_l,   IX_lineorder_lo_linenumber_lo_quantity) = 0\n",
      "doi(IXN_lineorder_lo_quantity_lo_o_lo_l,   IXN_lineorder_lo_linenumber_lo_quantity_lo_o) = 11.330334841949309\n",
      "doi(IXN_lineorder_lo_quantity_lo_o_lo_l,   IX_lineorder_lo_quantity_lo_linenumber) = 5.791331920651232\n",
      "doi(IXN_lineorder_lo_quantity_lo_o_lo_l,   IXN_lineorder_lo_quantity_lo_linenumber_lo_o) = 82.09379781315485\n",
      "doi(IX_lineorder_lo_linenumber_lo_quantity,   IXN_lineorder_lo_linenumber_lo_quantity_lo_o) = 0\n",
      "doi(IX_lineorder_lo_linenumber_lo_quantity,   IX_lineorder_lo_quantity_lo_linenumber) = 0\n",
      "doi(IX_lineorder_lo_linenumber_lo_quantity,   IXN_lineorder_lo_quantity_lo_linenumber_lo_o) = 0\n",
      "doi(IXN_lineorder_lo_linenumber_lo_quantity_lo_o,   IX_lineorder_lo_quantity_lo_linenumber) = 0.5640666698334215\n",
      "doi(IXN_lineorder_lo_linenumber_lo_quantity_lo_o,   IXN_lineorder_lo_quantity_lo_linenumber_lo_o) = 45.15853471298028\n",
      "doi(IX_lineorder_lo_quantity_lo_linenumber,   IXN_lineorder_lo_quantity_lo_linenumber_lo_o) = 23.082112507817577\n"
     ]
    }
   ],
   "source": [
    "for key, value in ibg.doi.items():\n",
    "    print(f\"doi({key[0]},   {key[1]}) = {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clone_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
