{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construction of Index Benefit Graph (from Schnaitter's PhD Thesis, 2011)\n",
    "\n",
    "***Definition***: The `IBG` of a query $q$ is a `DAG` in which each node $Y$ is a subset of $C$, a set of all relevant indexes that could ever be utlilized in the execution of $q$. Node $Y$ also stores the following two quantities: \n",
    "\n",
    "* $cost(q,Y)$ which is the query optimizer's estimated cost for executing $q$ under configuration $Y$  \n",
    "* $used(q,Y)$ which is the subset of indexes from $Y$ that are included in the query plan\n",
    "\n",
    "\n",
    "Recursive algorithm for constructing the IBG:\n",
    "\n",
    "```python\n",
    "construct_IBG(q, Y):\n",
    "    if Y.built:\n",
    "        return\n",
    "\n",
    "    # obtain estimated cost and determine indexes used\n",
    "    Y.cost = cost(q,Y)\n",
    "    Y.used = used(q,Y)\n",
    "    Y.built = True\n",
    "    \n",
    "    # create children (one for each index in Y.used)\n",
    "    for a in Y.used:\n",
    "        create child node: X = Y - {a}   # child node is set Y with index a removed\n",
    "        X.built = False\n",
    "        Y.add_child(X)\n",
    "        # recursively construct IBG on children\n",
    "        construct_IBG(q, X)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "# create root node\n",
    "Y = C\n",
    "Y.built = False\n",
    "\n",
    "# call construct_IBG(q, Y)\n",
    "construct_IBG(q, Y)\n",
    "```\n",
    "\n",
    "\n",
    "It is possible that some nodes may share the same child. Instead of creating a new node for that child for each different parent node, we can use a separate hash table to keep track of children that have already been created and reuse children which have already been created.\n",
    "\n",
    "Once the IBG has been constucted, we can use it to derive $cost(q, X)$ and $used(q, X)$ for any $X \\subseteq C$, even if $X$ is not in the IBG, as follows. We start from the root node in the IBG (which will contain all indexes in $X$ and possibly some additional ones not in X), iteratively traverse down to a child that corresponds to removal of a node not in $X$ until we reach a node $Y$ which only contains nodes that are in $X$. Then $cost(q,X) = cost(q,Y)$ and $used(q, X) = used(q,Y)$.\n",
    "\n",
    "So the whole point of the IBG is that it gives us a compressed/efficient representation of the power-set of $C$ so that for any subset $X$ in the power-set we can compute  $cost(q, X)$ and $used(q, X)$ using the IBG, without having to maintain those quantities for every possible subset.\n",
    "\n",
    "(Later on, we will also see how to use the IGB to derive information about index interactions.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from ssb_qgen_class import *\n",
    "from pg_utils import *\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an SSB query generator object\n",
    "qg = QGEN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, id, indexes):\n",
    "        self.id = id\n",
    "        self.indexes = indexes\n",
    "        self.children = []\n",
    "        self.parents = []\n",
    "        self.built = False\n",
    "        self.cost = None\n",
    "        self.used = None\n",
    "\n",
    "\n",
    "# class for creating and storing the IBG\n",
    "class IBG:\n",
    "    def __init__(self, query_string):\n",
    "        self.q = query_string\n",
    "        # get all candidate indexes\n",
    "        self.C = extract_query_indexes(self.q, include_cols=True)\n",
    "        #print(f\"Candidate indexes: {self.C}\")\n",
    "        # map index_id to integer\n",
    "        self.idx2id = {index.index_id:i for i, index in enumerate(self.C)}\n",
    "        \n",
    "        # create a hash table for keeping track of all created nodes\n",
    "        self.nodes = {}\n",
    "        # create a root node\n",
    "        self.root = Node(self.get_configuration_id(self.C), self.C)\n",
    "        self.nodes[self.root.id] = self.root\n",
    "        print(f\"Created root node with id: {self.root.id}\")\n",
    "\n",
    "\n",
    "    # assign unique string id to a configuration\n",
    "    def get_configuration_id(self, indexes):\n",
    "        # get sorted list of integer ids\n",
    "        ids = sorted([self.idx2id[idx.index_id] for idx in indexes])\n",
    "        return \"_\".join([str(i) for i in ids])\n",
    "    \n",
    "\n",
    "    def get_cost_used(self, indexes):\n",
    "        conn = create_connection()\n",
    "        # create hypothetical indexes\n",
    "        hypo_indexes = bulk_create_hypothetical_indexes(conn, indexes)\n",
    "        # map oid to index object\n",
    "        oid2index = {}\n",
    "        for i in range(len(hypo_indexes)):\n",
    "            oid2index[hypo_indexes[i][0]] = indexes[i]\n",
    "        # get cost and used indexes\n",
    "        cost, indexes_used = get_query_cost_estimate_hypo_indexes(conn, self.q, show_plan=False)\n",
    "        # map used index oids to index objects\n",
    "        used = [oid2index[oid] for oid,scan_type,scan_cos in indexes_used]\n",
    "        # drop hypothetical indexes\n",
    "        bulk_drop_hypothetical_indexes(conn)\n",
    "        close_connection(conn)   \n",
    "        return cost, used\n",
    "\n",
    "    # recursive IBG construction algorithm\n",
    "    def construct_ibg(self, Y):\n",
    "        if Y.built:\n",
    "            return \n",
    "        \n",
    "        # obtain query optimizers cost and used indexes\n",
    "        cost, used = self.get_cost_used(Y.indexes)\n",
    "        Y.cost = cost\n",
    "        Y.used = used\n",
    "        Y.built = True\n",
    "\n",
    "        # create children\n",
    "        for a in Y.used:\n",
    "            # create a new configuration with index a removed from Y\n",
    "            X_indexes = [index for index in Y.indexes if index != a]\n",
    "            X_id = self.get_configuration_id(X_indexes)\n",
    "            # if X is not in the hash table, create a new node and recursively build it\n",
    "            if X_id not in self.nodes:\n",
    "                X = Node(X_id, X_indexes)\n",
    "                X.parents.append(Y)\n",
    "                self.nodes[X_id] = X\n",
    "                Y.children.append(X)\n",
    "                self.construct_ibg(X)\n",
    "            else:\n",
    "                X = self.nodes[X_id]\n",
    "                Y.children.append(X)\n",
    "                X.parents.append(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template id: 14, query: \n",
      "                SELECT lo_linenumber, lo_quantity, lo_orderdate  \n",
      "                FROM lineorder\n",
      "                WHERE lo_linenumber >= 5 AND lo_linenumber <= 6\n",
      "                AND lo_quantity = 16;\n",
      "            , payload: {'lineorder': ['lo_linenumber', 'lo_quantity', 'lo_orderdate']}, predicates: {'lineorder': ['lo_linenumber', 'lo_quantity']}, order by: {}, group by: {}\n"
     ]
    }
   ],
   "source": [
    "query = qg.generate_query(14)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate indexes: [<pg_utils.Index object at 0x7fd2ca13e010>, <pg_utils.Index object at 0x7fd2ca162590>, <pg_utils.Index object at 0x7fd2ca161b90>, <pg_utils.Index object at 0x7fd2caf3c390>, <pg_utils.Index object at 0x7fd2caf3d3d0>, <pg_utils.Index object at 0x7fd2c9d61290>, <pg_utils.Index object at 0x7fd2c9d60610>, <pg_utils.Index object at 0x7fd2c9d63c90>, <pg_utils.Index object at 0x7fd2ca1218d0>, <pg_utils.Index object at 0x7fd2ca1208d0>, <pg_utils.Index object at 0x7fd2ca121210>, <pg_utils.Index object at 0x7fd2ca120a90>]\n",
      "Created root node with id: 0_1_2_3_4_5_6_7_8_9_10_11\n"
     ]
    }
   ],
   "source": [
    "ibg = IBG(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clone_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
