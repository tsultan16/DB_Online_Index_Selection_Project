{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Cost-Model for predicting query execution cost (assume disk IO dominates) and access paths selected \n",
    "\n",
    "\n",
    "Main steps in the cost model algorithm:\n",
    "\n",
    "1) Identify predicates (quatily and range) and payloads\n",
    "2) Enumerate all possible access paths (sequential scans, index scans, bitmap index scan + bitmap heap scan)\n",
    "3) Estimate selectivity for each predicate (i.e. what fraction of data needs to be accessed from a table)\n",
    "4) Estimate cardinality of each access path (using total number of rows and selectivity information)\n",
    "5) Estimate disk IO cost for each access path (for index scans, we use cardinality estimate to figure out how many pages need to be fetchs)\n",
    "6) Compare the estimated costs and choose best access paths for covering the query\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Some useful notes on access paths:\n",
    "* sequential scans --> better for low selectivity or if no suitable index available or if the table is really small\n",
    "* index scan --> better for high selectivity and simpler predicates\n",
    "* index only scan --> better for high selectivity and index is also a covering index and simpler predicates\n",
    "* bitmap index scan + bitmap heap scan --> better for medium selectivity and complex predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "from pg_utils import *\n",
    "from ssb_qgen_class import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Table Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'customer': 300000, 'dwdate': 2556, 'lineorder': 59986216, 'part': 800000, 'supplier': 20000}\n"
     ]
    }
   ],
   "source": [
    "def get_page_size():\n",
    "    return 8192  # 8 KB\n",
    "\n",
    "def get_table_stats(table_name):\n",
    "\n",
    "    conn = create_connection()\n",
    "\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Execute the query to get the estimated number of rows in the table\n",
    "        cur.execute(f\"\"\"\n",
    "                    SELECT reltuples::bigint AS estimated_rows\n",
    "                    FROM pg_class\n",
    "                    WHERE relname = '{table_name}';\n",
    "                    \"\"\")\n",
    "        estimated_rows = cur.fetchone()[0]\n",
    "    except:\n",
    "        print(f\"Error: Could not get the estimated number of rows in the '{table_name}' table.\")\n",
    "        estimated_rows = None\n",
    "\n",
    "    try:\n",
    "        # Query to get column statistics\n",
    "        cur.execute(f\"SELECT * FROM pg_stats WHERE tablename = '{table_name}';\")\n",
    "        column_stats = cur.fetchall()\n",
    "\n",
    "        # Define the column names based on the pg_stats view\n",
    "        column_names = [\n",
    "                        \"schemaname\", \"tablename\", \"attname\", \"inherited\", \"null_frac\",\n",
    "                        \"avg_width\", \"n_distinct\", \"most_common_vals\", \"most_common_freqs\",\n",
    "                        \"histogram_bounds\", \"correlation\", \"most_common_elems\",\n",
    "                        \"most_common_elem_freqs\", \"elem_count_histogram\"\n",
    "                    ]\n",
    "\n",
    "        # Organize the results into a dictionary\n",
    "        stats_dict = {}\n",
    "        for row in column_stats:\n",
    "            column_name = row[2]  # 'attname' is the third column in the result\n",
    "            stats_dict[column_name] = {column_names[i]: row[i] for i in range(len(column_names))}\n",
    "    except:\n",
    "        print(f\"Error: Could not get the statistics for the '{table_name}' table\")\n",
    "        stats_dict = None\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cur.close()\n",
    "    close_connection(conn)\n",
    "\n",
    "    return stats_dict, estimated_rows\n",
    "\n",
    "\n",
    "# Get the statistics for all tables in the SSB database\n",
    "table_names = [\"customer\", \"dwdate\", \"lineorder\", \"part\", \"supplier\"]\n",
    "stats = {}\n",
    "estimated_rows = {}\n",
    "for table_name in table_names:\n",
    "    stats[table_name], estimated_rows[table_name] = get_table_stats(table_name)\n",
    "\n",
    "\n",
    "# Print the organized statistics dictionary\n",
    "#for key, value in stats_dict.items():\n",
    "#    print(f\"{key}\")\n",
    "#    for k, v in value.items():\n",
    "#        print(f\"    {k}: {v}\")\n",
    "\n",
    "#print(f\"\\nEstimated number of rows in the 'customer' table: {estimated_rows}\")\n",
    "print(estimated_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c_custkey': 'numeric',\n",
       " 'c_name': 'char',\n",
       " 'c_address': 'char',\n",
       " 'c_city': 'char',\n",
       " 'c_nation': 'char',\n",
       " 'c_region': 'char',\n",
       " 'c_phone': 'char',\n",
       " 'c_mktsegment': 'char',\n",
       " 'd_datekey': 'char',\n",
       " 'd_date': 'char',\n",
       " 'd_dayofweek': 'char',\n",
       " 'd_month': 'char',\n",
       " 'd_year': 'numeric',\n",
       " 'd_yearmonthnum': 'numeric',\n",
       " 'd_yearmonth': 'char',\n",
       " 'd_daynuminweek': 'numeric',\n",
       " 'd_daynuminmonth': 'numeric',\n",
       " 'd_daynuminyear': 'numeric',\n",
       " 'd_monthnuminyear': 'numeric',\n",
       " 'd_weeknuminyear': 'numeric',\n",
       " 'd_sellingseason': 'char',\n",
       " 'd_lastdayinweekfl': 'numeric',\n",
       " 'd_lastdayinmonthfl': 'numeric',\n",
       " 'd_holidayfl': 'numeric',\n",
       " 'd_weekdayfl': 'numeric',\n",
       " 'lo_orderkey': 'numeric',\n",
       " 'lo_linenumber': 'numeric',\n",
       " 'lo_custkey': 'numeric',\n",
       " 'lo_partkey': 'numeric',\n",
       " 'lo_suppkey': 'numeric',\n",
       " 'lo_orderdate': 'char',\n",
       " 'lo_orderpriority': 'char',\n",
       " 'lo_shippriority': 'char',\n",
       " 'lo_quantity': 'numeric',\n",
       " 'lo_extendedprice': 'numeric',\n",
       " 'lo_ordtotalprice': 'numeric',\n",
       " 'lo_discount': 'numeric',\n",
       " 'lo_revenue': 'numeric',\n",
       " 'lo_supplycost': 'numeric',\n",
       " 'lo_tax': 'numeric',\n",
       " 'lo_commitdate': 'char',\n",
       " 'lo_shipmode': 'char',\n",
       " 'p_partkey': 'numeric',\n",
       " 'p_name': 'char',\n",
       " 'p_mfgr': 'char',\n",
       " 'p_category': 'char',\n",
       " 'p_brand': 'char',\n",
       " 'p_color': 'char',\n",
       " 'p_type': 'char',\n",
       " 'p_size': 'numeric',\n",
       " 'p_container': 'char',\n",
       " 's_suppkey': 'numeric',\n",
       " 's_name': 'char',\n",
       " 's_address': 'char',\n",
       " 's_city': 'char',\n",
       " 's_nation': 'char',\n",
       " 's_region': 'char',\n",
       " 's_phone': 'char'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssb_tables, pk_columns = get_ssb_schema()\n",
    "\n",
    "# create a dictionary and specify whether each attribute in each table is numeric or char\n",
    "data_type_dict = {}\n",
    "for table_name in [\"customer\", \"dwdate\", \"lineorder\", \"part\", \"supplier\"]:\n",
    "    for column_name, column_type in ssb_tables[table_name]:\n",
    "        if (\"INT\" in column_type) or (\"DECIMAL\" in column_type) or (\"BIT\" in column_type):\n",
    "            data_type_dict[column_name] = \"numeric\"\n",
    "        else:\n",
    "            data_type_dict[column_name] = \"char\"\n",
    "    \n",
    "data_type_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c_custkey': {'schemaname': 'public',\n",
       "  'tablename': 'customer',\n",
       "  'attname': 'c_custkey',\n",
       "  'inherited': False,\n",
       "  'null_frac': 0.0,\n",
       "  'avg_width': 4,\n",
       "  'n_distinct': -1.0,\n",
       "  'most_common_vals': None,\n",
       "  'most_common_freqs': None,\n",
       "  'histogram_bounds': '{6,2899,6114,8927,12227,15096,18002,21064,24084,27083,30233,33121,36597,39582,42470,45223,48127,50938,54109,56972,59898,62789,65654,68491,71562,74603,77584,80229,83386,86443,89528,92546,95625,98636,101754,104837,107890,111162,114410,117435,120672,123823,126668,129469,132808,135752,138847,141812,144740,147797,150948,153926,157031,159873,162949,165980,168812,172023,174986,177768,180770,183770,186610,189492,192193,195225,198284,201308,204255,207206,210257,213558,216737,219703,222943,225823,228723,231728,234660,237726,240430,243481,246317,249467,252487,255400,258396,261199,264278,267219,270075,273093,275941,279014,282138,285426,288188,291181,293711,296956,299991}',\n",
       "  'correlation': 1.0,\n",
       "  'most_common_elems': None,\n",
       "  'most_common_elem_freqs': None,\n",
       "  'elem_count_histogram': None},\n",
       " 'c_name': {'schemaname': 'public',\n",
       "  'tablename': 'customer',\n",
       "  'attname': 'c_name',\n",
       "  'inherited': False,\n",
       "  'null_frac': 0.0,\n",
       "  'avg_width': 19,\n",
       "  'n_distinct': -1.0,\n",
       "  'most_common_vals': None,\n",
       "  'most_common_freqs': None,\n",
       "  'histogram_bounds': '{Customer#000000006,Customer#000002899,Customer#000006114,Customer#000008927,Customer#000012227,Customer#000015096,Customer#000018002,Customer#000021064,Customer#000024084,Customer#000027083,Customer#000030233,Customer#000033121,Customer#000036597,Customer#000039582,Customer#000042470,Customer#000045223,Customer#000048127,Customer#000050938,Customer#000054109,Customer#000056972,Customer#000059898,Customer#000062789,Customer#000065654,Customer#000068491,Customer#000071562,Customer#000074603,Customer#000077584,Customer#000080229,Customer#000083386,Customer#000086443,Customer#000089528,Customer#000092546,Customer#000095625,Customer#000098636,Customer#000101754,Customer#000104837,Customer#000107890,Customer#000111162,Customer#000114410,Customer#000117435,Customer#000120672,Customer#000123823,Customer#000126668,Customer#000129469,Customer#000132808,Customer#000135752,Customer#000138847,Customer#000141812,Customer#000144740,Customer#000147797,Customer#000150948,Customer#000153926,Customer#000157031,Customer#000159873,Customer#000162949,Customer#000165980,Customer#000168812,Customer#000172023,Customer#000174986,Customer#000177768,Customer#000180770,Customer#000183770,Customer#000186610,Customer#000189492,Customer#000192193,Customer#000195225,Customer#000198284,Customer#000201308,Customer#000204255,Customer#000207206,Customer#000210257,Customer#000213558,Customer#000216737,Customer#000219703,Customer#000222943,Customer#000225823,Customer#000228723,Customer#000231728,Customer#000234660,Customer#000237726,Customer#000240430,Customer#000243481,Customer#000246317,Customer#000249467,Customer#000252487,Customer#000255400,Customer#000258396,Customer#000261199,Customer#000264278,Customer#000267219,Customer#000270075,Customer#000273093,Customer#000275941,Customer#000279014,Customer#000282138,Customer#000285426,Customer#000288188,Customer#000291181,Customer#000293711,Customer#000296956,Customer#000299991}',\n",
       "  'correlation': 1.0,\n",
       "  'most_common_elems': None,\n",
       "  'most_common_elem_freqs': None,\n",
       "  'elem_count_histogram': None},\n",
       " 'c_address': {'schemaname': 'public',\n",
       "  'tablename': 'customer',\n",
       "  'attname': 'c_address',\n",
       "  'inherited': False,\n",
       "  'null_frac': 0.0,\n",
       "  'avg_width': 16,\n",
       "  'n_distinct': -1.0,\n",
       "  'most_common_vals': None,\n",
       "  'most_common_freqs': None,\n",
       "  'histogram_bounds': '{\"  XiL1dCw,\",\" e4NF1GfP1lnE\",\",GjgG865y7DMdD\",\",z3yCO9ylwq\",0YRXE4xe3ISYdpFvdMy4xk,1DucrpmvZEFoPqpKMSNhtl,\"1vV6vK2FDgMBPT \",\"2aAM,npMkQqk\",3DgDWuE8B9Yo2EYXX,3rJQRlx2NmQ31P,4TFdZoAHRSdPcRX32AvYiz0R,59ssSOMl,\"5r,OndNy\",6UV7FoLFV54Z,\"76Yp YygWrtVbRBGDBNvr\",7l7Y5uITfPMfLQSJ20h5,\"8OpwwS,3nt34VqjZq,5,eh\",95GjT0NkmRwd,9mQqiAZbK4hLuN38,\"ANefBj 7QEpf\",B3dxTqCJGnKgMus4xyqkD,\"BiMceima Wbbzp\",\"CI5rL70eUppz,b1FXBu\",CuirIYLAhplqtkqNRISN9L,DVrdB4L3uiDj5Gj2pCZmFex,\"E6otouJV aZt1V\",\"EinsJ KzDqTgy2ho80PL4Z\",FLtzsuznsApGBI,\"G2,eE62qduXR\",Gf6ZaIWY,\"HH,CIqPM8\",Hz9dmGDY8nGz4NNopQaW,\"IbNwAozwq4,,GqdVkLorQ\",\"JE6GyuUTvAd2YmpgrgRqQY j\",\"JxC ZqS982dhQmGS5V\",KWN3nXyAPAt,L8douTRSxB,Ljzl1j,MRgqIlux,N3G7XPVKX2KOYbvCWtk,\"Ng6CB,c tAf1feSKZgaW\",\"OJK 5PxHNP,aAbIo6Ge\",\"P,gn0KPCLtHvaF\",PhTS3DRds7Xk6V2,\"QHq,mM4QXCPMSlnT1Y\",\"QtaE ukwWQW0x t\",RXJfbizJNgqJOuU,SClz1Hvm3Cf,Ssyqx4P9d0aa9cZG7cUBj0R,TTxq9K,\"U746q 2S JO\",\"Ul2izrS5AlJ,tC,zbaR\",VP8MIzc153E16YqiIpUxw,\"W,O1NA5\",WbjlTQEzxx4yZpOdQBPFM0v,\"XESkcR BzX9tnCESWB0xf\",\"XvPg9 oKawWnsx \",YX3kULHYp3yWPpn2h0,ZBYzrls5816hidNYDaTZuKc,\"ZspZ65H6eH4O \",\"aWXvvI,jT,N82btkZguXgN\",b8qTo3Sql543L0XSdT9EXV0a,bn7M7Xso4OlUoM3Q4U0veYA,cQFXcb0TjguISnj196CxS,\"d1JxfMsZWvGcSc,bQ \",\"dcafDM,dY ,GCB82,f0mFm\",\"eHAIV,81\",eteYGIx,fTUZMGhwhZhR4O,\"g8,9cHVfxiOuYqpyqA7\",\"gmcpo6UEU,LpiDYHaFTub\",\"hOcj,eSH6bCnrKc\",\"i3gd,EIfNL4esXq1SOm\",\"ik,XVe\",jKWa0eF3e,jzdZSI8PoN6ctzi1Al6tCD,kdDDWQX3nFwsu,\"lE6qa9vf7dHiYODyPS  4r7\",\"ls,wPyVEP3S1cGTN6Zzl0 \",\"mVVP19GKqL7KIt,MsNlkUPy\",n8ZeO8U6uwvB,no14oHP,oQYF0jRdkjw,p2SaM7,\"pfi7rSA87mTWexGq8fp \",qGKRqfONyu7FKa3Lqr,\"qsoSpV cPu VLit20 \",rU487oO5ZpVoSA0z,s8y3YDMpTFm,som92MDIkAr,tPK3Da,u7Vr6NC1WablTBi,umP7TJmX,\"vQpqXQrJRU,Mfsix0iPSWf9A\",\"w5,bdz\",wmEOT3,\"xQ9RZmM8h,daomIYTwyfm\",y4C79rfnAIZokVJ,yetDGfskjdr23tcjtO8wPI,zJZtLMcO3h,zzxVi8zZ17Br}',\n",
       "  'correlation': 0.004336422,\n",
       "  'most_common_elems': None,\n",
       "  'most_common_elem_freqs': None,\n",
       "  'elem_count_histogram': None},\n",
       " 'c_city': {'schemaname': 'public',\n",
       "  'tablename': 'customer',\n",
       "  'attname': 'c_city',\n",
       "  'inherited': False,\n",
       "  'null_frac': 0.0,\n",
       "  'avg_width': 11,\n",
       "  'n_distinct': 250.0,\n",
       "  'most_common_vals': '{\"ETHIOPIA 7\",\"JORDAN   4\",\"SAUDI ARA2\",\"IRAQ     5\",\"FRANCE   3\",\"FRANCE   4\",INDONESIA6,\"IRAN     6\"}',\n",
       "  'most_common_freqs': [0.0053333333,\n",
       "   0.0049333335,\n",
       "   0.0049333335,\n",
       "   0.0049,\n",
       "   0.0048666666,\n",
       "   0.0048666666,\n",
       "   0.0048666666,\n",
       "   0.004766667],\n",
       "  'histogram_bounds': '{\"ALGERIA  0\",\"ALGERIA  2\",\"ALGERIA  4\",\"ALGERIA  6\",\"ALGERIA  9\",ARGENTINA1,ARGENTINA4,ARGENTINA6,ARGENTINA9,\"BRAZIL   1\",\"BRAZIL   3\",\"BRAZIL   6\",\"BRAZIL   8\",\"CANADA   1\",\"CANADA   3\",\"CANADA   6\",\"CANADA   8\",\"CHINA    1\",\"CHINA    3\",\"CHINA    6\",\"CHINA    8\",\"EGYPT    1\",\"EGYPT    3\",\"EGYPT    6\",\"EGYPT    8\",\"ETHIOPIA 1\",\"ETHIOPIA 3\",\"ETHIOPIA 6\",\"ETHIOPIA 9\",\"FRANCE   1\",\"FRANCE   6\",\"FRANCE   8\",\"GERMANY  1\",\"GERMANY  3\",\"GERMANY  6\",\"GERMANY  8\",\"INDIA    0\",\"INDIA    3\",\"INDIA    5\",\"INDIA    7\",INDONESIA0,INDONESIA2,INDONESIA4,INDONESIA8,\"IRAN     0\",\"IRAN     2\",\"IRAN     5\",\"IRAN     8\",\"IRAQ     0\",\"IRAQ     3\",\"IRAQ     6\",\"IRAQ     9\",\"JAPAN    1\",\"JAPAN    4\",\"JAPAN    6\",\"JAPAN    9\",\"JORDAN   1\",\"JORDAN   3\",\"JORDAN   7\",\"JORDAN   9\",\"KENYA    2\",\"KENYA    4\",\"KENYA    6\",\"KENYA    9\",\"MOROCCO  1\",\"MOROCCO  4\",\"MOROCCO  7\",\"MOROCCO  9\",MOZAMBIQU1,MOZAMBIQU4,MOZAMBIQU6,MOZAMBIQU8,\"PERU     1\",\"PERU     3\",\"PERU     6\",\"PERU     8\",\"ROMANIA  1\",\"ROMANIA  3\",\"ROMANIA  5\",\"ROMANIA  8\",\"RUSSIA   0\",\"RUSSIA   3\",\"RUSSIA   6\",\"RUSSIA   8\",\"SAUDI ARA0\",\"SAUDI ARA4\",\"SAUDI ARA6\",\"SAUDI ARA9\",\"UNITED KI1\",\"UNITED KI3\",\"UNITED KI6\",\"UNITED KI8\",\"UNITED ST0\",\"UNITED ST3\",\"UNITED ST5\",\"UNITED ST7\",\"VIETNAM  0\",\"VIETNAM  2\",\"VIETNAM  4\",\"VIETNAM  7\",\"VIETNAM  9\"}',\n",
       "  'correlation': -0.006651641,\n",
       "  'most_common_elems': None,\n",
       "  'most_common_elem_freqs': None,\n",
       "  'elem_count_histogram': None},\n",
       " 'c_nation': {'schemaname': 'public',\n",
       "  'tablename': 'customer',\n",
       "  'attname': 'c_nation',\n",
       "  'inherited': False,\n",
       "  'null_frac': 0.0,\n",
       "  'avg_width': 8,\n",
       "  'n_distinct': 25.0,\n",
       "  'most_common_vals': '{INDONESIA,INDIA,\"UNITED KINGDOM\",\"UNITED STATES\",ETHIOPIA,MOZAMBIQUE,IRAN,JORDAN,ALGERIA,ROMANIA,FRANCE,\"SAUDI ARABIA\",IRAQ,ARGENTINA,KENYA,GERMANY,VIETNAM,BRAZIL,CANADA,PERU,JAPAN,CHINA,EGYPT,MOROCCO,RUSSIA}',\n",
       "  'most_common_freqs': [0.0422,\n",
       "   0.042066667,\n",
       "   0.041366667,\n",
       "   0.041233335,\n",
       "   0.041,\n",
       "   0.041,\n",
       "   0.040933333,\n",
       "   0.040866666,\n",
       "   0.040733334,\n",
       "   0.040633332,\n",
       "   0.040466666,\n",
       "   0.040266667,\n",
       "   0.040166665,\n",
       "   0.0401,\n",
       "   0.039866667,\n",
       "   0.039766666,\n",
       "   0.039333332,\n",
       "   0.039166667,\n",
       "   0.039133333,\n",
       "   0.039,\n",
       "   0.038933333,\n",
       "   0.038566668,\n",
       "   0.038033333,\n",
       "   0.037866667,\n",
       "   0.0373],\n",
       "  'histogram_bounds': None,\n",
       "  'correlation': 0.02925807,\n",
       "  'most_common_elems': None,\n",
       "  'most_common_elem_freqs': None,\n",
       "  'elem_count_histogram': None},\n",
       " 'c_region': {'schemaname': 'public',\n",
       "  'tablename': 'customer',\n",
       "  'attname': 'c_region',\n",
       "  'inherited': False,\n",
       "  'null_frac': 0.0,\n",
       "  'avg_width': 7,\n",
       "  'n_distinct': 5.0,\n",
       "  'most_common_vals': '{ASIA,AFRICA,\"MIDDLE EAST\",EUROPE,AMERICA}',\n",
       "  'most_common_freqs': [0.2011,\n",
       "   0.20046666,\n",
       "   0.20026666,\n",
       "   0.19953333,\n",
       "   0.19863333],\n",
       "  'histogram_bounds': None,\n",
       "  'correlation': 0.19702664,\n",
       "  'most_common_elems': None,\n",
       "  'most_common_elem_freqs': None,\n",
       "  'elem_count_histogram': None},\n",
       " 'c_phone': {'schemaname': 'public',\n",
       "  'tablename': 'customer',\n",
       "  'attname': 'c_phone',\n",
       "  'inherited': False,\n",
       "  'null_frac': 0.0,\n",
       "  'avg_width': 16,\n",
       "  'n_distinct': -1.0,\n",
       "  'most_common_vals': None,\n",
       "  'most_common_freqs': None,\n",
       "  'histogram_bounds': '{10-100-876-3009,10-317-681-4090,10-520-471-5608,10-754-261-4158,10-985-169-4549,11-306-841-7655,11-523-465-2591,11-754-492-7028,11-981-323-5248,12-319-383-9128,12-538-934-6603,12-780-849-2278,12-999-569-1271,13-342-878-2795,13-558-604-3250,13-798-513-9363,14-121-638-3969,14-343-927-9216,14-589-188-8236,14-827-889-4321,15-163-758-7030,15-366-176-6093,15-582-206-7674,15-819-477-7568,16-149-790-1853,16-372-133-3144,16-578-895-1399,16-813-242-5329,17-133-240-6327,17-362-896-2136,17-581-189-1574,17-816-935-5667,18-133-999-9010,18-357-973-6405,18-581-943-1457,18-799-657-2074,18-989-813-9214,19-300-332-2545,19-520-657-9845,19-736-860-8524,19-943-260-2276,20-269-293-6469,20-485-625-1173,20-713-153-5267,20-908-982-1574,21-233-982-1981,21-437-353-6214,21-657-342-8475,21-911-293-1133,22-252-983-9186,22-464-787-2885,22-694-613-2392,22-934-407-7725,23-278-430-3058,23-488-459-2008,23-693-337-8692,23-927-260-2556,24-257-999-7179,24-507-628-6107,24-706-824-9739,24-930-703-7452,25-254-534-3464,25-495-541-3011,25-732-186-5706,25-970-487-7345,26-281-370-9430,26-503-769-3929,26-729-569-9186,26-943-145-1012,27-284-458-7034,27-514-711-2332,27-748-644-6345,27-957-663-4590,28-309-622-5173,28-551-567-4204,28-778-185-8236,29-102-144-8472,29-337-968-6986,29-551-102-1940,29-762-725-3129,29-987-764-9868,30-331-870-9836,30-549-999-2982,30-771-337-5799,30-980-552-2127,31-297-569-2642,31-536-667-3582,31-765-113-8603,31-999-347-2356,32-326-461-5036,32-567-870-5035,32-804-669-2318,33-154-942-4832,33-360-620-8294,33-568-601-3235,33-794-980-9752,34-126-779-9836,34-335-935-7978,34-544-911-7607,34-776-334-8343,34-998-509-2114}',\n",
       "  'correlation': -0.006848719,\n",
       "  'most_common_elems': None,\n",
       "  'most_common_elem_freqs': None,\n",
       "  'elem_count_histogram': None},\n",
       " 'c_mktsegment': {'schemaname': 'public',\n",
       "  'tablename': 'customer',\n",
       "  'attname': 'c_mktsegment',\n",
       "  'inherited': False,\n",
       "  'null_frac': 0.0,\n",
       "  'avg_width': 9,\n",
       "  'n_distinct': 5.0,\n",
       "  'most_common_vals': '{FURNITURE,BUILDING,AUTOMOBILE,HOUSEHOLD,MACHINERY}',\n",
       "  'most_common_freqs': [0.20446667, 0.2014, 0.2011, 0.19656667, 0.19646667],\n",
       "  'histogram_bounds': None,\n",
       "  'correlation': 0.20046608,\n",
       "  'most_common_elems': None,\n",
       "  'most_common_elem_freqs': None,\n",
       "  'elem_count_histogram': None}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats['customer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating Selectivity for a value range on a particular column, i.e. what fraction of the data (i.e. tuples) fall in the given range, using the Table Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_selectivity_range(attribute, value_range, stats_dict, total_rows):\n",
    "    data_type = data_type_dict[attribute]\n",
    "    # get the column statistics\n",
    "    stats = stats_dict[attribute]\n",
    "    # get the histogram bounds\n",
    "    histogram_bounds = stats['histogram_bounds']\n",
    "    n_distinct = stats['n_distinct']\n",
    "    most_common_vals = stats['most_common_vals']\n",
    "    most_common_freqs = stats['most_common_freqs']\n",
    "\n",
    "    # convert most_common_values string to list of correct data type\n",
    "    if most_common_vals:\n",
    "        if data_type == 'numeric':\n",
    "            most_common_vals = [float(x) for x in most_common_vals.strip('{}').split(',')]\n",
    "        elif data_type == 'char':\n",
    "            most_common_vals = [x for x in most_common_vals.strip('{}').split(',')]    \n",
    "        else:\n",
    "            raise ValueError(\"Data type not supported, needs ot be either numeric or char\")\n",
    "\n",
    "    # Convert negative n_distinct to an absolute count\n",
    "    if n_distinct < 0:\n",
    "        n_distinct = -n_distinct * total_rows\n",
    "\n",
    "    min_value = value_range[0]\n",
    "    max_value = value_range[1]\n",
    "    selectivity = 0.0\n",
    "\n",
    "    # check for overlap with most common values\n",
    "    if most_common_vals:\n",
    "        for val, freq in zip(most_common_vals, most_common_freqs):\n",
    "            if min_value <= val <= max_value:\n",
    "                selectivity += freq    \n",
    "\n",
    "    if histogram_bounds is not None:\n",
    "        if data_type == 'numeric':\n",
    "            histogram_bounds = [float(x) for x in histogram_bounds.strip('{}').split(',')] # convert to list of integers\n",
    "        elif data_type == 'char':\n",
    "            histogram_bounds = [x for x in histogram_bounds.strip('{}').split(',')]\n",
    "        else:\n",
    "            raise ValueError(\"Data type not supported, needs ot be either numeric or char\")    \n",
    "\n",
    "        total_bins = len(histogram_bounds) - 1\n",
    "\n",
    "        # iterate over bins, find overlapping bins\n",
    "        for i in range(total_bins):\n",
    "            bin_lower_bound = histogram_bounds[i]\n",
    "            bin_upper_bound = histogram_bounds[i+1]\n",
    "\n",
    "            # check for range overlap\n",
    "            if min_value < bin_lower_bound or max_value > bin_upper_bound:\n",
    "                # does not overlap\n",
    "                continue    \n",
    "\n",
    "            # calculate the overlap fraction within this bin\n",
    "            overlap_min = max(min_value, bin_lower_bound)\n",
    "            overlap_max = min(max_value, bin_upper_bound)\n",
    "            overlap_fraction = (overlap_max - overlap_min) / (bin_upper_bound - bin_lower_bound)\n",
    "\n",
    "            #print(f\"Overlap fraction for bin {i}: {overlap_fraction}\")\n",
    "            #print(f\"Bin bounds: {bin_lower_bound}, {bin_upper_bound}\")\n",
    "\n",
    "            # accumulate to the total selectivity\n",
    "            # Assume each bin represents an equal fraction of the total rows\n",
    "            selectivity += overlap_fraction * (1.0 / total_bins)\n",
    "\n",
    "    if selectivity == 0.0:\n",
    "        # if no overlap with most common values or histogram bins, assume uniform distribution and estimate selectivity\n",
    "        selectivity = 1.0 / n_distinct       \n",
    "\n",
    "    return selectivity\n",
    "\n",
    "\n",
    "def estimate_selectivity_eq(attribute, value, stats_dict):\n",
    "    data_type = data_type_dict[attribute]\n",
    "    # get the column statistics\n",
    "    stats = stats_dict[attribute]\n",
    "    # get the histogram bounds\n",
    "    histogram_bounds = stats['histogram_bounds']\n",
    "    n_distinct = stats['n_distinct']\n",
    "    most_common_vals = stats['most_common_vals']\n",
    "    most_common_freqs = stats['most_common_freqs']\n",
    "\n",
    "    # convert most_common_values string to list of correct data type\n",
    "    if most_common_vals:\n",
    "        if data_type == 'numeric':\n",
    "            most_common_vals = [float(x) for x in most_common_vals.strip('{}').split(',')]\n",
    "        elif data_type == 'char':\n",
    "            most_common_vals = [x for x in most_common_vals.strip('{}').split(',')]    \n",
    "        else:\n",
    "            raise ValueError(\"Data type not supported, needs ot be either numeric or char\")\n",
    "\n",
    "    # first check if the value is in the most common values\n",
    "    if most_common_vals and value in most_common_vals:\n",
    "        selectivity = most_common_freqs[most_common_vals.index(value)] \n",
    "        return selectivity\n",
    "\n",
    "    # if not a common value, estimate using n_distinct\n",
    "    if n_distinct < 0:\n",
    "        n_distinct = -n_distinct\n",
    "\n",
    "    selectivity = 1.0 / n_distinct    \n",
    "\n",
    "    if histogram_bounds is not None:\n",
    "        if data_type == 'numeric':\n",
    "            histogram_bounds = [float(x) for x in histogram_bounds.strip('{}').split(',')] # convert to list of integers\n",
    "        elif data_type == 'char':\n",
    "            histogram_bounds = [x for x in histogram_bounds.strip('{}').split(',')]\n",
    "        else:\n",
    "            raise ValueError(\"Data type not supported, needs ot be either numeric or char\")    \n",
    "\n",
    "        total_bins = len(histogram_bounds) - 1\n",
    "\n",
    "        # iterate over bins, find bin that contains the value\n",
    "        for i in range(total_bins):\n",
    "            bin_lower_bound = histogram_bounds[i]\n",
    "            bin_upper_bound = histogram_bounds[i+1]\n",
    "\n",
    "            # check for range overlap\n",
    "            if bin_lower_bound <= value <= bin_upper_bound:\n",
    "                bin_width = bin_upper_bound - bin_lower_bound\n",
    "                if bin_width > 0:\n",
    "                    # assume uniform distribution within this bin and calculate selectivity\n",
    "                    uniform_selectivity = 1.0 / (bin_width*total_bins)\n",
    "                    selectivity = min(selectivity, uniform_selectivity)\n",
    "                break    \n",
    "\n",
    "    return selectivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated selectivity for range (1992, 1994): 0.42879498\n",
      "Estimated selectivity for value 1992: 0.14319248\n",
      "Estimated selectivity for range ('Monday', 'Wednesday'): 0.8571987299999999\n",
      "Estimated selectivity for value Monday: 0.14280125\n"
     ]
    }
   ],
   "source": [
    "# test the selectivity estimation functions on a numeric column\n",
    "attribute = 'd_year'\n",
    "stats_dict = stats['dwdate']\n",
    "\n",
    "# test range selectivity estimation\n",
    "value_range = (1992, 1994)\n",
    "selectivity = estimate_selectivity_range(attribute, value_range, stats_dict, estimated_rows)\n",
    "print(f\"Estimated selectivity for range {value_range}: {selectivity}\")\n",
    "\n",
    "# test equality selectivity estimation\n",
    "value = 1992\n",
    "selectivity = estimate_selectivity_eq(attribute, value, stats_dict)\n",
    "print(f\"Estimated selectivity for value {value}: {selectivity}\")\n",
    "\n",
    "# now, let's try a char column\n",
    "attribute = 'd_dayofweek'\n",
    "\n",
    "# test range selectivity estimation\n",
    "value_range = ('Monday', 'Wednesday')\n",
    "selectivity = estimate_selectivity_range(attribute, value_range, stats_dict, estimated_rows)\n",
    "print(f\"Estimated selectivity for range {value_range}: {selectivity}\")\n",
    "\n",
    "# test equality selectivity estimation\n",
    "value = 'Monday'\n",
    "selectivity = estimate_selectivity_eq(attribute, value, stats_dict)\n",
    "print(f\"Estimated selectivity for value {value}: {selectivity}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Case: consider three possible access paths: Sequential Scan, Index Scan and Index Only Scan (will add in the rest later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Extract query predicates and payload, the payload is a list of column names (across possibly multiple tables) and the predicate is a list of dictionaries, each dict contains the column name, operator (either equality or range) and either a range tuple or single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload: {'lineorder': ['lo_linenumber', 'lo_quantity', 'lo_orderdate']}\n",
      "Predicates: {'lineorder': [{'column': 'lo_linenumber', 'operator': 'range', 'value': (1, 5)}, {'column': 'lo_quantity', 'operator': 'eq', 'value': 10}]}\n"
     ]
    }
   ],
   "source": [
    "# simple example query on single table (will later be expanded to join queries)\n",
    "example_query = \"\"\"\n",
    "                SELECT lo_linenumber, lo_quantity, lo_orderdate  \n",
    "                FROM lineorder\n",
    "                WHERE lo_linenumber >= {linenumber_low} AND lo_linenumber <= {linenumber_high}\n",
    "                AND lo_quantity = {quantity};\n",
    "                \"\"\"\n",
    "\n",
    "# extract tables and associated columns\n",
    "tables = {}\n",
    "tables['lineorder'] = ['lo_linenumber', 'lo_quantity', 'lo_orderdate']\n",
    "\n",
    "# extract the payload\n",
    "payload = {}\n",
    "payload['lineorder'] = ['lo_linenumber', 'lo_quantity', 'lo_orderdate']\n",
    "\n",
    "# extract the predicates\n",
    "predicates = {}\n",
    "predicates['lineorder'] =  [  {'column': 'lo_linenumber', 'operator': 'range', 'value': (1, 5)},\n",
    "                              {'column': 'lo_quantity', 'operator': 'eq', 'value': 10}\n",
    "                           ]\n",
    "\n",
    "print(f\"Payload: {payload}\")\n",
    "print(f\"Predicates: {predicates}\")\n",
    "\n",
    "# create some index objects\n",
    "index_1 = Index('lineorder', 'IX_lineorder_lo_linenumber_lo_quantity', index_columns=['lo_linenumber', 'lo_quantity'])\n",
    "index_2 = Index('lineorder', 'IX_lineorder_lo_linenumber_lo_quantity_lo_o', index_columns=['lo_linenumber', 'lo_quantity'], include_columns=['lo_orderdate'])\n",
    "index_3 = Index('lineorder', 'IX_lineorder_lo_orderdate', index_columns=['lo_orderdate'])\n",
    "index_4 = Index('lineorder', 'IX_lineorder_lo_quantity', index_columns=['lo_quantity'])\n",
    "indexes = {index.index_id: index for index in [index_1, index_2, index_3, index_4]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Enumerate the possible access path for each table involved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking index:  IX_lineorder_lo_linenumber_lo_quantity\n",
      "Index scan possible\n",
      "Checking index:  IX_lineorder_lo_linenumber_lo_quantity_lo_o\n",
      "Index scan possible\n",
      "Index only scan possible\n",
      "Checking index:  IX_lineorder_lo_orderdate\n",
      "Checking index:  IX_lineorder_lo_quantity\n",
      "Index scan possible\n",
      "Access paths: \n",
      "Table: lineorder\n",
      "    {'scan_type': 'Sequential Scan', 'lineorder': 'lineorder'}\n",
      "    {'scan_type': 'Index Scan', 'index_id': 'IX_lineorder_lo_linenumber_lo_quantity'}\n",
      "    {'scan_type': 'Index Scan', 'index_id': 'IX_lineorder_lo_linenumber_lo_quantity_lo_o'}\n",
      "    {'scan_type': 'Index Only Scan', 'index_id': 'IX_lineorder_lo_linenumber_lo_quantity_lo_o'}\n",
      "    {'scan_type': 'Index Scan', 'index_id': 'IX_lineorder_lo_quantity'}\n"
     ]
    }
   ],
   "source": [
    "access_paths = {}\n",
    "for table_name in tables:\n",
    "    table_predicate_cols = [pred['column'] for pred in predicates[table_name]]\n",
    "    table_payload_cols = [col for col in payload[table_name] if col in tables[table_name]]   \n",
    "    table_access_paths = [{'scan_type': 'Sequential Scan', table_name: table_name}]\n",
    "    for index in indexes.values():\n",
    "        if index.table_name == table_name:\n",
    "            print(\"Checking index: \", index.index_id)\n",
    "            # check if index scan is possible, at least one index column should be in the predicate\n",
    "            if set(index.index_columns).intersection(table_predicate_cols):\n",
    "                table_access_paths.append({'scan_type': 'Index Scan', 'index_id': index.index_id})\n",
    "                print(\"Index scan possible\")\n",
    "            # check if index only scan is possible\n",
    "            if set(index.index_columns).issuperset(table_predicate_cols) and set(list(index.index_columns) + list(index.include_columns)).issuperset(table_payload_cols):\n",
    "                table_access_paths.append({'scan_type': 'Index Only Scan', 'index_id': index.index_id})\n",
    "                print(\"Index only scan possible\")\n",
    "    access_paths[table_name] = table_access_paths\n",
    "\n",
    "print(f\"Access paths: \")\n",
    "for table, paths in access_paths.items():\n",
    "    print(f\"Table: {table}\")\n",
    "    for path in paths:\n",
    "        print(f\"    {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate selectivity of the predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_selectivity(attribute, operator, value, stats_dict, total_rows):\n",
    "    if operator == 'eq':\n",
    "        return estimate_selectivity_eq(attribute, value, stats_dict)\n",
    "    elif operator == 'range':\n",
    "        return estimate_selectivity_range(attribute, value, stats_dict, total_rows)\n",
    "    else:\n",
    "        raise ValueError(\"Operator not supported, needs to be either eq or range\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated selectivity for predicate {'column': 'lo_linenumber', 'operator': 'range', 'value': (1, 5)}: 0.894000005\n",
      "Estimated selectivity for predicate {'column': 'lo_quantity', 'operator': 'eq', 'value': 10}: 0.0182\n"
     ]
    }
   ],
   "source": [
    "for table_name, table_preds in predicates.items():\n",
    "    table_stats_dict = stats[table_name]   \n",
    "    table_estimated_rows = estimated_rows[table_name]\n",
    "    for pred in table_preds:\n",
    "        selectivity = estimate_selectivity(pred['column'], pred['operator'], pred['value'], table_stats_dict, table_estimated_rows)\n",
    "        print(f\"Estimated selectivity for predicate {pred}: {selectivity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lineorder': [{'column': 'lo_linenumber',\n",
       "   'operator': 'range',\n",
       "   'value': (1, 5)},\n",
       "  {'column': 'lo_quantity', 'operator': 'eq', 'value': 10}]}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each table, estimate selectivity and disk IO cost of all access path for that table and select cheapest path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_row_overhead(num_nullable_columns=0):\n",
    "    # Tuple header size\n",
    "    tuple_header_size = 23  # bytes\n",
    "    # Null bitmap size (1 byte for every 8 nullable columns)\n",
    "    null_bitmap_size = (num_nullable_columns + 7) // 8\n",
    "    # Total overhead\n",
    "    total_overhead = tuple_header_size + null_bitmap_size\n",
    "\n",
    "    return total_overhead\n",
    "\n",
    "\n",
    "def table_avg_rows_per_page(table_stats_dict):\n",
    "    # add up the average width of all columns to get the average width of a row\n",
    "    avg_row_size = 0\n",
    "    for column, column_stats in table_stats_dict.items():\n",
    "        avg_row_size += column_stats['avg_width']\n",
    "    # add the row overhead\n",
    "    avg_row_size += calculate_row_overhead()\n",
    "    # calculate the average number of rows that can fit in a page\n",
    "    avg_rows_per_page = int(get_page_size() / avg_row_size)\n",
    "\n",
    "    return avg_rows_per_page\n",
    "\n",
    "def index_average_rows_per_page(index, table_stats_dict):\n",
    "    columns = list(index.index_columns) + list(index.include_columns)   \n",
    "    # add up the average width of all columns to get the average width of a row\n",
    "    avg_row_size = 0\n",
    "    for column in columns:\n",
    "        avg_row_size += table_stats_dict[column]['avg_width']\n",
    "    # add the row overhead\n",
    "    index_row_overhead = 16  # assume 16 bytes \n",
    "    avg_row_size += index_row_overhead\n",
    "    # calculate the average number of rows that can fit in a page\n",
    "    # (assuming the index is a B+ tree, so only the leaf nodes contain the actual data)\n",
    "    avg_rows_per_page = int(get_page_size() / avg_row_size)\n",
    "       \n",
    "    return avg_rows_per_page\n",
    "\n",
    "\n",
    "def estimate_index_scan_cost(index, table_stats_dict, table_predicates, total_rows, index_only_scan=False):\n",
    "    # check if leading index column is in the predicates\n",
    "    leading_index_column = index.index_columns[0]\n",
    "    predicate_columns = [pred['column'] for pred in table_predicates]\n",
    "    \n",
    "    if leading_index_column not in predicate_columns:\n",
    "        # assign high cost to prevent using this index, sequential scan will be cheaper\n",
    "        return float('inf')\n",
    "    \n",
    "    # calculate the combined selectivity for this index (assuming attribute independence/no correlations of predicates)\n",
    "    combined_selectivity = 1.0\n",
    "    for pred in table_predicates:\n",
    "        if pred['column'] in index.index_columns:\n",
    "        \n",
    "            selectivity = estimate_selectivity(pred['column'], pred['operator'], pred['value'], table_stats_dict, total_rows)\n",
    "            combined_selectivity *= selectivity\n",
    "\n",
    "    # estimate cardinality of the index scan\n",
    "    index_cardinality = combined_selectivity * total_rows\n",
    "    # estimate the number of pages that need to be accessed\n",
    "    avg_rows_per_page = index_average_rows_per_page(index, table_stats_dict)\n",
    "    index_pages = int(index_cardinality / avg_rows_per_page)\n",
    "    \n",
    "    if index_only_scan: \n",
    "        index_scan_cost = index_pages\n",
    "    else:\n",
    "        # for index scan, we need to access the table as well\n",
    "        index_average_rows_per_page_table = table_avg_rows_per_page(table_stats_dict)\n",
    "        table_pages = int(index_cardinality / index_average_rows_per_page_table)\n",
    "        # return total cost as the sum of index and table pages\n",
    "        index_scan_cost = index_pages + table_pages\n",
    "\n",
    "    return index_scan_cost\n",
    "\n",
    "\n",
    "\n",
    "def estimate_sequentail_scan_cost(table_stats_dict, total_rows):\n",
    "    # estimate cardinality of the scan\n",
    "    scan_cardinality = total_rows\n",
    "    # estimate the number of pages that need to be accessed\n",
    "    avg_rows_per_page = table_avg_rows_per_page(table_stats_dict)\n",
    "    scan_pages = int(scan_cardinality / avg_rows_per_page)\n",
    "    # estimate the total cost as the number of pages that need to be accessed\n",
    "    sequential_scan_cost = scan_pages\n",
    "\n",
    "    return sequential_scan_cost\n",
    "\n",
    "\n",
    "def find_cheapest_paths(access_paths, predicates, stats, estimated_rows, verbose=False):\n",
    "    cheapest_table_access_path = {}    \n",
    "    if verbose: print(f\"Finding cheapest access paths for tables: {access_paths.keys()}\")\n",
    "    # enumerate over tables that need to be accessed\n",
    "    for table_name in access_paths:\n",
    "        if verbose: print(f\"\\nTable: {table_name}\")\n",
    "        # enumerate over access paths for this table\n",
    "        cheapest_cost = float('inf')\n",
    "        for path in access_paths[table_name]:\n",
    "            # compute the cost of this access path\n",
    "            # (for now, assume cost is proportional to the cardinality of the data that needs to be accessed)\n",
    "            if path['scan_type'] == 'Sequential Scan':\n",
    "                cost = estimate_sequentail_scan_cost(stats[table_name], estimated_rows[table_name])\n",
    "            elif path['scan_type'] == 'Index Scan':\n",
    "                index_id = path['index_id']\n",
    "                index = indexes[index_id]\n",
    "                cost = estimate_index_scan_cost(index, stats[table_name], predicates[table_name], estimated_rows[table_name])\n",
    "            elif path['scan_type'] == 'Index Only Scan':\n",
    "                index_id = path['index_id']\n",
    "                index = indexes[index_id]\n",
    "                cost = estimate_index_scan_cost(index, stats[table_name], predicates[table_name], estimated_rows[table_name], index_only_scan=True)\n",
    "            else:\n",
    "                raise ValueError(\"Scan type not supported\")            \n",
    "\n",
    "            if verbose: print(f\"\\t\\tAccess path: {path}, Cost: {cost}\")\n",
    "            if cost < cheapest_cost:\n",
    "                cheapest_cost = cost\n",
    "                cheapest_access_path = path\n",
    "        cheapest_table_access_path[table_name] = cheapest_access_path\n",
    "        if verbose: print(f\"\\tCheapest access path: {cheapest_access_path}, Cost: {cheapest_cost}\")\n",
    "    return cheapest_table_access_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding cheapest access paths for tables: dict_keys(['lineorder'])\n",
      "\n",
      "Table: lineorder\n",
      "\t\tAccess path: {'scan_type': 'Sequential Scan', 'lineorder': 'lineorder'}, Cost: 759319\n",
      "\t\tAccess path: {'scan_type': 'Index Scan', 'index_id': 'IX_lineorder_lo_linenumber_lo_quantity'}, Cost: 15216\n",
      "\t\tAccess path: {'scan_type': 'Index Scan', 'index_id': 'IX_lineorder_lo_linenumber_lo_quantity_lo_o'}, Cost: 15696\n",
      "\t\tAccess path: {'scan_type': 'Index Only Scan', 'index_id': 'IX_lineorder_lo_linenumber_lo_quantity_lo_o'}, Cost: 3342\n",
      "\t\tAccess path: {'scan_type': 'Index Scan', 'index_id': 'IX_lineorder_lo_quantity'}, Cost: 16488\n",
      "\tCheapest access path: {'scan_type': 'Index Only Scan', 'index_id': 'IX_lineorder_lo_linenumber_lo_quantity_lo_o'}, Cost: 3342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lineorder': {'scan_type': 'Index Only Scan',\n",
       "  'index_id': 'IX_lineorder_lo_linenumber_lo_quantity_lo_o'}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_cheapest_paths(access_paths, predicates, stats, estimated_rows, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_clone_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
